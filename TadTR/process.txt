(TadTR) next@pc-b-mou-d-2001-ubuntu:~/PycharmProjects/TadTR/TadTR$ python main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval --resume data/thumos14_i3d2s_tadtr_reference.pth 
Not using distributed mode
this is master process, set up logger
[11/28 15:28:42][INFO]: Log file is outputs/thumos14_i3d2s_tadtr/test.log
[11/28 15:28:42][INFO]: git:
  sha: 3af0abcb17a20210ddd04d2c7e212a024ea0fedc, status: clean, branch: master

[11/28 15:28:42][INFO]: main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval --resume data/thumos14_i3d2s_tadtr_reference.pth
[11/28 15:28:42][INFO]: Namespace(cfg='configs/thumos14_i3d2s_tadtr.yml', device='cuda', dist_url='env://', distributed=False, eval=True, multi_gpu=False, num_workers=2, opt=[], resume='data/thumos14_i3d2s_tadtr_reference.pth', seed=42, world_size=1)
[11/28 15:28:42][INFO]: {'tensorboard': False, 'disable_cuda': False, 'dfm_att_backend': 'pytorch', 'output_dir': 'outputs/thumos14_i3d2s_tadtr', 'dataset_name': 'thumos14', 'input_type': 'feature', 'feature': 'i3d2s', 'feature_dim': 2048, 'binary': False, 'test_set': 'val', 'online_slice': True, 'slice_len': 128, 'slice_overlap': 0.75, 'test_slice_overlap': 0.25, 'backbone': 'none', 'use_pos_embed': True, 'position_embedding': 'sine', 'enc_layers': 4, 'dec_layers': 4, 'dim_feedforward': 1024, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'enc_n_points': 4, 'dec_n_points': 4, 'num_queries': 40, 'activation': 'relu', 'seg_refine': True, 'act_reg': True, 'disable_query_self_att': False, 'aux_loss': True, 'act_loss_coef': 4, 'cls_loss_coef': 2, 'seg_loss_coef': 5, 'iou_loss_coef': 2, 'eos_coef': 0.1, 'focal_alpha': 0.25, 'set_cost_class': 6, 'set_cost_seg': 5, 'set_cost_iou': 2, 'lr': 0.0002, 'lr_backbone_names': ['backbone'], 'lr_backbone': 1e-05, 'lr_linear_proj_names': ['reference_points', 'sampling_offsets'], 'lr_linear_proj_mult': 0.1, 'optimizer': 'AdamW', 'batch_size': 16, 'weight_decay': 0.0001, 'clip_max_norm': 0.1, 'epochs': 16, 'lr_step': [14], 'ckpt_interval': 10, 'iter_size': 1, 'test_interval': 1, 'postproc_rank': 1, 'postproc_cls_topk': 1, 'postproc_ins_topk': 100, 'nms_thr': 0.4}
[11/28 15:28:44][INFO]: number of params: 8661594
Use data transform None
[11/28 15:28:44][INFO]: 213 videos, 1779 slices
[11/28 15:28:44][INFO]: test subset video numbers: 1779
loading checkpint data/thumos14_i3d2s_tadtr_reference.pth
[11/28 15:28:44][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
  2%|██▎                                                                                                                                | 2/112 [00:00<00:13,  8.01it/s]
Traceback (most recent call last):
  File "main.py", line 310, in <module>
    main(args)
  File "main.py", line 221, in main
    test_stats = test(model, criterion, postprocessors,
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/next/PycharmProjects/TadTR/TadTR/engine.py", line 120, in test
    for (samples, targets) in tqdm.tqdm(data_loader, total=len(data_loader)):
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1183, in _next_data
    return self._process_data(data)
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 204, in __getitem__
    video_data = self._get_video_data(index)
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 109, in _get_video_data
    return self._get_feature_data(index)
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 132, in _get_feature_data
    feature_data = load_feature(local_ft_path, ft_format, shape)
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/data_utils.py", line 169, in load_feature
    video_df = torch.load(ft_path).numpy()
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'data/thumos14/I3D_2stream_Pth/video_test_0000028'

(TadTR) next@pc-b-mou-d-2001-ubuntu:~/PycharmProjects/TadTR/TadTR$ python main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval --resume data/thumos14_i3d2s_tadtr_reference.pth 
Not using distributed mode
this is master process, set up logger
[11/28 15:45:57][INFO]: Log file is outputs/thumos14_i3d2s_tadtr/test.log
[11/28 15:45:57][INFO]: git:
  sha: 3af0abcb17a20210ddd04d2c7e212a024ea0fedc, status: clean, branch: master

[11/28 15:45:57][INFO]: main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval --resume data/thumos14_i3d2s_tadtr_reference.pth
[11/28 15:45:57][INFO]: Namespace(cfg='configs/thumos14_i3d2s_tadtr.yml', device='cuda', dist_url='env://', distributed=False, eval=True, multi_gpu=False, num_workers=2, opt=[], resume='data/thumos14_i3d2s_tadtr_reference.pth', seed=42, world_size=1)
[11/28 15:45:57][INFO]: {'tensorboard': False, 'disable_cuda': False, 'dfm_att_backend': 'pytorch', 'output_dir': 'outputs/thumos14_i3d2s_tadtr', 'dataset_name': 'thumos14', 'input_type': 'feature', 'feature': 'i3d2s', 'feature_dim': 2048, 'binary': False, 'test_set': 'val', 'online_slice': True, 'slice_len': 128, 'slice_overlap': 0.75, 'test_slice_overlap': 0.25, 'backbone': 'none', 'use_pos_embed': True, 'position_embedding': 'sine', 'enc_layers': 4, 'dec_layers': 4, 'dim_feedforward': 1024, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'enc_n_points': 4, 'dec_n_points': 4, 'num_queries': 40, 'activation': 'relu', 'seg_refine': True, 'act_reg': True, 'disable_query_self_att': False, 'aux_loss': True, 'act_loss_coef': 4, 'cls_loss_coef': 2, 'seg_loss_coef': 5, 'iou_loss_coef': 2, 'eos_coef': 0.1, 'focal_alpha': 0.25, 'set_cost_class': 6, 'set_cost_seg': 5, 'set_cost_iou': 2, 'lr': 0.0002, 'lr_backbone_names': ['backbone'], 'lr_backbone': 1e-05, 'lr_linear_proj_names': ['reference_points', 'sampling_offsets'], 'lr_linear_proj_mult': 0.1, 'optimizer': 'AdamW', 'batch_size': 16, 'weight_decay': 0.0001, 'clip_max_norm': 0.1, 'epochs': 16, 'lr_step': [14], 'ckpt_interval': 10, 'iter_size': 1, 'test_interval': 1, 'postproc_rank': 1, 'postproc_cls_topk': 1, 'postproc_ins_topk': 100, 'nms_thr': 0.4}
[11/28 15:46:00][INFO]: number of params: 8661594
Use data transform None
Traceback (most recent call last):
  File "main.py", line 310, in <module>
    main(args)
  File "main.py", line 164, in main
    dataset_val = build_dataset(subset=cfg.test_set, args=cfg, mode='val')
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/__init__.py", line 6, in build_dataset
    return build_video_dataset(args.dataset_name, subset, args, mode)
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 220, in build
    return TADDataset(
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 60, in __init__
    self._prepare()
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 76, in _prepare
    anno_dict = json.load(open(self.ann_file))
FileNotFoundError: [Errno 2] No such file or directory: 'data/thumos14/th14_annotations_with_fps_duration.json'
(TadTR) next@pc-b-mou-d-2001-ubuntu:~/PycharmProjects/TadTR/TadTR$ python main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval --resume data/thumos14_i3d2s_tadtr_reference.pth 
Not using distributed mode
this is master process, set up logger
[11/28 15:47:11][INFO]: Log file is outputs/thumos14_i3d2s_tadtr/test.log
[11/28 15:47:11][INFO]: git:
  sha: 3af0abcb17a20210ddd04d2c7e212a024ea0fedc, status: clean, branch: master

[11/28 15:47:11][INFO]: main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval --resume data/thumos14_i3d2s_tadtr_reference.pth
[11/28 15:47:11][INFO]: Namespace(cfg='configs/thumos14_i3d2s_tadtr.yml', device='cuda', dist_url='env://', distributed=False, eval=True, multi_gpu=False, num_workers=2, opt=[], resume='data/thumos14_i3d2s_tadtr_reference.pth', seed=42, world_size=1)
[11/28 15:47:11][INFO]: {'tensorboard': False, 'disable_cuda': False, 'dfm_att_backend': 'pytorch', 'output_dir': 'outputs/thumos14_i3d2s_tadtr', 'dataset_name': 'thumos14', 'input_type': 'feature', 'feature': 'i3d2s', 'feature_dim': 2048, 'binary': False, 'test_set': 'val', 'online_slice': True, 'slice_len': 128, 'slice_overlap': 0.75, 'test_slice_overlap': 0.25, 'backbone': 'none', 'use_pos_embed': True, 'position_embedding': 'sine', 'enc_layers': 4, 'dec_layers': 4, 'dim_feedforward': 1024, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'enc_n_points': 4, 'dec_n_points': 4, 'num_queries': 40, 'activation': 'relu', 'seg_refine': True, 'act_reg': True, 'disable_query_self_att': False, 'aux_loss': True, 'act_loss_coef': 4, 'cls_loss_coef': 2, 'seg_loss_coef': 5, 'iou_loss_coef': 2, 'eos_coef': 0.1, 'focal_alpha': 0.25, 'set_cost_class': 6, 'set_cost_seg': 5, 'set_cost_iou': 2, 'lr': 0.0002, 'lr_backbone_names': ['backbone'], 'lr_backbone': 1e-05, 'lr_linear_proj_names': ['reference_points', 'sampling_offsets'], 'lr_linear_proj_mult': 0.1, 'optimizer': 'AdamW', 'batch_size': 16, 'weight_decay': 0.0001, 'clip_max_norm': 0.1, 'epochs': 16, 'lr_step': [14], 'ckpt_interval': 10, 'iter_size': 1, 'test_interval': 1, 'postproc_rank': 1, 'postproc_cls_topk': 1, 'postproc_ins_topk': 100, 'nms_thr': 0.4}
[11/28 15:47:13][INFO]: number of params: 8661594
Use data transform None
Traceback (most recent call last):
  File "main.py", line 310, in <module>
    main(args)
  File "main.py", line 164, in main
    dataset_val = build_dataset(subset=cfg.test_set, args=cfg, mode='val')
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/__init__.py", line 6, in build_dataset
    return build_video_dataset(args.dataset_name, subset, args, mode)
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 220, in build
    return TADDataset(
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 60, in __init__
    self._prepare()
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 79, in _prepare
    self.video_dict, self.video_list = get_dataset_dict(self.ft_info_file, self.ann_file, self.subset, mode=self.mode, online_slice=self.online_slice, slice_len=self.slice_len, slice_overlap=self.slice_overlap, ignore_empty=self.mode == 'train', return_id_list=True)
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/data_utils.py", line 61, in get_dataset_dict
    video_ft_info = load_json(video_info_path)
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/data_utils.py", line 19, in load_json
    return json.load(open(path))
FileNotFoundError: [Errno 2] No such file or directory: 'data/thumos14/th14_i3d2s_ft_info.json'
(TadTR) next@pc-b-mou-d-2001-ubuntu:~/PycharmProjects/TadTR/TadTR$ python main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval --resume data/thumos14_i3d2s_tadtr_reference.pth 
Not using distributed mode
this is master process, set up logger
[11/28 15:47:31][INFO]: Log file is outputs/thumos14_i3d2s_tadtr/test.log
[11/28 15:47:31][INFO]: git:
  sha: 3af0abcb17a20210ddd04d2c7e212a024ea0fedc, status: clean, branch: master

[11/28 15:47:31][INFO]: main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval --resume data/thumos14_i3d2s_tadtr_reference.pth
[11/28 15:47:31][INFO]: Namespace(cfg='configs/thumos14_i3d2s_tadtr.yml', device='cuda', dist_url='env://', distributed=False, eval=True, multi_gpu=False, num_workers=2, opt=[], resume='data/thumos14_i3d2s_tadtr_reference.pth', seed=42, world_size=1)
[11/28 15:47:31][INFO]: {'tensorboard': False, 'disable_cuda': False, 'dfm_att_backend': 'pytorch', 'output_dir': 'outputs/thumos14_i3d2s_tadtr', 'dataset_name': 'thumos14', 'input_type': 'feature', 'feature': 'i3d2s', 'feature_dim': 2048, 'binary': False, 'test_set': 'val', 'online_slice': True, 'slice_len': 128, 'slice_overlap': 0.75, 'test_slice_overlap': 0.25, 'backbone': 'none', 'use_pos_embed': True, 'position_embedding': 'sine', 'enc_layers': 4, 'dec_layers': 4, 'dim_feedforward': 1024, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'enc_n_points': 4, 'dec_n_points': 4, 'num_queries': 40, 'activation': 'relu', 'seg_refine': True, 'act_reg': True, 'disable_query_self_att': False, 'aux_loss': True, 'act_loss_coef': 4, 'cls_loss_coef': 2, 'seg_loss_coef': 5, 'iou_loss_coef': 2, 'eos_coef': 0.1, 'focal_alpha': 0.25, 'set_cost_class': 6, 'set_cost_seg': 5, 'set_cost_iou': 2, 'lr': 0.0002, 'lr_backbone_names': ['backbone'], 'lr_backbone': 1e-05, 'lr_linear_proj_names': ['reference_points', 'sampling_offsets'], 'lr_linear_proj_mult': 0.1, 'optimizer': 'AdamW', 'batch_size': 16, 'weight_decay': 0.0001, 'clip_max_norm': 0.1, 'epochs': 16, 'lr_step': [14], 'ckpt_interval': 10, 'iter_size': 1, 'test_interval': 1, 'postproc_rank': 1, 'postproc_cls_topk': 1, 'postproc_ins_topk': 100, 'nms_thr': 0.4}
[11/28 15:47:33][INFO]: number of params: 8661594
Use data transform None
[11/28 15:47:33][INFO]: 213 videos, 1779 slices
[11/28 15:47:33][INFO]: test subset video numbers: 1779
loading checkpint data/thumos14_i3d2s_tadtr_reference.pth
[11/28 15:47:33][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 310, in <module>
    main(args)
  File "main.py", line 221, in main
    test_stats = test(model, criterion, postprocessors,
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/next/PycharmProjects/TadTR/TadTR/engine.py", line 120, in test
    for (samples, targets) in tqdm.tqdm(data_loader, total=len(data_loader)):
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 204, in __getitem__
    video_data = self._get_video_data(index)
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 109, in _get_video_data
    return self._get_feature_data(index)
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_dataset.py", line 132, in _get_feature_data
    feature_data = load_feature(local_ft_path, ft_format, shape)
  File "/home/next/PycharmProjects/TadTR/TadTR/datasets/data_utils.py", line 169, in load_feature
    video_df = torch.load(ft_path).numpy()
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'data/thumos14/I3D_2stream_Pth/video_test_0000004'

(TadTR) next@pc-b-mou-d-2001-ubuntu:~/PycharmProjects/TadTR/TadTR$ python main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval --resume data/thumos14_i3d2s_tadtr_reference.pth 
Not using distributed mode
this is master process, set up logger
[11/28 15:48:12][INFO]: Log file is outputs/thumos14_i3d2s_tadtr/test.log
[11/28 15:48:12][INFO]: git:
  sha: 3af0abcb17a20210ddd04d2c7e212a024ea0fedc, status: clean, branch: master

[11/28 15:48:12][INFO]: main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval --resume data/thumos14_i3d2s_tadtr_reference.pth
[11/28 15:48:12][INFO]: Namespace(cfg='configs/thumos14_i3d2s_tadtr.yml', device='cuda', dist_url='env://', distributed=False, eval=True, multi_gpu=False, num_workers=2, opt=[], resume='data/thumos14_i3d2s_tadtr_reference.pth', seed=42, world_size=1)
[11/28 15:48:12][INFO]: {'tensorboard': False, 'disable_cuda': False, 'dfm_att_backend': 'pytorch', 'output_dir': 'outputs/thumos14_i3d2s_tadtr', 'dataset_name': 'thumos14', 'input_type': 'feature', 'feature': 'i3d2s', 'feature_dim': 2048, 'binary': False, 'test_set': 'val', 'online_slice': True, 'slice_len': 128, 'slice_overlap': 0.75, 'test_slice_overlap': 0.25, 'backbone': 'none', 'use_pos_embed': True, 'position_embedding': 'sine', 'enc_layers': 4, 'dec_layers': 4, 'dim_feedforward': 1024, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'enc_n_points': 4, 'dec_n_points': 4, 'num_queries': 40, 'activation': 'relu', 'seg_refine': True, 'act_reg': True, 'disable_query_self_att': False, 'aux_loss': True, 'act_loss_coef': 4, 'cls_loss_coef': 2, 'seg_loss_coef': 5, 'iou_loss_coef': 2, 'eos_coef': 0.1, 'focal_alpha': 0.25, 'set_cost_class': 6, 'set_cost_seg': 5, 'set_cost_iou': 2, 'lr': 0.0002, 'lr_backbone_names': ['backbone'], 'lr_backbone': 1e-05, 'lr_linear_proj_names': ['reference_points', 'sampling_offsets'], 'lr_linear_proj_mult': 0.1, 'optimizer': 'AdamW', 'batch_size': 16, 'weight_decay': 0.0001, 'clip_max_norm': 0.1, 'epochs': 16, 'lr_step': [14], 'ckpt_interval': 10, 'iter_size': 1, 'test_interval': 1, 'postproc_rank': 1, 'postproc_cls_topk': 1, 'postproc_ins_topk': 100, 'nms_thr': 0.4}
[11/28 15:48:14][INFO]: number of params: 8661594
Use data transform None
[11/28 15:48:14][INFO]: 213 videos, 1779 slices
[11/28 15:48:14][INFO]: test subset video numbers: 1779
loading checkpint data/thumos14_i3d2s_tadtr_reference.pth
[11/28 15:48:15][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 25.13it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:48:23][INFO]: dump detection result in JSON format to outputs/detection_raw.json
[11/28 15:48:29][INFO]: mode=raw 114899 predictions from 210 videos
[11/28 15:48:32][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
74.80 69.11 60.10 46.63 32.84 56.70 raw epoch14
[11/28 15:48:32][INFO]: mAP_raw: 56.70
[11/28 15:48:32][INFO]: main takes 20.011 seconds
(TadTR) next@pc-b-mou-d-2001-ubuntu:~/PycharmProjects/TadTR/TadTR$ python main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval
Not using distributed mode
this is master process, set up logger
[11/28 15:50:47][INFO]: Log file is outputs/thumos14_i3d2s_tadtr/test.log
[11/28 15:50:47][INFO]: git:
  sha: 3af0abcb17a20210ddd04d2c7e212a024ea0fedc, status: clean, branch: master

[11/28 15:50:47][INFO]: main.py --cfg configs/thumos14_i3d2s_tadtr.yml --eval
[11/28 15:50:47][INFO]: Namespace(cfg='configs/thumos14_i3d2s_tadtr.yml', device='cuda', dist_url='env://', distributed=False, eval=True, multi_gpu=False, num_workers=2, opt=[], resume='', seed=42, world_size=1)
[11/28 15:50:47][INFO]: {'tensorboard': False, 'disable_cuda': False, 'dfm_att_backend': 'pytorch', 'output_dir': 'outputs/thumos14_i3d2s_tadtr', 'dataset_name': 'thumos14', 'input_type': 'feature', 'feature': 'i3d2s', 'feature_dim': 2048, 'binary': False, 'test_set': 'val', 'online_slice': True, 'slice_len': 128, 'slice_overlap': 0.75, 'test_slice_overlap': 0.25, 'backbone': 'none', 'use_pos_embed': True, 'position_embedding': 'sine', 'enc_layers': 4, 'dec_layers': 4, 'dim_feedforward': 1024, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'enc_n_points': 4, 'dec_n_points': 4, 'num_queries': 40, 'activation': 'relu', 'seg_refine': True, 'act_reg': True, 'disable_query_self_att': False, 'aux_loss': True, 'act_loss_coef': 4, 'cls_loss_coef': 2, 'seg_loss_coef': 5, 'iou_loss_coef': 2, 'eos_coef': 0.1, 'focal_alpha': 0.25, 'set_cost_class': 6, 'set_cost_seg': 5, 'set_cost_iou': 2, 'lr': 0.0002, 'lr_backbone_names': ['backbone'], 'lr_backbone': 1e-05, 'lr_linear_proj_names': ['reference_points', 'sampling_offsets'], 'lr_linear_proj_mult': 0.1, 'optimizer': 'AdamW', 'batch_size': 16, 'weight_decay': 0.0001, 'clip_max_norm': 0.1, 'epochs': 16, 'lr_step': [14], 'ckpt_interval': 10, 'iter_size': 1, 'test_interval': 1, 'postproc_rank': 1, 'postproc_cls_topk': 1, 'postproc_ins_topk': 100, 'nms_thr': 0.4}
[11/28 15:50:49][INFO]: number of params: 8661594
Use data transform None
[11/28 15:50:49][INFO]: 213 videos, 1779 slices
[11/28 15:50:49][INFO]: test subset video numbers: 1779
loading checkpint outputs/thumos14_i3d2s_tadtr/model_best.pth
Traceback (most recent call last):
  File "main.py", line 310, in <module>
    main(args)
  File "main.py", line 210, in main
    checkpoint = torch.load(args.resume, map_location='cpu')
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/next/miniconda3/envs/TadTR/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'outputs/thumos14_i3d2s_tadtr/model_best.pth'
(TadTR) next@pc-b-mou-d-2001-ubuntu:~/PycharmProjects/TadTR/TadTR$ python main.py --cfg configs/thumos14_i3d2s_tadtr.yml 
Not using distributed mode
this is master process, set up logger
[11/28 15:52:11][INFO]: Log file is outputs/thumos14_i3d2s_tadtr/train.log
[11/28 15:52:11][INFO]: git:
  sha: 3af0abcb17a20210ddd04d2c7e212a024ea0fedc, status: clean, branch: master

[11/28 15:52:11][INFO]: main.py --cfg configs/thumos14_i3d2s_tadtr.yml
[11/28 15:52:11][INFO]: Namespace(cfg='configs/thumos14_i3d2s_tadtr.yml', device='cuda', dist_url='env://', distributed=False, eval=False, multi_gpu=False, num_workers=2, opt=[], resume='', seed=42, world_size=1)
[11/28 15:52:11][INFO]: {'tensorboard': False, 'disable_cuda': False, 'dfm_att_backend': 'pytorch', 'output_dir': 'outputs/thumos14_i3d2s_tadtr', 'dataset_name': 'thumos14', 'input_type': 'feature', 'feature': 'i3d2s', 'feature_dim': 2048, 'binary': False, 'test_set': 'val', 'online_slice': True, 'slice_len': 128, 'slice_overlap': 0.75, 'test_slice_overlap': 0.25, 'backbone': 'none', 'use_pos_embed': True, 'position_embedding': 'sine', 'enc_layers': 4, 'dec_layers': 4, 'dim_feedforward': 1024, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'enc_n_points': 4, 'dec_n_points': 4, 'num_queries': 40, 'activation': 'relu', 'seg_refine': True, 'act_reg': True, 'disable_query_self_att': False, 'aux_loss': True, 'act_loss_coef': 4, 'cls_loss_coef': 2, 'seg_loss_coef': 5, 'iou_loss_coef': 2, 'eos_coef': 0.1, 'focal_alpha': 0.25, 'set_cost_class': 6, 'set_cost_seg': 5, 'set_cost_iou': 2, 'lr': 0.0002, 'lr_backbone_names': ['backbone'], 'lr_backbone': 1e-05, 'lr_linear_proj_names': ['reference_points', 'sampling_offsets'], 'lr_linear_proj_mult': 0.1, 'optimizer': 'AdamW', 'batch_size': 16, 'weight_decay': 0.0001, 'clip_max_norm': 0.1, 'epochs': 16, 'lr_step': [14], 'ckpt_interval': 10, 'iter_size': 1, 'test_interval': 1, 'postproc_rank': 1, 'postproc_cls_topk': 1, 'postproc_ins_topk': 100, 'nms_thr': 0.4}
[11/28 15:52:14][INFO]: number of params: 8661594
Use data transform None
[11/28 15:52:14][INFO]: 213 videos, 1779 slices
[11/28 15:52:14][INFO]: test subset video numbers: 1779
Use data transform None
[11/28 15:52:14][INFO]: 199 videos, 3176 slices
[11/28 15:52:14][INFO]: val subset video numbers: 3176
[11/28 15:52:14][INFO]: Start training
[11/28 15:52:14][INFO]: lr=0.0002
[11/28 15:52:14][INFO]: lr=1e-05
[11/28 15:52:14][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:52:14][INFO]: Epoch: [0]  [  0/198]  eta: 0:01:08  lr: 0.000200  loss: 11.8947 (11.8947)  loss_ce: 2.1490 (2.1490)  loss_iou: 0.2747 (0.2747)  loss_ce_0: 1.9974 (1.9974)  loss_iou_0: 1.0598 (1.0598)  loss_ce_1: 2.0440 (2.0440)  loss_iou_1: 1.0402 (1.0402)  loss_ce_2: 2.2451 (2.2451)  loss_iou_2: 1.0844 (1.0844)  loss_ce_unscaled: 1.0745 (1.0745)  class_error_unscaled: 87.5000 (87.5000)  loss_segments_unscaled: 0.1097 (0.1097)  loss_iou_unscaled: 0.1374 (0.1374)  loss_ce_0_unscaled: 0.9987 (0.9987)  loss_segments_0_unscaled: 0.1083 (0.1083)  loss_iou_0_unscaled: 0.5299 (0.5299)  loss_ce_1_unscaled: 1.0220 (1.0220)  loss_segments_1_unscaled: 0.1023 (0.1023)  loss_iou_1_unscaled: 0.5201 (0.5201)  loss_ce_2_unscaled: 1.1225 (1.1225)  loss_segments_2_unscaled: 0.1091 (0.1091)  loss_iou_2_unscaled: 0.5422 (0.5422)  time: 0.3482  data: 0.2262  max mem: 391
[11/28 15:52:15][INFO]: Epoch: [0]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 7.6169 (8.0833)  loss_ce: 1.0460 (1.2306)  loss_iou: 0.2108 (0.2247)  loss_ce_0: 1.0805 (1.2338)  loss_iou_0: 1.0254 (1.0326)  loss_ce_1: 1.0365 (1.1795)  loss_iou_1: 1.0072 (0.9929)  loss_ce_2: 1.0003 (1.2042)  loss_iou_2: 0.9928 (0.9852)  loss_ce_unscaled: 0.5230 (0.6153)  class_error_unscaled: 61.7021 (64.2912)  loss_segments_unscaled: 0.0938 (0.0946)  loss_iou_unscaled: 0.1054 (0.1123)  loss_ce_0_unscaled: 0.5403 (0.6169)  loss_segments_0_unscaled: 0.0974 (0.0997)  loss_iou_0_unscaled: 0.5127 (0.5163)  loss_ce_1_unscaled: 0.5182 (0.5897)  loss_segments_1_unscaled: 0.0952 (0.0960)  loss_iou_1_unscaled: 0.5036 (0.4964)  loss_ce_2_unscaled: 0.5002 (0.6021)  loss_segments_2_unscaled: 0.0952 (0.0962)  loss_iou_2_unscaled: 0.4964 (0.4926)  time: 0.0683  data: 0.0012  max mem: 488
[11/28 15:52:17][INFO]: Epoch: [0]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 5.9055 (7.0655)  loss_ce: 0.7815 (1.0002)  loss_iou: 0.2051 (0.2168)  loss_ce_0: 0.6474 (0.9661)  loss_iou_0: 0.9769 (1.0115)  loss_ce_1: 0.6818 (0.9515)  loss_iou_1: 0.9389 (0.9745)  loss_ce_2: 0.7495 (0.9838)  loss_iou_2: 0.9086 (0.9612)  loss_ce_unscaled: 0.3908 (0.5001)  class_error_unscaled: 25.4545 (47.0083)  loss_segments_unscaled: 0.0917 (0.0939)  loss_iou_unscaled: 0.1025 (0.1084)  loss_ce_0_unscaled: 0.3237 (0.4831)  loss_segments_0_unscaled: 0.0975 (0.0987)  loss_iou_0_unscaled: 0.4884 (0.5057)  loss_ce_1_unscaled: 0.3409 (0.4757)  loss_segments_1_unscaled: 0.0928 (0.0963)  loss_iou_1_unscaled: 0.4695 (0.4872)  loss_ce_2_unscaled: 0.3748 (0.4919)  loss_segments_2_unscaled: 0.0912 (0.0945)  loss_iou_2_unscaled: 0.4543 (0.4806)  time: 0.0662  data: 0.0011  max mem: 488
[11/28 15:52:18][INFO]: Epoch: [0]  [ 60/198]  eta: 0:00:09  lr: 0.000200  loss: 5.3322 (6.5401)  loss_ce: 0.6324 (0.8875)  loss_iou: 0.2057 (0.2150)  loss_ce_0: 0.5424 (0.8364)  loss_iou_0: 0.9397 (0.9975)  loss_ce_1: 0.5775 (0.8395)  loss_iou_1: 0.8922 (0.9566)  loss_ce_2: 0.6232 (0.8748)  loss_iou_2: 0.8654 (0.9328)  loss_ce_unscaled: 0.3162 (0.4437)  class_error_unscaled: 18.6047 (39.2801)  loss_segments_unscaled: 0.0751 (0.0879)  loss_iou_unscaled: 0.1029 (0.1075)  loss_ce_0_unscaled: 0.2712 (0.4182)  loss_segments_0_unscaled: 0.0914 (0.0961)  loss_iou_0_unscaled: 0.4699 (0.4987)  loss_ce_1_unscaled: 0.2888 (0.4197)  loss_segments_1_unscaled: 0.0828 (0.0924)  loss_iou_1_unscaled: 0.4461 (0.4783)  loss_ce_2_unscaled: 0.3116 (0.4374)  loss_segments_2_unscaled: 0.0731 (0.0880)  loss_iou_2_unscaled: 0.4327 (0.4664)  time: 0.0653  data: 0.0010  max mem: 488
[11/28 15:52:19][INFO]: Epoch: [0]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 5.0986 (6.1997)  loss_ce: 0.5833 (0.8174)  loss_iou: 0.2246 (0.2169)  loss_ce_0: 0.4583 (0.7491)  loss_iou_0: 0.9741 (0.9931)  loss_ce_1: 0.4867 (0.7634)  loss_iou_1: 0.8879 (0.9410)  loss_ce_2: 0.5658 (0.7990)  loss_iou_2: 0.8738 (0.9198)  loss_ce_unscaled: 0.2917 (0.4087)  class_error_unscaled: 12.2449 (33.4793)  loss_segments_unscaled: 0.0695 (0.0851)  loss_iou_unscaled: 0.1123 (0.1084)  loss_ce_0_unscaled: 0.2292 (0.3746)  loss_segments_0_unscaled: 0.0972 (0.0957)  loss_iou_0_unscaled: 0.4871 (0.4966)  loss_ce_1_unscaled: 0.2433 (0.3817)  loss_segments_1_unscaled: 0.0803 (0.0897)  loss_iou_1_unscaled: 0.4440 (0.4705)  loss_ce_2_unscaled: 0.2829 (0.3995)  loss_segments_2_unscaled: 0.0721 (0.0857)  loss_iou_2_unscaled: 0.4369 (0.4599)  time: 0.0648  data: 0.0011  max mem: 488
[11/28 15:52:21][INFO]: Epoch: [0]  [100/198]  eta: 0:00:06  lr: 0.000200  loss: 5.1286 (5.9819)  loss_ce: 0.5627 (0.7668)  loss_iou: 0.2369 (0.2206)  loss_ce_0: 0.4407 (0.6887)  loss_iou_0: 0.9645 (0.9935)  loss_ce_1: 0.5015 (0.7109)  loss_iou_1: 0.9104 (0.9389)  loss_ce_2: 0.5331 (0.7464)  loss_iou_2: 0.9240 (0.9162)  loss_ce_unscaled: 0.2813 (0.3834)  class_error_unscaled: 11.3208 (29.4099)  loss_segments_unscaled: 0.0665 (0.0821)  loss_iou_unscaled: 0.1184 (0.1103)  loss_ce_0_unscaled: 0.2204 (0.3443)  loss_segments_0_unscaled: 0.0815 (0.0937)  loss_iou_0_unscaled: 0.4822 (0.4967)  loss_ce_1_unscaled: 0.2507 (0.3555)  loss_segments_1_unscaled: 0.0728 (0.0867)  loss_iou_1_unscaled: 0.4552 (0.4694)  loss_ce_2_unscaled: 0.2665 (0.3732)  loss_segments_2_unscaled: 0.0681 (0.0828)  loss_iou_2_unscaled: 0.4620 (0.4581)  time: 0.0677  data: 0.0012  max mem: 488
[11/28 15:52:22][INFO]: Epoch: [0]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 4.5900 (5.7695)  loss_ce: 0.5313 (0.7281)  loss_iou: 0.2074 (0.2194)  loss_ce_0: 0.4044 (0.6439)  loss_iou_0: 0.8776 (0.9787)  loss_ce_1: 0.4795 (0.6724)  loss_iou_1: 0.7911 (0.9202)  loss_ce_2: 0.5075 (0.7093)  loss_iou_2: 0.7667 (0.8975)  loss_ce_unscaled: 0.2657 (0.3641)  class_error_unscaled: 12.8205 (26.8885)  loss_segments_unscaled: 0.0634 (0.0797)  loss_iou_unscaled: 0.1037 (0.1097)  loss_ce_0_unscaled: 0.2022 (0.3219)  loss_segments_0_unscaled: 0.0758 (0.0913)  loss_iou_0_unscaled: 0.4388 (0.4893)  loss_ce_1_unscaled: 0.2398 (0.3362)  loss_segments_1_unscaled: 0.0666 (0.0839)  loss_iou_1_unscaled: 0.3955 (0.4601)  loss_ce_2_unscaled: 0.2538 (0.3546)  loss_segments_2_unscaled: 0.0649 (0.0803)  loss_iou_2_unscaled: 0.3833 (0.4488)  time: 0.0679  data: 0.0011  max mem: 488
[11/28 15:52:23][INFO]: Epoch: [0]  [140/198]  eta: 0:00:03  lr: 0.000200  loss: 4.4265 (5.5919)  loss_ce: 0.5205 (0.7003)  loss_iou: 0.2015 (0.2180)  loss_ce_0: 0.3870 (0.6093)  loss_iou_0: 0.8362 (0.9624)  loss_ce_1: 0.4399 (0.6397)  loss_iou_1: 0.7843 (0.9041)  loss_ce_2: 0.4915 (0.6796)  loss_iou_2: 0.7739 (0.8787)  loss_ce_unscaled: 0.2603 (0.3501)  class_error_unscaled: 12.3077 (24.6848)  loss_segments_unscaled: 0.0577 (0.0767)  loss_iou_unscaled: 0.1008 (0.1090)  loss_ce_0_unscaled: 0.1935 (0.3046)  loss_segments_0_unscaled: 0.0690 (0.0885)  loss_iou_0_unscaled: 0.4181 (0.4812)  loss_ce_1_unscaled: 0.2200 (0.3199)  loss_segments_1_unscaled: 0.0614 (0.0812)  loss_iou_1_unscaled: 0.3921 (0.4521)  loss_ce_2_unscaled: 0.2457 (0.3398)  loss_segments_2_unscaled: 0.0587 (0.0776)  loss_iou_2_unscaled: 0.3869 (0.4393)  time: 0.0657  data: 0.0013  max mem: 488
[11/28 15:52:25][INFO]: Epoch: [0]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 4.4482 (5.4460)  loss_ce: 0.4788 (0.6734)  loss_iou: 0.2163 (0.2178)  loss_ce_0: 0.3541 (0.5793)  loss_iou_0: 0.8726 (0.9529)  loss_ce_1: 0.3935 (0.6101)  loss_iou_1: 0.8278 (0.8952)  loss_ce_2: 0.4510 (0.6513)  loss_iou_2: 0.7708 (0.8659)  loss_ce_unscaled: 0.2394 (0.3367)  class_error_unscaled: 8.1081 (22.7627)  loss_segments_unscaled: 0.0601 (0.0747)  loss_iou_unscaled: 0.1082 (0.1089)  loss_ce_0_unscaled: 0.1771 (0.2897)  loss_segments_0_unscaled: 0.0726 (0.0863)  loss_iou_0_unscaled: 0.4363 (0.4764)  loss_ce_1_unscaled: 0.1968 (0.3051)  loss_segments_1_unscaled: 0.0626 (0.0792)  loss_iou_1_unscaled: 0.4139 (0.4476)  loss_ce_2_unscaled: 0.2255 (0.3256)  loss_segments_2_unscaled: 0.0574 (0.0754)  loss_iou_2_unscaled: 0.3854 (0.4330)  time: 0.0662  data: 0.0011  max mem: 488
[11/28 15:52:26][INFO]: Epoch: [0]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 4.1382 (5.3106)  loss_ce: 0.4411 (0.6480)  loss_iou: 0.2092 (0.2176)  loss_ce_0: 0.3158 (0.5515)  loss_iou_0: 0.8657 (0.9424)  loss_ce_1: 0.3423 (0.5818)  loss_iou_1: 0.8328 (0.8875)  loss_ce_2: 0.3887 (0.6235)  loss_iou_2: 0.7988 (0.8582)  loss_ce_unscaled: 0.2205 (0.3240)  class_error_unscaled: 5.6604 (21.2673)  loss_segments_unscaled: 0.0589 (0.0729)  loss_iou_unscaled: 0.1046 (0.1088)  loss_ce_0_unscaled: 0.1579 (0.2758)  loss_segments_0_unscaled: 0.0628 (0.0841)  loss_iou_0_unscaled: 0.4329 (0.4712)  loss_ce_1_unscaled: 0.1711 (0.2909)  loss_segments_1_unscaled: 0.0629 (0.0775)  loss_iou_1_unscaled: 0.4164 (0.4437)  loss_ce_2_unscaled: 0.1944 (0.3118)  loss_segments_2_unscaled: 0.0606 (0.0738)  loss_iou_2_unscaled: 0.3994 (0.4291)  time: 0.0674  data: 0.0012  max mem: 488
[11/28 15:52:27][INFO]: Epoch: [0]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 4.3559 (5.2273)  loss_ce: 0.4536 (0.6313)  loss_iou: 0.2122 (0.2175)  loss_ce_0: 0.3095 (0.5318)  loss_iou_0: 0.8911 (0.9388)  loss_ce_1: 0.3562 (0.5611)  loss_iou_1: 0.8761 (0.8864)  loss_ce_2: 0.3879 (0.6039)  loss_iou_2: 0.8249 (0.8565)  loss_ce_unscaled: 0.2268 (0.3156)  class_error_unscaled: 5.2632 (20.1700)  loss_segments_unscaled: 0.0643 (0.0725)  loss_iou_unscaled: 0.1061 (0.1088)  loss_ce_0_unscaled: 0.1547 (0.2659)  loss_segments_0_unscaled: 0.0696 (0.0834)  loss_iou_0_unscaled: 0.4455 (0.4694)  loss_ce_1_unscaled: 0.1781 (0.2805)  loss_segments_1_unscaled: 0.0708 (0.0772)  loss_iou_1_unscaled: 0.4380 (0.4432)  loss_ce_2_unscaled: 0.1940 (0.3019)  loss_segments_2_unscaled: 0.0650 (0.0736)  loss_iou_2_unscaled: 0.4124 (0.4283)  time: 0.0637  data: 0.0012  max mem: 488
[11/28 15:52:27][INFO]: Epoch: [0] Total time: 0:00:13 (0.0681 s / it)
[11/28 15:52:27][INFO]: Averaged stats:lr: 0.000200  loss: 4.3559 (5.2273)  loss_ce: 0.4536 (0.6313)  loss_iou: 0.2122 (0.2175)  loss_ce_0: 0.3095 (0.5318)  loss_iou_0: 0.8911 (0.9388)  loss_ce_1: 0.3562 (0.5611)  loss_iou_1: 0.8761 (0.8864)  loss_ce_2: 0.3879 (0.6039)  loss_iou_2: 0.8249 (0.8565)  loss_ce_unscaled: 0.2268 (0.3156)  class_error_unscaled: 5.2632 (20.1700)  loss_segments_unscaled: 0.0643 (0.0725)  loss_iou_unscaled: 0.1061 (0.1088)  loss_ce_0_unscaled: 0.1547 (0.2659)  loss_segments_0_unscaled: 0.0696 (0.0834)  loss_iou_0_unscaled: 0.4455 (0.4694)  loss_ce_1_unscaled: 0.1781 (0.2805)  loss_segments_1_unscaled: 0.0708 (0.0772)  loss_iou_1_unscaled: 0.4380 (0.4432)  loss_ce_2_unscaled: 0.1940 (0.3019)  loss_segments_2_unscaled: 0.0650 (0.0736)  loss_iou_2_unscaled: 0.4124 (0.4283)
[11/28 15:52:27][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 26.40it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:52:35][INFO]: mode=raw 106724 predictions from 210 videos
[11/28 15:52:38][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
49.23 43.21 33.09 21.27 10.61 31.48 raw epoch0
[11/28 15:52:38][INFO]: mAP_raw: 31.48
[11/28 15:52:38][INFO]: new best metric 0.3148@epoch0
[11/28 15:52:38][INFO]: lr=0.0002
[11/28 15:52:38][INFO]: lr=1e-05
[11/28 15:52:38][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:52:39][INFO]: Epoch: [1]  [  0/198]  eta: 0:01:00  lr: 0.000200  loss: 4.8459 (4.8459)  loss_ce: 0.5043 (0.5043)  loss_iou: 0.2444 (0.2444)  loss_ce_0: 0.3505 (0.3505)  loss_iou_0: 1.0067 (1.0067)  loss_ce_1: 0.4004 (0.4004)  loss_iou_1: 0.9743 (0.9743)  loss_ce_2: 0.4497 (0.4497)  loss_iou_2: 0.9156 (0.9156)  loss_ce_unscaled: 0.2522 (0.2522)  class_error_unscaled: 24.5614 (24.5614)  loss_segments_unscaled: 0.0407 (0.0407)  loss_iou_unscaled: 0.1222 (0.1222)  loss_ce_0_unscaled: 0.1752 (0.1752)  loss_segments_0_unscaled: 0.0560 (0.0560)  loss_iou_0_unscaled: 0.5033 (0.5033)  loss_ce_1_unscaled: 0.2002 (0.2002)  loss_segments_1_unscaled: 0.0486 (0.0486)  loss_iou_1_unscaled: 0.4871 (0.4871)  loss_ce_2_unscaled: 0.2248 (0.2248)  loss_segments_2_unscaled: 0.0490 (0.0490)  loss_iou_2_unscaled: 0.4578 (0.4578)  time: 0.3041  data: 0.1967  max mem: 488
[11/28 15:52:40][INFO]: Epoch: [1]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 3.9395 (4.0712)  loss_ce: 0.3813 (0.3907)  loss_iou: 0.2132 (0.2238)  loss_ce_0: 0.3004 (0.3060)  loss_iou_0: 0.7995 (0.8503)  loss_ce_1: 0.2837 (0.3045)  loss_iou_1: 0.7794 (0.8399)  loss_ce_2: 0.3261 (0.3406)  loss_iou_2: 0.7552 (0.8154)  loss_ce_unscaled: 0.1906 (0.1953)  class_error_unscaled: 3.7037 (5.7523)  loss_segments_unscaled: 0.0567 (0.0587)  loss_iou_unscaled: 0.1066 (0.1119)  loss_ce_0_unscaled: 0.1502 (0.1530)  loss_segments_0_unscaled: 0.0606 (0.0659)  loss_iou_0_unscaled: 0.3997 (0.4252)  loss_ce_1_unscaled: 0.1419 (0.1522)  loss_segments_1_unscaled: 0.0616 (0.0636)  loss_iou_1_unscaled: 0.3897 (0.4200)  loss_ce_2_unscaled: 0.1631 (0.1703)  loss_segments_2_unscaled: 0.0590 (0.0618)  loss_iou_2_unscaled: 0.3776 (0.4077)  time: 0.0693  data: 0.0011  max mem: 488
[11/28 15:52:41][INFO]: Epoch: [1]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 3.8600 (4.0103)  loss_ce: 0.3323 (0.3718)  loss_iou: 0.2186 (0.2238)  loss_ce_0: 0.2805 (0.2989)  loss_iou_0: 0.8456 (0.8464)  loss_ce_1: 0.2763 (0.2941)  loss_iou_1: 0.8093 (0.8372)  loss_ce_2: 0.3109 (0.3268)  loss_iou_2: 0.7876 (0.8113)  loss_ce_unscaled: 0.1661 (0.1859)  class_error_unscaled: 2.5641 (5.1281)  loss_segments_unscaled: 0.0665 (0.0620)  loss_iou_unscaled: 0.1093 (0.1119)  loss_ce_0_unscaled: 0.1403 (0.1494)  loss_segments_0_unscaled: 0.0664 (0.0674)  loss_iou_0_unscaled: 0.4228 (0.4232)  loss_ce_1_unscaled: 0.1381 (0.1470)  loss_segments_1_unscaled: 0.0701 (0.0665)  loss_iou_1_unscaled: 0.4047 (0.4186)  loss_ce_2_unscaled: 0.1554 (0.1634)  loss_segments_2_unscaled: 0.0667 (0.0641)  loss_iou_2_unscaled: 0.3938 (0.4056)  time: 0.0665  data: 0.0010  max mem: 488
[11/28 15:52:43][INFO]: Epoch: [1]  [ 60/198]  eta: 0:00:09  lr: 0.000200  loss: 3.7437 (3.9482)  loss_ce: 0.3085 (0.3533)  loss_iou: 0.2137 (0.2205)  loss_ce_0: 0.2737 (0.2915)  loss_iou_0: 0.8391 (0.8417)  loss_ce_1: 0.2603 (0.2870)  loss_iou_1: 0.7942 (0.8299)  loss_ce_2: 0.2864 (0.3130)  loss_iou_2: 0.7880 (0.8114)  loss_ce_unscaled: 0.1543 (0.1766)  class_error_unscaled: 5.4054 (5.1331)  loss_segments_unscaled: 0.0616 (0.0625)  loss_iou_unscaled: 0.1068 (0.1103)  loss_ce_0_unscaled: 0.1368 (0.1458)  loss_segments_0_unscaled: 0.0664 (0.0671)  loss_iou_0_unscaled: 0.4195 (0.4209)  loss_ce_1_unscaled: 0.1301 (0.1435)  loss_segments_1_unscaled: 0.0645 (0.0662)  loss_iou_1_unscaled: 0.3971 (0.4149)  loss_ce_2_unscaled: 0.1432 (0.1565)  loss_segments_2_unscaled: 0.0621 (0.0644)  loss_iou_2_unscaled: 0.3940 (0.4057)  time: 0.0650  data: 0.0012  max mem: 488
[11/28 15:52:44][INFO]: Epoch: [1]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 3.5034 (3.8605)  loss_ce: 0.2566 (0.3317)  loss_iou: 0.2064 (0.2187)  loss_ce_0: 0.2386 (0.2819)  loss_iou_0: 0.7783 (0.8318)  loss_ce_1: 0.2335 (0.2760)  loss_iou_1: 0.7530 (0.8188)  loss_ce_2: 0.2355 (0.2957)  loss_iou_2: 0.7614 (0.8060)  loss_ce_unscaled: 0.1283 (0.1658)  class_error_unscaled: 4.0816 (5.0659)  loss_segments_unscaled: 0.0624 (0.0629)  loss_iou_unscaled: 0.1032 (0.1094)  loss_ce_0_unscaled: 0.1193 (0.1409)  loss_segments_0_unscaled: 0.0606 (0.0664)  loss_iou_0_unscaled: 0.3891 (0.4159)  loss_ce_1_unscaled: 0.1167 (0.1380)  loss_segments_1_unscaled: 0.0596 (0.0657)  loss_iou_1_unscaled: 0.3765 (0.4094)  loss_ce_2_unscaled: 0.1177 (0.1478)  loss_segments_2_unscaled: 0.0653 (0.0648)  loss_iou_2_unscaled: 0.3807 (0.4030)  time: 0.0678  data: 0.0012  max mem: 488
[11/28 15:52:45][INFO]: Epoch: [1]  [100/198]  eta: 0:00:06  lr: 0.000200  loss: 3.7337 (3.8549)  loss_ce: 0.3129 (0.3273)  loss_iou: 0.2288 (0.2205)  loss_ce_0: 0.2971 (0.2864)  loss_iou_0: 0.7767 (0.8288)  loss_ce_1: 0.2574 (0.2767)  loss_iou_1: 0.7831 (0.8158)  loss_ce_2: 0.2758 (0.2937)  loss_iou_2: 0.7585 (0.8057)  loss_ce_unscaled: 0.1565 (0.1637)  class_error_unscaled: 3.2258 (4.9128)  loss_segments_unscaled: 0.0661 (0.0633)  loss_iou_unscaled: 0.1144 (0.1102)  loss_ce_0_unscaled: 0.1485 (0.1432)  loss_segments_0_unscaled: 0.0625 (0.0663)  loss_iou_0_unscaled: 0.3884 (0.4144)  loss_ce_1_unscaled: 0.1287 (0.1384)  loss_segments_1_unscaled: 0.0617 (0.0656)  loss_iou_1_unscaled: 0.3915 (0.4079)  loss_ce_2_unscaled: 0.1379 (0.1469)  loss_segments_2_unscaled: 0.0660 (0.0648)  loss_iou_2_unscaled: 0.3793 (0.4028)  time: 0.0657  data: 0.0011  max mem: 488
[11/28 15:52:47][INFO]: Epoch: [1]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 3.3948 (3.7909)  loss_ce: 0.2218 (0.3115)  loss_iou: 0.2109 (0.2203)  loss_ce_0: 0.2357 (0.2798)  loss_iou_0: 0.7678 (0.8222)  loss_ce_1: 0.2111 (0.2670)  loss_iou_1: 0.7467 (0.8088)  loss_ce_2: 0.2092 (0.2817)  loss_iou_2: 0.7507 (0.7996)  loss_ce_unscaled: 0.1109 (0.1557)  class_error_unscaled: 0.0000 (4.4485)  loss_segments_unscaled: 0.0623 (0.0634)  loss_iou_unscaled: 0.1055 (0.1101)  loss_ce_0_unscaled: 0.1178 (0.1399)  loss_segments_0_unscaled: 0.0657 (0.0663)  loss_iou_0_unscaled: 0.3839 (0.4111)  loss_ce_1_unscaled: 0.1056 (0.1335)  loss_segments_1_unscaled: 0.0630 (0.0654)  loss_iou_1_unscaled: 0.3733 (0.4044)  loss_ce_2_unscaled: 0.1046 (0.1408)  loss_segments_2_unscaled: 0.0616 (0.0647)  loss_iou_2_unscaled: 0.3754 (0.3998)  time: 0.0680  data: 0.0011  max mem: 488
[11/28 15:52:48][INFO]: Epoch: [1]  [140/198]  eta: 0:00:03  lr: 0.000200  loss: 3.6367 (3.7608)  loss_ce: 0.2457 (0.3034)  loss_iou: 0.2361 (0.2228)  loss_ce_0: 0.2632 (0.2780)  loss_iou_0: 0.8086 (0.8182)  loss_ce_1: 0.2422 (0.2646)  loss_iou_1: 0.7527 (0.8021)  loss_ce_2: 0.2320 (0.2768)  loss_iou_2: 0.7721 (0.7949)  loss_ce_unscaled: 0.1228 (0.1517)  class_error_unscaled: 1.8519 (4.2136)  loss_segments_unscaled: 0.0664 (0.0643)  loss_iou_unscaled: 0.1180 (0.1114)  loss_ce_0_unscaled: 0.1316 (0.1390)  loss_segments_0_unscaled: 0.0749 (0.0674)  loss_iou_0_unscaled: 0.4043 (0.4091)  loss_ce_1_unscaled: 0.1211 (0.1323)  loss_segments_1_unscaled: 0.0726 (0.0659)  loss_iou_1_unscaled: 0.3763 (0.4011)  loss_ce_2_unscaled: 0.1160 (0.1384)  loss_segments_2_unscaled: 0.0692 (0.0653)  loss_iou_2_unscaled: 0.3860 (0.3974)  time: 0.0675  data: 0.0012  max mem: 488
[11/28 15:52:49][INFO]: Epoch: [1]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 3.4524 (3.7262)  loss_ce: 0.2342 (0.2942)  loss_iou: 0.2174 (0.2234)  loss_ce_0: 0.2475 (0.2742)  loss_iou_0: 0.7945 (0.8156)  loss_ce_1: 0.2041 (0.2585)  loss_iou_1: 0.7807 (0.7990)  loss_ce_2: 0.2200 (0.2694)  loss_iou_2: 0.7715 (0.7918)  loss_ce_unscaled: 0.1171 (0.1471)  class_error_unscaled: 0.0000 (3.8590)  loss_segments_unscaled: 0.0601 (0.0637)  loss_iou_unscaled: 0.1087 (0.1117)  loss_ce_0_unscaled: 0.1237 (0.1371)  loss_segments_0_unscaled: 0.0594 (0.0666)  loss_iou_0_unscaled: 0.3972 (0.4078)  loss_ce_1_unscaled: 0.1020 (0.1292)  loss_segments_1_unscaled: 0.0589 (0.0652)  loss_iou_1_unscaled: 0.3903 (0.3995)  loss_ce_2_unscaled: 0.1100 (0.1347)  loss_segments_2_unscaled: 0.0602 (0.0647)  loss_iou_2_unscaled: 0.3857 (0.3959)  time: 0.0662  data: 0.0012  max mem: 488
[11/28 15:52:51][INFO]: Epoch: [1]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 3.3857 (3.6930)  loss_ce: 0.2128 (0.2878)  loss_iou: 0.2265 (0.2253)  loss_ce_0: 0.2259 (0.2697)  loss_iou_0: 0.7537 (0.8114)  loss_ce_1: 0.1929 (0.2535)  loss_iou_1: 0.7457 (0.7940)  loss_ce_2: 0.2014 (0.2646)  loss_iou_2: 0.7401 (0.7867)  loss_ce_unscaled: 0.1064 (0.1439)  class_error_unscaled: 1.8182 (3.6581)  loss_segments_unscaled: 0.0531 (0.0627)  loss_iou_unscaled: 0.1133 (0.1126)  loss_ce_0_unscaled: 0.1130 (0.1348)  loss_segments_0_unscaled: 0.0543 (0.0656)  loss_iou_0_unscaled: 0.3768 (0.4057)  loss_ce_1_unscaled: 0.0965 (0.1267)  loss_segments_1_unscaled: 0.0481 (0.0642)  loss_iou_1_unscaled: 0.3728 (0.3970)  loss_ce_2_unscaled: 0.1007 (0.1323)  loss_segments_2_unscaled: 0.0514 (0.0635)  loss_iou_2_unscaled: 0.3701 (0.3934)  time: 0.0669  data: 0.0011  max mem: 488
[11/28 15:52:52][INFO]: Epoch: [1]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 3.5247 (3.6787)  loss_ce: 0.2165 (0.2818)  loss_iou: 0.2212 (0.2250)  loss_ce_0: 0.2120 (0.2657)  loss_iou_0: 0.8365 (0.8134)  loss_ce_1: 0.1929 (0.2489)  loss_iou_1: 0.8176 (0.7957)  loss_ce_2: 0.2047 (0.2600)  loss_iou_2: 0.8124 (0.7882)  loss_ce_unscaled: 0.1083 (0.1409)  class_error_unscaled: 1.5625 (3.5208)  loss_segments_unscaled: 0.0621 (0.0631)  loss_iou_unscaled: 0.1106 (0.1125)  loss_ce_0_unscaled: 0.1060 (0.1328)  loss_segments_0_unscaled: 0.0671 (0.0660)  loss_iou_0_unscaled: 0.4183 (0.4067)  loss_ce_1_unscaled: 0.0965 (0.1245)  loss_segments_1_unscaled: 0.0630 (0.0646)  loss_iou_1_unscaled: 0.4088 (0.3979)  loss_ce_2_unscaled: 0.1023 (0.1300)  loss_segments_2_unscaled: 0.0613 (0.0639)  loss_iou_2_unscaled: 0.4062 (0.3941)  time: 0.0658  data: 0.0012  max mem: 488
[11/28 15:52:52][INFO]: Epoch: [1] Total time: 0:00:13 (0.0684 s / it)
[11/28 15:52:52][INFO]: Averaged stats:lr: 0.000200  loss: 3.5247 (3.6787)  loss_ce: 0.2165 (0.2818)  loss_iou: 0.2212 (0.2250)  loss_ce_0: 0.2120 (0.2657)  loss_iou_0: 0.8365 (0.8134)  loss_ce_1: 0.1929 (0.2489)  loss_iou_1: 0.8176 (0.7957)  loss_ce_2: 0.2047 (0.2600)  loss_iou_2: 0.8124 (0.7882)  loss_ce_unscaled: 0.1083 (0.1409)  class_error_unscaled: 1.5625 (3.5208)  loss_segments_unscaled: 0.0621 (0.0631)  loss_iou_unscaled: 0.1106 (0.1125)  loss_ce_0_unscaled: 0.1060 (0.1328)  loss_segments_0_unscaled: 0.0671 (0.0660)  loss_iou_0_unscaled: 0.4183 (0.4067)  loss_ce_1_unscaled: 0.0965 (0.1245)  loss_segments_1_unscaled: 0.0630 (0.0646)  loss_iou_1_unscaled: 0.4088 (0.3979)  loss_ce_2_unscaled: 0.1023 (0.1300)  loss_segments_2_unscaled: 0.0613 (0.0639)  loss_iou_2_unscaled: 0.4062 (0.3941)
[11/28 15:52:52][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 26.09it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:53:00][INFO]: mode=raw 116464 predictions from 210 videos
[11/28 15:53:04][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
64.12 55.61 42.78 27.60 13.80 40.78 raw epoch1
[11/28 15:53:04][INFO]: mAP_raw: 40.78
[11/28 15:53:04][INFO]: new best metric 0.4078@epoch1
[11/28 15:53:04][INFO]: lr=0.0002
[11/28 15:53:04][INFO]: lr=1e-05
[11/28 15:53:04][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:53:04][INFO]: Epoch: [2]  [  0/198]  eta: 0:00:55  lr: 0.000200  loss: 3.5392 (3.5392)  loss_ce: 0.2548 (0.2548)  loss_iou: 0.2804 (0.2804)  loss_ce_0: 0.2046 (0.2046)  loss_iou_0: 0.8203 (0.8203)  loss_ce_1: 0.2108 (0.2108)  loss_iou_1: 0.7752 (0.7752)  loss_ce_2: 0.2404 (0.2404)  loss_iou_2: 0.7528 (0.7528)  loss_ce_unscaled: 0.1274 (0.1274)  class_error_unscaled: 3.7736 (3.7736)  loss_segments_unscaled: 0.0519 (0.0519)  loss_iou_unscaled: 0.1402 (0.1402)  loss_ce_0_unscaled: 0.1023 (0.1023)  loss_segments_0_unscaled: 0.0534 (0.0534)  loss_iou_0_unscaled: 0.4102 (0.4102)  loss_ce_1_unscaled: 0.1054 (0.1054)  loss_segments_1_unscaled: 0.0510 (0.0510)  loss_iou_1_unscaled: 0.3876 (0.3876)  loss_ce_2_unscaled: 0.1202 (0.1202)  loss_segments_2_unscaled: 0.0517 (0.0517)  loss_iou_2_unscaled: 0.3764 (0.3764)  time: 0.2796  data: 0.1894  max mem: 488
[11/28 15:53:05][INFO]: Epoch: [2]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 3.1652 (3.2619)  loss_ce: 0.1916 (0.2033)  loss_iou: 0.2173 (0.2359)  loss_ce_0: 0.2077 (0.2210)  loss_iou_0: 0.7649 (0.7565)  loss_ce_1: 0.1728 (0.1969)  loss_iou_1: 0.7110 (0.7256)  loss_ce_2: 0.1737 (0.1950)  loss_iou_2: 0.7126 (0.7276)  loss_ce_unscaled: 0.0958 (0.1017)  class_error_unscaled: 0.0000 (1.0280)  loss_segments_unscaled: 0.0565 (0.0586)  loss_iou_unscaled: 0.1087 (0.1180)  loss_ce_0_unscaled: 0.1038 (0.1105)  loss_segments_0_unscaled: 0.0590 (0.0609)  loss_iou_0_unscaled: 0.3824 (0.3783)  loss_ce_1_unscaled: 0.0864 (0.0985)  loss_segments_1_unscaled: 0.0562 (0.0594)  loss_iou_1_unscaled: 0.3555 (0.3628)  loss_ce_2_unscaled: 0.0868 (0.0975)  loss_segments_2_unscaled: 0.0603 (0.0600)  loss_iou_2_unscaled: 0.3563 (0.3638)  time: 0.0706  data: 0.0011  max mem: 488
[11/28 15:53:07][INFO]: Epoch: [2]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 3.3476 (3.3038)  loss_ce: 0.2316 (0.2158)  loss_iou: 0.2147 (0.2301)  loss_ce_0: 0.2023 (0.2177)  loss_iou_0: 0.7596 (0.7607)  loss_ce_1: 0.1868 (0.1978)  loss_iou_1: 0.7424 (0.7420)  loss_ce_2: 0.1779 (0.2009)  loss_iou_2: 0.7573 (0.7388)  loss_ce_unscaled: 0.1158 (0.1079)  class_error_unscaled: 0.0000 (1.4330)  loss_segments_unscaled: 0.0566 (0.0583)  loss_iou_unscaled: 0.1074 (0.1151)  loss_ce_0_unscaled: 0.1011 (0.1088)  loss_segments_0_unscaled: 0.0577 (0.0612)  loss_iou_0_unscaled: 0.3798 (0.3804)  loss_ce_1_unscaled: 0.0934 (0.0989)  loss_segments_1_unscaled: 0.0586 (0.0601)  loss_iou_1_unscaled: 0.3712 (0.3710)  loss_ce_2_unscaled: 0.0889 (0.1004)  loss_segments_2_unscaled: 0.0573 (0.0596)  loss_iou_2_unscaled: 0.3787 (0.3694)  time: 0.0681  data: 0.0011  max mem: 488
[11/28 15:53:08][INFO]: Epoch: [2]  [ 60/198]  eta: 0:00:09  lr: 0.000200  loss: 3.1997 (3.3043)  loss_ce: 0.2021 (0.2140)  loss_iou: 0.2243 (0.2298)  loss_ce_0: 0.2118 (0.2204)  loss_iou_0: 0.7623 (0.7617)  loss_ce_1: 0.1807 (0.1959)  loss_iou_1: 0.7434 (0.7437)  loss_ce_2: 0.1812 (0.1982)  loss_iou_2: 0.7359 (0.7405)  loss_ce_unscaled: 0.1010 (0.1070)  class_error_unscaled: 2.1739 (1.5438)  loss_segments_unscaled: 0.0503 (0.0566)  loss_iou_unscaled: 0.1122 (0.1149)  loss_ce_0_unscaled: 0.1059 (0.1102)  loss_segments_0_unscaled: 0.0543 (0.0597)  loss_iou_0_unscaled: 0.3811 (0.3809)  loss_ce_1_unscaled: 0.0904 (0.0980)  loss_segments_1_unscaled: 0.0515 (0.0584)  loss_iou_1_unscaled: 0.3717 (0.3719)  loss_ce_2_unscaled: 0.0906 (0.0991)  loss_segments_2_unscaled: 0.0521 (0.0578)  loss_iou_2_unscaled: 0.3680 (0.3703)  time: 0.0665  data: 0.0011  max mem: 488
[11/28 15:53:09][INFO]: Epoch: [2]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 3.2133 (3.2873)  loss_ce: 0.1902 (0.2103)  loss_iou: 0.2038 (0.2248)  loss_ce_0: 0.2061 (0.2167)  loss_iou_0: 0.7672 (0.7641)  loss_ce_1: 0.1744 (0.1928)  loss_iou_1: 0.7470 (0.7441)  loss_ce_2: 0.1854 (0.1950)  loss_iou_2: 0.7340 (0.7394)  loss_ce_unscaled: 0.0951 (0.1051)  class_error_unscaled: 0.0000 (1.4941)  loss_segments_unscaled: 0.0550 (0.0565)  loss_iou_unscaled: 0.1019 (0.1124)  loss_ce_0_unscaled: 0.1030 (0.1083)  loss_segments_0_unscaled: 0.0604 (0.0601)  loss_iou_0_unscaled: 0.3836 (0.3821)  loss_ce_1_unscaled: 0.0872 (0.0964)  loss_segments_1_unscaled: 0.0579 (0.0582)  loss_iou_1_unscaled: 0.3735 (0.3721)  loss_ce_2_unscaled: 0.0927 (0.0975)  loss_segments_2_unscaled: 0.0556 (0.0575)  loss_iou_2_unscaled: 0.3670 (0.3697)  time: 0.0668  data: 0.0012  max mem: 488
[11/28 15:53:11][INFO]: Epoch: [2]  [100/198]  eta: 0:00:06  lr: 0.000200  loss: 3.3537 (3.2975)  loss_ce: 0.1743 (0.2050)  loss_iou: 0.2287 (0.2267)  loss_ce_0: 0.1897 (0.2141)  loss_iou_0: 0.8072 (0.7718)  loss_ce_1: 0.1653 (0.1898)  loss_iou_1: 0.7772 (0.7523)  loss_ce_2: 0.1716 (0.1913)  loss_iou_2: 0.7673 (0.7467)  loss_ce_unscaled: 0.0871 (0.1025)  class_error_unscaled: 0.0000 (1.4408)  loss_segments_unscaled: 0.0602 (0.0569)  loss_iou_unscaled: 0.1144 (0.1133)  loss_ce_0_unscaled: 0.0949 (0.1070)  loss_segments_0_unscaled: 0.0611 (0.0604)  loss_iou_0_unscaled: 0.4036 (0.3859)  loss_ce_1_unscaled: 0.0826 (0.0949)  loss_segments_1_unscaled: 0.0595 (0.0585)  loss_iou_1_unscaled: 0.3886 (0.3761)  loss_ce_2_unscaled: 0.0858 (0.0956)  loss_segments_2_unscaled: 0.0594 (0.0579)  loss_iou_2_unscaled: 0.3837 (0.3733)  time: 0.0662  data: 0.0011  max mem: 488
[11/28 15:53:12][INFO]: Epoch: [2]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 3.1744 (3.2916)  loss_ce: 0.1744 (0.2019)  loss_iou: 0.2161 (0.2267)  loss_ce_0: 0.1947 (0.2115)  loss_iou_0: 0.7526 (0.7741)  loss_ce_1: 0.1517 (0.1867)  loss_iou_1: 0.7370 (0.7536)  loss_ce_2: 0.1642 (0.1883)  loss_iou_2: 0.7578 (0.7487)  loss_ce_unscaled: 0.0872 (0.1010)  class_error_unscaled: 0.0000 (1.3243)  loss_segments_unscaled: 0.0542 (0.0570)  loss_iou_unscaled: 0.1080 (0.1134)  loss_ce_0_unscaled: 0.0974 (0.1058)  loss_segments_0_unscaled: 0.0566 (0.0603)  loss_iou_0_unscaled: 0.3763 (0.3870)  loss_ce_1_unscaled: 0.0758 (0.0933)  loss_segments_1_unscaled: 0.0580 (0.0586)  loss_iou_1_unscaled: 0.3685 (0.3768)  loss_ce_2_unscaled: 0.0821 (0.0942)  loss_segments_2_unscaled: 0.0552 (0.0579)  loss_iou_2_unscaled: 0.3789 (0.3744)  time: 0.0682  data: 0.0013  max mem: 488
[11/28 15:53:13][INFO]: Epoch: [2]  [140/198]  eta: 0:00:03  lr: 0.000200  loss: 2.9150 (3.2445)  loss_ce: 0.1403 (0.1962)  loss_iou: 0.2336 (0.2276)  loss_ce_0: 0.1836 (0.2084)  loss_iou_0: 0.6939 (0.7638)  loss_ce_1: 0.1560 (0.1831)  loss_iou_1: 0.6783 (0.7427)  loss_ce_2: 0.1479 (0.1843)  loss_iou_2: 0.6742 (0.7382)  loss_ce_unscaled: 0.0702 (0.0981)  class_error_unscaled: 0.0000 (1.2626)  loss_segments_unscaled: 0.0499 (0.0564)  loss_iou_unscaled: 0.1168 (0.1138)  loss_ce_0_unscaled: 0.0918 (0.1042)  loss_segments_0_unscaled: 0.0539 (0.0595)  loss_iou_0_unscaled: 0.3469 (0.3819)  loss_ce_1_unscaled: 0.0780 (0.0916)  loss_segments_1_unscaled: 0.0515 (0.0578)  loss_iou_1_unscaled: 0.3392 (0.3714)  loss_ce_2_unscaled: 0.0739 (0.0922)  loss_segments_2_unscaled: 0.0499 (0.0573)  loss_iou_2_unscaled: 0.3371 (0.3691)  time: 0.0644  data: 0.0011  max mem: 488
[11/28 15:53:15][INFO]: Epoch: [2]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 3.0778 (3.2281)  loss_ce: 0.1572 (0.1935)  loss_iou: 0.2326 (0.2290)  loss_ce_0: 0.1637 (0.2056)  loss_iou_0: 0.7067 (0.7628)  loss_ce_1: 0.1503 (0.1808)  loss_iou_1: 0.6843 (0.7399)  loss_ce_2: 0.1432 (0.1817)  loss_iou_2: 0.6774 (0.7348)  loss_ce_unscaled: 0.0786 (0.0967)  class_error_unscaled: 0.0000 (1.2664)  loss_segments_unscaled: 0.0569 (0.0564)  loss_iou_unscaled: 0.1163 (0.1145)  loss_ce_0_unscaled: 0.0819 (0.1028)  loss_segments_0_unscaled: 0.0593 (0.0596)  loss_iou_0_unscaled: 0.3533 (0.3814)  loss_ce_1_unscaled: 0.0752 (0.0904)  loss_segments_1_unscaled: 0.0597 (0.0578)  loss_iou_1_unscaled: 0.3421 (0.3700)  loss_ce_2_unscaled: 0.0716 (0.0909)  loss_segments_2_unscaled: 0.0576 (0.0573)  loss_iou_2_unscaled: 0.3387 (0.3674)  time: 0.0689  data: 0.0012  max mem: 488
[11/28 15:53:16][INFO]: Epoch: [2]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 2.8067 (3.1968)  loss_ce: 0.1554 (0.1904)  loss_iou: 0.2447 (0.2302)  loss_ce_0: 0.1766 (0.2032)  loss_iou_0: 0.6722 (0.7555)  loss_ce_1: 0.1398 (0.1783)  loss_iou_1: 0.6256 (0.7319)  loss_ce_2: 0.1495 (0.1791)  loss_iou_2: 0.6331 (0.7283)  loss_ce_unscaled: 0.0777 (0.0952)  class_error_unscaled: 0.0000 (1.1725)  loss_segments_unscaled: 0.0551 (0.0562)  loss_iou_unscaled: 0.1223 (0.1151)  loss_ce_0_unscaled: 0.0883 (0.1016)  loss_segments_0_unscaled: 0.0554 (0.0592)  loss_iou_0_unscaled: 0.3361 (0.3777)  loss_ce_1_unscaled: 0.0699 (0.0892)  loss_segments_1_unscaled: 0.0538 (0.0574)  loss_iou_1_unscaled: 0.3128 (0.3659)  loss_ce_2_unscaled: 0.0747 (0.0895)  loss_segments_2_unscaled: 0.0540 (0.0570)  loss_iou_2_unscaled: 0.3165 (0.3641)  time: 0.0655  data: 0.0012  max mem: 488
[11/28 15:53:17][INFO]: Epoch: [2]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 3.0355 (3.1950)  loss_ce: 0.1820 (0.1910)  loss_iou: 0.2381 (0.2304)  loss_ce_0: 0.2124 (0.2050)  loss_iou_0: 0.7033 (0.7537)  loss_ce_1: 0.1698 (0.1798)  loss_iou_1: 0.6791 (0.7290)  loss_ce_2: 0.1631 (0.1801)  loss_iou_2: 0.6815 (0.7261)  loss_ce_unscaled: 0.0910 (0.0955)  class_error_unscaled: 1.4286 (1.2241)  loss_segments_unscaled: 0.0505 (0.0559)  loss_iou_unscaled: 0.1191 (0.1152)  loss_ce_0_unscaled: 0.1062 (0.1025)  loss_segments_0_unscaled: 0.0534 (0.0587)  loss_iou_0_unscaled: 0.3517 (0.3768)  loss_ce_1_unscaled: 0.0849 (0.0899)  loss_segments_1_unscaled: 0.0515 (0.0569)  loss_iou_1_unscaled: 0.3395 (0.3645)  loss_ce_2_unscaled: 0.0816 (0.0900)  loss_segments_2_unscaled: 0.0519 (0.0565)  loss_iou_2_unscaled: 0.3407 (0.3630)  time: 0.0617  data: 0.0011  max mem: 488
[11/28 15:53:17][INFO]: Epoch: [2] Total time: 0:00:13 (0.0681 s / it)
[11/28 15:53:17][INFO]: Averaged stats:lr: 0.000200  loss: 3.0355 (3.1950)  loss_ce: 0.1820 (0.1910)  loss_iou: 0.2381 (0.2304)  loss_ce_0: 0.2124 (0.2050)  loss_iou_0: 0.7033 (0.7537)  loss_ce_1: 0.1698 (0.1798)  loss_iou_1: 0.6791 (0.7290)  loss_ce_2: 0.1631 (0.1801)  loss_iou_2: 0.6815 (0.7261)  loss_ce_unscaled: 0.0910 (0.0955)  class_error_unscaled: 1.4286 (1.2241)  loss_segments_unscaled: 0.0505 (0.0559)  loss_iou_unscaled: 0.1191 (0.1152)  loss_ce_0_unscaled: 0.1062 (0.1025)  loss_segments_0_unscaled: 0.0534 (0.0587)  loss_iou_0_unscaled: 0.3517 (0.3768)  loss_ce_1_unscaled: 0.0849 (0.0899)  loss_segments_1_unscaled: 0.0515 (0.0569)  loss_iou_1_unscaled: 0.3395 (0.3645)  loss_ce_2_unscaled: 0.0816 (0.0900)  loss_segments_2_unscaled: 0.0519 (0.0565)  loss_iou_2_unscaled: 0.3407 (0.3630)
[11/28 15:53:17][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 26.79it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:53:25][INFO]: mode=raw 124958 predictions from 210 videos
[11/28 15:53:29][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
65.80 58.73 45.91 31.05 17.13 43.72 raw epoch2
[11/28 15:53:29][INFO]: mAP_raw: 43.72
[11/28 15:53:29][INFO]: new best metric 0.4372@epoch2
[11/28 15:53:29][INFO]: lr=0.0002
[11/28 15:53:29][INFO]: lr=1e-05
[11/28 15:53:29][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:53:29][INFO]: Epoch: [3]  [  0/198]  eta: 0:00:56  lr: 0.000200  loss: 2.8626 (2.8626)  loss_ce: 0.1406 (0.1406)  loss_iou: 0.2048 (0.2048)  loss_ce_0: 0.1320 (0.1320)  loss_iou_0: 0.7726 (0.7726)  loss_ce_1: 0.1180 (0.1180)  loss_iou_1: 0.6807 (0.6807)  loss_ce_2: 0.1195 (0.1195)  loss_iou_2: 0.6944 (0.6944)  loss_ce_unscaled: 0.0703 (0.0703)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0358 (0.0358)  loss_iou_unscaled: 0.1024 (0.1024)  loss_ce_0_unscaled: 0.0660 (0.0660)  loss_segments_0_unscaled: 0.0369 (0.0369)  loss_iou_0_unscaled: 0.3863 (0.3863)  loss_ce_1_unscaled: 0.0590 (0.0590)  loss_segments_1_unscaled: 0.0361 (0.0361)  loss_iou_1_unscaled: 0.3404 (0.3404)  loss_ce_2_unscaled: 0.0597 (0.0597)  loss_segments_2_unscaled: 0.0357 (0.0357)  loss_iou_2_unscaled: 0.3472 (0.3472)  time: 0.2841  data: 0.1931  max mem: 488
[11/28 15:53:31][INFO]: Epoch: [3]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 3.1546 (3.1980)  loss_ce: 0.1616 (0.1800)  loss_iou: 0.2417 (0.2495)  loss_ce_0: 0.1864 (0.1965)  loss_iou_0: 0.7614 (0.7659)  loss_ce_1: 0.1558 (0.1718)  loss_iou_1: 0.7229 (0.7324)  loss_ce_2: 0.1607 (0.1732)  loss_iou_2: 0.7224 (0.7287)  loss_ce_unscaled: 0.0808 (0.0900)  class_error_unscaled: 0.0000 (1.4519)  loss_segments_unscaled: 0.0579 (0.0578)  loss_iou_unscaled: 0.1208 (0.1247)  loss_ce_0_unscaled: 0.0932 (0.0983)  loss_segments_0_unscaled: 0.0596 (0.0603)  loss_iou_0_unscaled: 0.3807 (0.3830)  loss_ce_1_unscaled: 0.0779 (0.0859)  loss_segments_1_unscaled: 0.0571 (0.0578)  loss_iou_1_unscaled: 0.3614 (0.3662)  loss_ce_2_unscaled: 0.0803 (0.0866)  loss_segments_2_unscaled: 0.0580 (0.0575)  loss_iou_2_unscaled: 0.3612 (0.3644)  time: 0.0692  data: 0.0012  max mem: 488
[11/28 15:53:32][INFO]: Epoch: [3]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 2.8116 (3.0243)  loss_ce: 0.1466 (0.1654)  loss_iou: 0.2139 (0.2328)  loss_ce_0: 0.1586 (0.1842)  loss_iou_0: 0.6809 (0.7312)  loss_ce_1: 0.1356 (0.1588)  loss_iou_1: 0.6276 (0.6998)  loss_ce_2: 0.1283 (0.1577)  loss_iou_2: 0.6251 (0.6943)  loss_ce_unscaled: 0.0733 (0.0827)  class_error_unscaled: 0.0000 (1.2335)  loss_segments_unscaled: 0.0532 (0.0558)  loss_iou_unscaled: 0.1070 (0.1164)  loss_ce_0_unscaled: 0.0793 (0.0921)  loss_segments_0_unscaled: 0.0541 (0.0578)  loss_iou_0_unscaled: 0.3404 (0.3656)  loss_ce_1_unscaled: 0.0678 (0.0794)  loss_segments_1_unscaled: 0.0513 (0.0560)  loss_iou_1_unscaled: 0.3138 (0.3499)  loss_ce_2_unscaled: 0.0641 (0.0789)  loss_segments_2_unscaled: 0.0540 (0.0558)  loss_iou_2_unscaled: 0.3126 (0.3472)  time: 0.0688  data: 0.0011  max mem: 488
[11/28 15:53:33][INFO]: Epoch: [3]  [ 60/198]  eta: 0:00:10  lr: 0.000200  loss: 2.9912 (3.0170)  loss_ce: 0.1550 (0.1629)  loss_iou: 0.2132 (0.2277)  loss_ce_0: 0.1658 (0.1784)  loss_iou_0: 0.7565 (0.7381)  loss_ce_1: 0.1300 (0.1531)  loss_iou_1: 0.7031 (0.7034)  loss_ce_2: 0.1418 (0.1536)  loss_iou_2: 0.6858 (0.6998)  loss_ce_unscaled: 0.0775 (0.0814)  class_error_unscaled: 0.0000 (0.9389)  loss_segments_unscaled: 0.0551 (0.0556)  loss_iou_unscaled: 0.1066 (0.1139)  loss_ce_0_unscaled: 0.0829 (0.0892)  loss_segments_0_unscaled: 0.0567 (0.0587)  loss_iou_0_unscaled: 0.3783 (0.3691)  loss_ce_1_unscaled: 0.0650 (0.0765)  loss_segments_1_unscaled: 0.0565 (0.0564)  loss_iou_1_unscaled: 0.3515 (0.3517)  loss_ce_2_unscaled: 0.0709 (0.0768)  loss_segments_2_unscaled: 0.0551 (0.0562)  loss_iou_2_unscaled: 0.3429 (0.3499)  time: 0.0699  data: 0.0012  max mem: 488
[11/28 15:53:35][INFO]: Epoch: [3]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 2.9130 (2.9909)  loss_ce: 0.1507 (0.1599)  loss_iou: 0.2275 (0.2291)  loss_ce_0: 0.1689 (0.1792)  loss_iou_0: 0.6853 (0.7297)  loss_ce_1: 0.1437 (0.1534)  loss_iou_1: 0.6486 (0.6959)  loss_ce_2: 0.1400 (0.1521)  loss_iou_2: 0.6650 (0.6916)  loss_ce_unscaled: 0.0753 (0.0799)  class_error_unscaled: 0.0000 (1.0845)  loss_segments_unscaled: 0.0551 (0.0555)  loss_iou_unscaled: 0.1138 (0.1145)  loss_ce_0_unscaled: 0.0844 (0.0896)  loss_segments_0_unscaled: 0.0547 (0.0583)  loss_iou_0_unscaled: 0.3426 (0.3648)  loss_ce_1_unscaled: 0.0718 (0.0767)  loss_segments_1_unscaled: 0.0520 (0.0563)  loss_iou_1_unscaled: 0.3243 (0.3480)  loss_ce_2_unscaled: 0.0700 (0.0761)  loss_segments_2_unscaled: 0.0560 (0.0560)  loss_iou_2_unscaled: 0.3325 (0.3458)  time: 0.0701  data: 0.0011  max mem: 488
[11/28 15:53:36][INFO]: Epoch: [3]  [100/198]  eta: 0:00:07  lr: 0.000200  loss: 2.9260 (3.0011)  loss_ce: 0.1674 (0.1615)  loss_iou: 0.2318 (0.2296)  loss_ce_0: 0.1841 (0.1818)  loss_iou_0: 0.6697 (0.7283)  loss_ce_1: 0.1714 (0.1563)  loss_iou_1: 0.6475 (0.6966)  loss_ce_2: 0.1622 (0.1548)  loss_iou_2: 0.6622 (0.6923)  loss_ce_unscaled: 0.0837 (0.0807)  class_error_unscaled: 0.0000 (0.9928)  loss_segments_unscaled: 0.0513 (0.0550)  loss_iou_unscaled: 0.1159 (0.1148)  loss_ce_0_unscaled: 0.0920 (0.0909)  loss_segments_0_unscaled: 0.0520 (0.0580)  loss_iou_0_unscaled: 0.3348 (0.3641)  loss_ce_1_unscaled: 0.0857 (0.0782)  loss_segments_1_unscaled: 0.0509 (0.0559)  loss_iou_1_unscaled: 0.3238 (0.3483)  loss_ce_2_unscaled: 0.0811 (0.0774)  loss_segments_2_unscaled: 0.0487 (0.0555)  loss_iou_2_unscaled: 0.3311 (0.3462)  time: 0.0711  data: 0.0012  max mem: 488
[11/28 15:53:38][INFO]: Epoch: [3]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 2.9070 (2.9966)  loss_ce: 0.1628 (0.1633)  loss_iou: 0.2296 (0.2310)  loss_ce_0: 0.1708 (0.1827)  loss_iou_0: 0.7005 (0.7244)  loss_ce_1: 0.1574 (0.1570)  loss_iou_1: 0.6612 (0.6931)  loss_ce_2: 0.1500 (0.1556)  loss_iou_2: 0.6632 (0.6895)  loss_ce_unscaled: 0.0814 (0.0817)  class_error_unscaled: 0.0000 (0.9492)  loss_segments_unscaled: 0.0481 (0.0544)  loss_iou_unscaled: 0.1148 (0.1155)  loss_ce_0_unscaled: 0.0854 (0.0914)  loss_segments_0_unscaled: 0.0484 (0.0572)  loss_iou_0_unscaled: 0.3502 (0.3622)  loss_ce_1_unscaled: 0.0787 (0.0785)  loss_segments_1_unscaled: 0.0469 (0.0552)  loss_iou_1_unscaled: 0.3306 (0.3465)  loss_ce_2_unscaled: 0.0750 (0.0778)  loss_segments_2_unscaled: 0.0486 (0.0548)  loss_iou_2_unscaled: 0.3316 (0.3447)  time: 0.0683  data: 0.0012  max mem: 488
[11/28 15:53:39][INFO]: Epoch: [3]  [140/198]  eta: 0:00:04  lr: 0.000200  loss: 2.8668 (2.9927)  loss_ce: 0.1494 (0.1625)  loss_iou: 0.2359 (0.2326)  loss_ce_0: 0.1669 (0.1815)  loss_iou_0: 0.7065 (0.7239)  loss_ce_1: 0.1460 (0.1567)  loss_iou_1: 0.6734 (0.6923)  loss_ce_2: 0.1476 (0.1552)  loss_iou_2: 0.6601 (0.6880)  loss_ce_unscaled: 0.0747 (0.0812)  class_error_unscaled: 0.0000 (0.9533)  loss_segments_unscaled: 0.0477 (0.0540)  loss_iou_unscaled: 0.1179 (0.1163)  loss_ce_0_unscaled: 0.0834 (0.0908)  loss_segments_0_unscaled: 0.0490 (0.0568)  loss_iou_0_unscaled: 0.3533 (0.3620)  loss_ce_1_unscaled: 0.0730 (0.0783)  loss_segments_1_unscaled: 0.0476 (0.0548)  loss_iou_1_unscaled: 0.3367 (0.3461)  loss_ce_2_unscaled: 0.0738 (0.0776)  loss_segments_2_unscaled: 0.0486 (0.0544)  loss_iou_2_unscaled: 0.3300 (0.3440)  time: 0.0691  data: 0.0012  max mem: 488
[11/28 15:53:40][INFO]: Epoch: [3]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 3.0559 (2.9822)  loss_ce: 0.1482 (0.1609)  loss_iou: 0.2325 (0.2328)  loss_ce_0: 0.1617 (0.1801)  loss_iou_0: 0.6861 (0.7212)  loss_ce_1: 0.1332 (0.1550)  loss_iou_1: 0.7040 (0.6913)  loss_ce_2: 0.1384 (0.1534)  loss_iou_2: 0.7062 (0.6876)  loss_ce_unscaled: 0.0741 (0.0805)  class_error_unscaled: 0.0000 (0.9243)  loss_segments_unscaled: 0.0480 (0.0534)  loss_iou_unscaled: 0.1162 (0.1164)  loss_ce_0_unscaled: 0.0809 (0.0900)  loss_segments_0_unscaled: 0.0515 (0.0563)  loss_iou_0_unscaled: 0.3430 (0.3606)  loss_ce_1_unscaled: 0.0666 (0.0775)  loss_segments_1_unscaled: 0.0478 (0.0543)  loss_iou_1_unscaled: 0.3520 (0.3457)  loss_ce_2_unscaled: 0.0692 (0.0767)  loss_segments_2_unscaled: 0.0479 (0.0539)  loss_iou_2_unscaled: 0.3531 (0.3438)  time: 0.0685  data: 0.0013  max mem: 488
[11/28 15:53:42][INFO]: Epoch: [3]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 2.8452 (2.9776)  loss_ce: 0.1347 (0.1592)  loss_iou: 0.2260 (0.2321)  loss_ce_0: 0.1692 (0.1801)  loss_iou_0: 0.6728 (0.7196)  loss_ce_1: 0.1460 (0.1548)  loss_iou_1: 0.6691 (0.6914)  loss_ce_2: 0.1314 (0.1523)  loss_iou_2: 0.6832 (0.6881)  loss_ce_unscaled: 0.0674 (0.0796)  class_error_unscaled: 0.0000 (0.8703)  loss_segments_unscaled: 0.0491 (0.0533)  loss_iou_unscaled: 0.1130 (0.1161)  loss_ce_0_unscaled: 0.0846 (0.0901)  loss_segments_0_unscaled: 0.0544 (0.0562)  loss_iou_0_unscaled: 0.3364 (0.3598)  loss_ce_1_unscaled: 0.0730 (0.0774)  loss_segments_1_unscaled: 0.0510 (0.0541)  loss_iou_1_unscaled: 0.3346 (0.3457)  loss_ce_2_unscaled: 0.0657 (0.0761)  loss_segments_2_unscaled: 0.0531 (0.0539)  loss_iou_2_unscaled: 0.3416 (0.3441)  time: 0.0677  data: 0.0012  max mem: 488
[11/28 15:53:43][INFO]: Epoch: [3]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 2.7561 (2.9640)  loss_ce: 0.1228 (0.1573)  loss_iou: 0.2311 (0.2322)  loss_ce_0: 0.1517 (0.1789)  loss_iou_0: 0.6595 (0.7173)  loss_ce_1: 0.1215 (0.1534)  loss_iou_1: 0.6510 (0.6887)  loss_ce_2: 0.1184 (0.1506)  loss_iou_2: 0.6550 (0.6855)  loss_ce_unscaled: 0.0614 (0.0787)  class_error_unscaled: 0.0000 (0.8268)  loss_segments_unscaled: 0.0429 (0.0526)  loss_iou_unscaled: 0.1156 (0.1161)  loss_ce_0_unscaled: 0.0758 (0.0894)  loss_segments_0_unscaled: 0.0471 (0.0556)  loss_iou_0_unscaled: 0.3297 (0.3587)  loss_ce_1_unscaled: 0.0607 (0.0767)  loss_segments_1_unscaled: 0.0446 (0.0535)  loss_iou_1_unscaled: 0.3255 (0.3444)  loss_ce_2_unscaled: 0.0592 (0.0753)  loss_segments_2_unscaled: 0.0441 (0.0533)  loss_iou_2_unscaled: 0.3275 (0.3428)  time: 0.0651  data: 0.0012  max mem: 488
[11/28 15:53:43][INFO]: Epoch: [3] Total time: 0:00:13 (0.0702 s / it)
[11/28 15:53:43][INFO]: Averaged stats:lr: 0.000200  loss: 2.7561 (2.9640)  loss_ce: 0.1228 (0.1573)  loss_iou: 0.2311 (0.2322)  loss_ce_0: 0.1517 (0.1789)  loss_iou_0: 0.6595 (0.7173)  loss_ce_1: 0.1215 (0.1534)  loss_iou_1: 0.6510 (0.6887)  loss_ce_2: 0.1184 (0.1506)  loss_iou_2: 0.6550 (0.6855)  loss_ce_unscaled: 0.0614 (0.0787)  class_error_unscaled: 0.0000 (0.8268)  loss_segments_unscaled: 0.0429 (0.0526)  loss_iou_unscaled: 0.1156 (0.1161)  loss_ce_0_unscaled: 0.0758 (0.0894)  loss_segments_0_unscaled: 0.0471 (0.0556)  loss_iou_0_unscaled: 0.3297 (0.3587)  loss_ce_1_unscaled: 0.0607 (0.0767)  loss_segments_1_unscaled: 0.0446 (0.0535)  loss_iou_1_unscaled: 0.3255 (0.3444)  loss_ce_2_unscaled: 0.0592 (0.0753)  loss_segments_2_unscaled: 0.0441 (0.0533)  loss_iou_2_unscaled: 0.3275 (0.3428)
[11/28 15:53:43][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 25.99it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:53:51][INFO]: mode=raw 121811 predictions from 210 videos
[11/28 15:53:55][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
70.57 63.24 53.10 36.82 20.99 48.94 raw epoch3
[11/28 15:53:55][INFO]: mAP_raw: 48.94
[11/28 15:53:55][INFO]: new best metric 0.4894@epoch3
[11/28 15:53:55][INFO]: lr=0.0002
[11/28 15:53:55][INFO]: lr=1e-05
[11/28 15:53:55][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:53:55][INFO]: Epoch: [4]  [  0/198]  eta: 0:01:00  lr: 0.000200  loss: 2.7626 (2.7626)  loss_ce: 0.1252 (0.1252)  loss_iou: 0.2677 (0.2677)  loss_ce_0: 0.1631 (0.1631)  loss_iou_0: 0.6614 (0.6614)  loss_ce_1: 0.1369 (0.1369)  loss_iou_1: 0.6457 (0.6457)  loss_ce_2: 0.1263 (0.1263)  loss_iou_2: 0.6363 (0.6363)  loss_ce_unscaled: 0.0626 (0.0626)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0465 (0.0465)  loss_iou_unscaled: 0.1338 (0.1338)  loss_ce_0_unscaled: 0.0815 (0.0815)  loss_segments_0_unscaled: 0.0472 (0.0472)  loss_iou_0_unscaled: 0.3307 (0.3307)  loss_ce_1_unscaled: 0.0685 (0.0685)  loss_segments_1_unscaled: 0.0463 (0.0463)  loss_iou_1_unscaled: 0.3228 (0.3228)  loss_ce_2_unscaled: 0.0632 (0.0632)  loss_segments_2_unscaled: 0.0465 (0.0465)  loss_iou_2_unscaled: 0.3181 (0.3181)  time: 0.3072  data: 0.2228  max mem: 488
[11/28 15:53:57][INFO]: Epoch: [4]  [ 20/198]  eta: 0:00:15  lr: 0.000200  loss: 2.7106 (2.8030)  loss_ce: 0.1142 (0.1285)  loss_iou: 0.2131 (0.2267)  loss_ce_0: 0.1318 (0.1415)  loss_iou_0: 0.7012 (0.7060)  loss_ce_1: 0.1116 (0.1230)  loss_iou_1: 0.6750 (0.6818)  loss_ce_2: 0.1124 (0.1242)  loss_iou_2: 0.6606 (0.6712)  loss_ce_unscaled: 0.0571 (0.0643)  class_error_unscaled: 0.0000 (0.4031)  loss_segments_unscaled: 0.0442 (0.0462)  loss_iou_unscaled: 0.1065 (0.1134)  loss_ce_0_unscaled: 0.0659 (0.0707)  loss_segments_0_unscaled: 0.0461 (0.0492)  loss_iou_0_unscaled: 0.3506 (0.3530)  loss_ce_1_unscaled: 0.0558 (0.0615)  loss_segments_1_unscaled: 0.0473 (0.0476)  loss_iou_1_unscaled: 0.3375 (0.3409)  loss_ce_2_unscaled: 0.0562 (0.0621)  loss_segments_2_unscaled: 0.0453 (0.0470)  loss_iou_2_unscaled: 0.3303 (0.3356)  time: 0.0734  data: 0.0012  max mem: 488
[11/28 15:53:58][INFO]: Epoch: [4]  [ 40/198]  eta: 0:00:12  lr: 0.000200  loss: 2.5394 (2.7215)  loss_ce: 0.1305 (0.1337)  loss_iou: 0.2331 (0.2320)  loss_ce_0: 0.1409 (0.1433)  loss_iou_0: 0.6367 (0.6754)  loss_ce_1: 0.1113 (0.1285)  loss_iou_1: 0.5939 (0.6439)  loss_ce_2: 0.1102 (0.1276)  loss_iou_2: 0.5918 (0.6372)  loss_ce_unscaled: 0.0652 (0.0669)  class_error_unscaled: 0.0000 (0.3488)  loss_segments_unscaled: 0.0416 (0.0459)  loss_iou_unscaled: 0.1165 (0.1160)  loss_ce_0_unscaled: 0.0704 (0.0716)  loss_segments_0_unscaled: 0.0465 (0.0491)  loss_iou_0_unscaled: 0.3183 (0.3377)  loss_ce_1_unscaled: 0.0557 (0.0642)  loss_segments_1_unscaled: 0.0441 (0.0471)  loss_iou_1_unscaled: 0.2970 (0.3219)  loss_ce_2_unscaled: 0.0551 (0.0638)  loss_segments_2_unscaled: 0.0418 (0.0462)  loss_iou_2_unscaled: 0.2959 (0.3186)  time: 0.0678  data: 0.0012  max mem: 488
[11/28 15:54:00][INFO]: Epoch: [4]  [ 60/198]  eta: 0:00:10  lr: 0.000200  loss: 2.4937 (2.6689)  loss_ce: 0.1072 (0.1274)  loss_iou: 0.2309 (0.2317)  loss_ce_0: 0.1444 (0.1451)  loss_iou_0: 0.6249 (0.6603)  loss_ce_1: 0.1148 (0.1265)  loss_iou_1: 0.6065 (0.6304)  loss_ce_2: 0.1129 (0.1234)  loss_iou_2: 0.5956 (0.6241)  loss_ce_unscaled: 0.0536 (0.0637)  class_error_unscaled: 0.0000 (0.3164)  loss_segments_unscaled: 0.0458 (0.0464)  loss_iou_unscaled: 0.1154 (0.1159)  loss_ce_0_unscaled: 0.0722 (0.0726)  loss_segments_0_unscaled: 0.0489 (0.0498)  loss_iou_0_unscaled: 0.3124 (0.3301)  loss_ce_1_unscaled: 0.0574 (0.0632)  loss_segments_1_unscaled: 0.0455 (0.0476)  loss_iou_1_unscaled: 0.3032 (0.3152)  loss_ce_2_unscaled: 0.0564 (0.0617)  loss_segments_2_unscaled: 0.0454 (0.0467)  loss_iou_2_unscaled: 0.2978 (0.3120)  time: 0.0687  data: 0.0013  max mem: 488
[11/28 15:54:01][INFO]: Epoch: [4]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 2.4439 (2.6370)  loss_ce: 0.1333 (0.1263)  loss_iou: 0.2363 (0.2329)  loss_ce_0: 0.1383 (0.1438)  loss_iou_0: 0.6001 (0.6517)  loss_ce_1: 0.1223 (0.1257)  loss_iou_1: 0.5501 (0.6203)  loss_ce_2: 0.1113 (0.1219)  loss_iou_2: 0.5676 (0.6143)  loss_ce_unscaled: 0.0667 (0.0632)  class_error_unscaled: 0.0000 (0.2600)  loss_segments_unscaled: 0.0424 (0.0456)  loss_iou_unscaled: 0.1181 (0.1165)  loss_ce_0_unscaled: 0.0692 (0.0719)  loss_segments_0_unscaled: 0.0428 (0.0490)  loss_iou_0_unscaled: 0.3000 (0.3259)  loss_ce_1_unscaled: 0.0611 (0.0629)  loss_segments_1_unscaled: 0.0398 (0.0466)  loss_iou_1_unscaled: 0.2750 (0.3102)  loss_ce_2_unscaled: 0.0556 (0.0609)  loss_segments_2_unscaled: 0.0389 (0.0457)  loss_iou_2_unscaled: 0.2838 (0.3072)  time: 0.0690  data: 0.0011  max mem: 488
[11/28 15:54:02][INFO]: Epoch: [4]  [100/198]  eta: 0:00:06  lr: 0.000200  loss: 2.8221 (2.6595)  loss_ce: 0.1272 (0.1247)  loss_iou: 0.2190 (0.2311)  loss_ce_0: 0.1467 (0.1448)  loss_iou_0: 0.6795 (0.6596)  loss_ce_1: 0.1203 (0.1248)  loss_iou_1: 0.6935 (0.6305)  loss_ce_2: 0.1265 (0.1205)  loss_iou_2: 0.6742 (0.6236)  loss_ce_unscaled: 0.0636 (0.0624)  class_error_unscaled: 0.0000 (0.3111)  loss_segments_unscaled: 0.0465 (0.0462)  loss_iou_unscaled: 0.1095 (0.1156)  loss_ce_0_unscaled: 0.0733 (0.0724)  loss_segments_0_unscaled: 0.0501 (0.0495)  loss_iou_0_unscaled: 0.3397 (0.3298)  loss_ce_1_unscaled: 0.0602 (0.0624)  loss_segments_1_unscaled: 0.0471 (0.0473)  loss_iou_1_unscaled: 0.3467 (0.3152)  loss_ce_2_unscaled: 0.0632 (0.0602)  loss_segments_2_unscaled: 0.0469 (0.0463)  loss_iou_2_unscaled: 0.3371 (0.3118)  time: 0.0647  data: 0.0011  max mem: 488
[11/28 15:54:04][INFO]: Epoch: [4]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 2.5885 (2.6554)  loss_ce: 0.1049 (0.1227)  loss_iou: 0.2283 (0.2316)  loss_ce_0: 0.1390 (0.1436)  loss_iou_0: 0.6738 (0.6603)  loss_ce_1: 0.1177 (0.1235)  loss_iou_1: 0.6413 (0.6306)  loss_ce_2: 0.1040 (0.1189)  loss_iou_2: 0.6233 (0.6242)  loss_ce_unscaled: 0.0525 (0.0613)  class_error_unscaled: 0.0000 (0.2840)  loss_segments_unscaled: 0.0445 (0.0464)  loss_iou_unscaled: 0.1142 (0.1158)  loss_ce_0_unscaled: 0.0695 (0.0718)  loss_segments_0_unscaled: 0.0464 (0.0498)  loss_iou_0_unscaled: 0.3369 (0.3302)  loss_ce_1_unscaled: 0.0589 (0.0618)  loss_segments_1_unscaled: 0.0451 (0.0475)  loss_iou_1_unscaled: 0.3206 (0.3153)  loss_ce_2_unscaled: 0.0520 (0.0594)  loss_segments_2_unscaled: 0.0442 (0.0466)  loss_iou_2_unscaled: 0.3117 (0.3121)  time: 0.0670  data: 0.0011  max mem: 488
[11/28 15:54:05][INFO]: Epoch: [4]  [140/198]  eta: 0:00:04  lr: 0.000200  loss: 2.6310 (2.6575)  loss_ce: 0.1148 (0.1237)  loss_iou: 0.2144 (0.2296)  loss_ce_0: 0.1467 (0.1450)  loss_iou_0: 0.6572 (0.6594)  loss_ce_1: 0.1361 (0.1256)  loss_iou_1: 0.6066 (0.6295)  loss_ce_2: 0.1192 (0.1205)  loss_iou_2: 0.5913 (0.6242)  loss_ce_unscaled: 0.0574 (0.0619)  class_error_unscaled: 0.0000 (0.2999)  loss_segments_unscaled: 0.0425 (0.0463)  loss_iou_unscaled: 0.1072 (0.1148)  loss_ce_0_unscaled: 0.0734 (0.0725)  loss_segments_0_unscaled: 0.0478 (0.0495)  loss_iou_0_unscaled: 0.3286 (0.3297)  loss_ce_1_unscaled: 0.0681 (0.0628)  loss_segments_1_unscaled: 0.0469 (0.0473)  loss_iou_1_unscaled: 0.3033 (0.3148)  loss_ce_2_unscaled: 0.0596 (0.0602)  loss_segments_2_unscaled: 0.0425 (0.0465)  loss_iou_2_unscaled: 0.2956 (0.3121)  time: 0.0672  data: 0.0012  max mem: 488
[11/28 15:54:06][INFO]: Epoch: [4]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 2.6622 (2.6628)  loss_ce: 0.1062 (0.1224)  loss_iou: 0.2133 (0.2285)  loss_ce_0: 0.1430 (0.1439)  loss_iou_0: 0.6619 (0.6635)  loss_ce_1: 0.1150 (0.1245)  loss_iou_1: 0.6294 (0.6330)  loss_ce_2: 0.1098 (0.1190)  loss_iou_2: 0.6261 (0.6280)  loss_ce_unscaled: 0.0531 (0.0612)  class_error_unscaled: 0.0000 (0.3418)  loss_segments_unscaled: 0.0438 (0.0465)  loss_iou_unscaled: 0.1066 (0.1143)  loss_ce_0_unscaled: 0.0715 (0.0720)  loss_segments_0_unscaled: 0.0446 (0.0495)  loss_iou_0_unscaled: 0.3309 (0.3317)  loss_ce_1_unscaled: 0.0575 (0.0622)  loss_segments_1_unscaled: 0.0409 (0.0473)  loss_iou_1_unscaled: 0.3147 (0.3165)  loss_ce_2_unscaled: 0.0549 (0.0595)  loss_segments_2_unscaled: 0.0437 (0.0468)  loss_iou_2_unscaled: 0.3130 (0.3140)  time: 0.0688  data: 0.0013  max mem: 488
[11/28 15:54:08][INFO]: Epoch: [4]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 2.5453 (2.6665)  loss_ce: 0.1090 (0.1215)  loss_iou: 0.2241 (0.2283)  loss_ce_0: 0.1311 (0.1433)  loss_iou_0: 0.6465 (0.6651)  loss_ce_1: 0.1161 (0.1243)  loss_iou_1: 0.6139 (0.6349)  loss_ce_2: 0.1102 (0.1193)  loss_iou_2: 0.6211 (0.6297)  loss_ce_unscaled: 0.0545 (0.0608)  class_error_unscaled: 0.0000 (0.3481)  loss_segments_unscaled: 0.0454 (0.0467)  loss_iou_unscaled: 0.1121 (0.1141)  loss_ce_0_unscaled: 0.0656 (0.0716)  loss_segments_0_unscaled: 0.0502 (0.0498)  loss_iou_0_unscaled: 0.3232 (0.3326)  loss_ce_1_unscaled: 0.0581 (0.0622)  loss_segments_1_unscaled: 0.0482 (0.0476)  loss_iou_1_unscaled: 0.3069 (0.3174)  loss_ce_2_unscaled: 0.0551 (0.0596)  loss_segments_2_unscaled: 0.0463 (0.0470)  loss_iou_2_unscaled: 0.3106 (0.3149)  time: 0.0682  data: 0.0012  max mem: 488
[11/28 15:54:09][INFO]: Epoch: [4]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 2.6355 (2.6661)  loss_ce: 0.1139 (0.1219)  loss_iou: 0.2324 (0.2298)  loss_ce_0: 0.1285 (0.1421)  loss_iou_0: 0.6371 (0.6653)  loss_ce_1: 0.1195 (0.1238)  loss_iou_1: 0.6106 (0.6347)  loss_ce_2: 0.1217 (0.1193)  loss_iou_2: 0.6112 (0.6292)  loss_ce_unscaled: 0.0570 (0.0609)  class_error_unscaled: 0.0000 (0.3482)  loss_segments_unscaled: 0.0470 (0.0467)  loss_iou_unscaled: 0.1162 (0.1149)  loss_ce_0_unscaled: 0.0642 (0.0711)  loss_segments_0_unscaled: 0.0473 (0.0498)  loss_iou_0_unscaled: 0.3185 (0.3326)  loss_ce_1_unscaled: 0.0598 (0.0619)  loss_segments_1_unscaled: 0.0475 (0.0477)  loss_iou_1_unscaled: 0.3053 (0.3173)  loss_ce_2_unscaled: 0.0609 (0.0596)  loss_segments_2_unscaled: 0.0473 (0.0470)  loss_iou_2_unscaled: 0.3056 (0.3146)  time: 0.0665  data: 0.0011  max mem: 488
[11/28 15:54:09][INFO]: Epoch: [4] Total time: 0:00:13 (0.0696 s / it)
[11/28 15:54:09][INFO]: Averaged stats:lr: 0.000200  loss: 2.6355 (2.6661)  loss_ce: 0.1139 (0.1219)  loss_iou: 0.2324 (0.2298)  loss_ce_0: 0.1285 (0.1421)  loss_iou_0: 0.6371 (0.6653)  loss_ce_1: 0.1195 (0.1238)  loss_iou_1: 0.6106 (0.6347)  loss_ce_2: 0.1217 (0.1193)  loss_iou_2: 0.6112 (0.6292)  loss_ce_unscaled: 0.0570 (0.0609)  class_error_unscaled: 0.0000 (0.3482)  loss_segments_unscaled: 0.0470 (0.0467)  loss_iou_unscaled: 0.1162 (0.1149)  loss_ce_0_unscaled: 0.0642 (0.0711)  loss_segments_0_unscaled: 0.0473 (0.0498)  loss_iou_0_unscaled: 0.3185 (0.3326)  loss_ce_1_unscaled: 0.0598 (0.0619)  loss_segments_1_unscaled: 0.0475 (0.0477)  loss_iou_1_unscaled: 0.3053 (0.3173)  loss_ce_2_unscaled: 0.0609 (0.0596)  loss_segments_2_unscaled: 0.0473 (0.0470)  loss_iou_2_unscaled: 0.3056 (0.3146)
[11/28 15:54:09][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 25.98it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:54:17][INFO]: mode=raw 123260 predictions from 210 videos
[11/28 15:54:20][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
71.57 64.28 53.87 39.73 23.71 50.63 raw epoch4
[11/28 15:54:20][INFO]: mAP_raw: 50.63
[11/28 15:54:20][INFO]: new best metric 0.5063@epoch4
[11/28 15:54:20][INFO]: lr=0.0002
[11/28 15:54:20][INFO]: lr=1e-05
[11/28 15:54:20][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:54:21][INFO]: Epoch: [5]  [  0/198]  eta: 0:00:58  lr: 0.000200  loss: 2.6911 (2.6911)  loss_ce: 0.0998 (0.0998)  loss_iou: 0.2065 (0.2065)  loss_ce_0: 0.1074 (0.1074)  loss_iou_0: 0.7244 (0.7244)  loss_ce_1: 0.1009 (0.1009)  loss_iou_1: 0.6812 (0.6812)  loss_ce_2: 0.0932 (0.0932)  loss_iou_2: 0.6777 (0.6777)  loss_ce_unscaled: 0.0499 (0.0499)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0358 (0.0358)  loss_iou_unscaled: 0.1033 (0.1033)  loss_ce_0_unscaled: 0.0537 (0.0537)  loss_segments_0_unscaled: 0.0418 (0.0418)  loss_iou_0_unscaled: 0.3622 (0.3622)  loss_ce_1_unscaled: 0.0505 (0.0505)  loss_segments_1_unscaled: 0.0356 (0.0356)  loss_iou_1_unscaled: 0.3406 (0.3406)  loss_ce_2_unscaled: 0.0466 (0.0466)  loss_segments_2_unscaled: 0.0366 (0.0366)  loss_iou_2_unscaled: 0.3388 (0.3388)  time: 0.2953  data: 0.2107  max mem: 488
[11/28 15:54:22][INFO]: Epoch: [5]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 2.4452 (2.4694)  loss_ce: 0.0872 (0.0897)  loss_iou: 0.2197 (0.2248)  loss_ce_0: 0.1127 (0.1210)  loss_iou_0: 0.6219 (0.6370)  loss_ce_1: 0.0976 (0.0997)  loss_iou_1: 0.6007 (0.6065)  loss_ce_2: 0.0860 (0.0904)  loss_iou_2: 0.6105 (0.6004)  loss_ce_unscaled: 0.0436 (0.0449)  class_error_unscaled: 0.0000 (0.3755)  loss_segments_unscaled: 0.0443 (0.0444)  loss_iou_unscaled: 0.1098 (0.1124)  loss_ce_0_unscaled: 0.0563 (0.0605)  loss_segments_0_unscaled: 0.0449 (0.0473)  loss_iou_0_unscaled: 0.3109 (0.3185)  loss_ce_1_unscaled: 0.0488 (0.0499)  loss_segments_1_unscaled: 0.0428 (0.0446)  loss_iou_1_unscaled: 0.3004 (0.3032)  loss_ce_2_unscaled: 0.0430 (0.0452)  loss_segments_2_unscaled: 0.0435 (0.0444)  loss_iou_2_unscaled: 0.3053 (0.3002)  time: 0.0692  data: 0.0012  max mem: 488
[11/28 15:54:23][INFO]: Epoch: [5]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 2.3774 (2.4756)  loss_ce: 0.0953 (0.0933)  loss_iou: 0.2259 (0.2251)  loss_ce_0: 0.1114 (0.1195)  loss_iou_0: 0.6237 (0.6376)  loss_ce_1: 0.0967 (0.0980)  loss_iou_1: 0.6183 (0.6081)  loss_ce_2: 0.0898 (0.0911)  loss_iou_2: 0.5740 (0.6030)  loss_ce_unscaled: 0.0476 (0.0467)  class_error_unscaled: 0.0000 (0.1923)  loss_segments_unscaled: 0.0426 (0.0444)  loss_iou_unscaled: 0.1129 (0.1126)  loss_ce_0_unscaled: 0.0557 (0.0597)  loss_segments_0_unscaled: 0.0451 (0.0469)  loss_iou_0_unscaled: 0.3118 (0.3188)  loss_ce_1_unscaled: 0.0484 (0.0490)  loss_segments_1_unscaled: 0.0418 (0.0445)  loss_iou_1_unscaled: 0.3091 (0.3040)  loss_ce_2_unscaled: 0.0449 (0.0455)  loss_segments_2_unscaled: 0.0435 (0.0444)  loss_iou_2_unscaled: 0.2870 (0.3015)  time: 0.0632  data: 0.0012  max mem: 488
[11/28 15:54:25][INFO]: Epoch: [5]  [ 60/198]  eta: 0:00:09  lr: 0.000200  loss: 2.3196 (2.4526)  loss_ce: 0.0857 (0.0930)  loss_iou: 0.2307 (0.2270)  loss_ce_0: 0.1076 (0.1171)  loss_iou_0: 0.6052 (0.6316)  loss_ce_1: 0.0965 (0.0973)  loss_iou_1: 0.5655 (0.6011)  loss_ce_2: 0.0951 (0.0903)  loss_iou_2: 0.5641 (0.5952)  loss_ce_unscaled: 0.0428 (0.0465)  class_error_unscaled: 0.0000 (0.1580)  loss_segments_unscaled: 0.0443 (0.0449)  loss_iou_unscaled: 0.1154 (0.1135)  loss_ce_0_unscaled: 0.0538 (0.0585)  loss_segments_0_unscaled: 0.0484 (0.0475)  loss_iou_0_unscaled: 0.3026 (0.3158)  loss_ce_1_unscaled: 0.0482 (0.0486)  loss_segments_1_unscaled: 0.0454 (0.0451)  loss_iou_1_unscaled: 0.2827 (0.3006)  loss_ce_2_unscaled: 0.0476 (0.0452)  loss_segments_2_unscaled: 0.0443 (0.0447)  loss_iou_2_unscaled: 0.2820 (0.2976)  time: 0.0663  data: 0.0011  max mem: 488
[11/28 15:54:26][INFO]: Epoch: [5]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 2.4272 (2.4530)  loss_ce: 0.0849 (0.0936)  loss_iou: 0.2242 (0.2287)  loss_ce_0: 0.1124 (0.1178)  loss_iou_0: 0.6291 (0.6312)  loss_ce_1: 0.0962 (0.0980)  loss_iou_1: 0.5937 (0.5992)  loss_ce_2: 0.0880 (0.0925)  loss_iou_2: 0.5837 (0.5919)  loss_ce_unscaled: 0.0425 (0.0468)  class_error_unscaled: 0.0000 (0.1571)  loss_segments_unscaled: 0.0400 (0.0448)  loss_iou_unscaled: 0.1121 (0.1144)  loss_ce_0_unscaled: 0.0562 (0.0589)  loss_segments_0_unscaled: 0.0429 (0.0475)  loss_iou_0_unscaled: 0.3145 (0.3156)  loss_ce_1_unscaled: 0.0481 (0.0490)  loss_segments_1_unscaled: 0.0397 (0.0451)  loss_iou_1_unscaled: 0.2969 (0.2996)  loss_ce_2_unscaled: 0.0440 (0.0462)  loss_segments_2_unscaled: 0.0400 (0.0449)  loss_iou_2_unscaled: 0.2918 (0.2959)  time: 0.0664  data: 0.0012  max mem: 488
[11/28 15:54:27][INFO]: Epoch: [5]  [100/198]  eta: 0:00:06  lr: 0.000200  loss: 2.6695 (2.4960)  loss_ce: 0.1074 (0.0970)  loss_iou: 0.2357 (0.2307)  loss_ce_0: 0.1177 (0.1186)  loss_iou_0: 0.7065 (0.6419)  loss_ce_1: 0.1080 (0.1010)  loss_iou_1: 0.6808 (0.6096)  loss_ce_2: 0.1030 (0.0959)  loss_iou_2: 0.6549 (0.6013)  loss_ce_unscaled: 0.0537 (0.0485)  class_error_unscaled: 0.0000 (0.1739)  loss_segments_unscaled: 0.0447 (0.0452)  loss_iou_unscaled: 0.1179 (0.1153)  loss_ce_0_unscaled: 0.0589 (0.0593)  loss_segments_0_unscaled: 0.0454 (0.0479)  loss_iou_0_unscaled: 0.3533 (0.3210)  loss_ce_1_unscaled: 0.0540 (0.0505)  loss_segments_1_unscaled: 0.0437 (0.0455)  loss_iou_1_unscaled: 0.3404 (0.3048)  loss_ce_2_unscaled: 0.0515 (0.0479)  loss_segments_2_unscaled: 0.0453 (0.0453)  loss_iou_2_unscaled: 0.3275 (0.3007)  time: 0.0674  data: 0.0011  max mem: 488
[11/28 15:54:29][INFO]: Epoch: [5]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 2.5430 (2.5078)  loss_ce: 0.1090 (0.1002)  loss_iou: 0.2263 (0.2316)  loss_ce_0: 0.1524 (0.1221)  loss_iou_0: 0.6146 (0.6416)  loss_ce_1: 0.1183 (0.1042)  loss_iou_1: 0.5801 (0.6089)  loss_ce_2: 0.1066 (0.0985)  loss_iou_2: 0.5824 (0.6007)  loss_ce_unscaled: 0.0545 (0.0501)  class_error_unscaled: 0.0000 (0.2146)  loss_segments_unscaled: 0.0472 (0.0455)  loss_iou_unscaled: 0.1132 (0.1158)  loss_ce_0_unscaled: 0.0762 (0.0610)  loss_segments_0_unscaled: 0.0483 (0.0484)  loss_iou_0_unscaled: 0.3073 (0.3208)  loss_ce_1_unscaled: 0.0592 (0.0521)  loss_segments_1_unscaled: 0.0472 (0.0461)  loss_iou_1_unscaled: 0.2900 (0.3044)  loss_ce_2_unscaled: 0.0533 (0.0493)  loss_segments_2_unscaled: 0.0473 (0.0457)  loss_iou_2_unscaled: 0.2912 (0.3004)  time: 0.0665  data: 0.0012  max mem: 488
[11/28 15:54:30][INFO]: Epoch: [5]  [140/198]  eta: 0:00:03  lr: 0.000200  loss: 2.5556 (2.5202)  loss_ce: 0.1042 (0.1019)  loss_iou: 0.2267 (0.2313)  loss_ce_0: 0.1187 (0.1228)  loss_iou_0: 0.6446 (0.6441)  loss_ce_1: 0.0942 (0.1046)  loss_iou_1: 0.6285 (0.6116)  loss_ce_2: 0.0980 (0.0999)  loss_iou_2: 0.6142 (0.6040)  loss_ce_unscaled: 0.0521 (0.0510)  class_error_unscaled: 0.0000 (0.2015)  loss_segments_unscaled: 0.0438 (0.0456)  loss_iou_unscaled: 0.1133 (0.1157)  loss_ce_0_unscaled: 0.0594 (0.0614)  loss_segments_0_unscaled: 0.0473 (0.0484)  loss_iou_0_unscaled: 0.3223 (0.3220)  loss_ce_1_unscaled: 0.0471 (0.0523)  loss_segments_1_unscaled: 0.0454 (0.0462)  loss_iou_1_unscaled: 0.3142 (0.3058)  loss_ce_2_unscaled: 0.0490 (0.0499)  loss_segments_2_unscaled: 0.0439 (0.0459)  loss_iou_2_unscaled: 0.3071 (0.3020)  time: 0.0674  data: 0.0012  max mem: 488
[11/28 15:54:31][INFO]: Epoch: [5]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 2.6378 (2.5371)  loss_ce: 0.1057 (0.1029)  loss_iou: 0.2242 (0.2316)  loss_ce_0: 0.1354 (0.1241)  loss_iou_0: 0.6719 (0.6481)  loss_ce_1: 0.1180 (0.1059)  loss_iou_1: 0.6642 (0.6156)  loss_ce_2: 0.1127 (0.1009)  loss_iou_2: 0.6263 (0.6079)  loss_ce_unscaled: 0.0528 (0.0514)  class_error_unscaled: 0.0000 (0.1996)  loss_segments_unscaled: 0.0414 (0.0454)  loss_iou_unscaled: 0.1121 (0.1158)  loss_ce_0_unscaled: 0.0677 (0.0621)  loss_segments_0_unscaled: 0.0476 (0.0483)  loss_iou_0_unscaled: 0.3359 (0.3240)  loss_ce_1_unscaled: 0.0590 (0.0530)  loss_segments_1_unscaled: 0.0428 (0.0459)  loss_iou_1_unscaled: 0.3321 (0.3078)  loss_ce_2_unscaled: 0.0564 (0.0505)  loss_segments_2_unscaled: 0.0422 (0.0456)  loss_iou_2_unscaled: 0.3131 (0.3039)  time: 0.0673  data: 0.0012  max mem: 488
[11/28 15:54:33][INFO]: Epoch: [5]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 2.5137 (2.5413)  loss_ce: 0.1062 (0.1041)  loss_iou: 0.2280 (0.2313)  loss_ce_0: 0.1255 (0.1251)  loss_iou_0: 0.6250 (0.6488)  loss_ce_1: 0.1045 (0.1069)  loss_iou_1: 0.5567 (0.6153)  loss_ce_2: 0.1086 (0.1022)  loss_iou_2: 0.5619 (0.6076)  loss_ce_unscaled: 0.0531 (0.0520)  class_error_unscaled: 0.0000 (0.2153)  loss_segments_unscaled: 0.0419 (0.0454)  loss_iou_unscaled: 0.1140 (0.1156)  loss_ce_0_unscaled: 0.0627 (0.0626)  loss_segments_0_unscaled: 0.0444 (0.0483)  loss_iou_0_unscaled: 0.3125 (0.3244)  loss_ce_1_unscaled: 0.0523 (0.0534)  loss_segments_1_unscaled: 0.0437 (0.0459)  loss_iou_1_unscaled: 0.2784 (0.3077)  loss_ce_2_unscaled: 0.0543 (0.0511)  loss_segments_2_unscaled: 0.0419 (0.0456)  loss_iou_2_unscaled: 0.2810 (0.3038)  time: 0.0671  data: 0.0012  max mem: 488
[11/28 15:54:34][INFO]: Epoch: [5]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 2.5158 (2.5442)  loss_ce: 0.1108 (0.1052)  loss_iou: 0.2335 (0.2325)  loss_ce_0: 0.1305 (0.1263)  loss_iou_0: 0.6352 (0.6485)  loss_ce_1: 0.1108 (0.1081)  loss_iou_1: 0.5840 (0.6139)  loss_ce_2: 0.1106 (0.1035)  loss_iou_2: 0.5839 (0.6062)  loss_ce_unscaled: 0.0554 (0.0526)  class_error_unscaled: 0.0000 (0.2174)  loss_segments_unscaled: 0.0398 (0.0453)  loss_iou_unscaled: 0.1168 (0.1163)  loss_ce_0_unscaled: 0.0652 (0.0632)  loss_segments_0_unscaled: 0.0430 (0.0484)  loss_iou_0_unscaled: 0.3176 (0.3242)  loss_ce_1_unscaled: 0.0554 (0.0541)  loss_segments_1_unscaled: 0.0399 (0.0459)  loss_iou_1_unscaled: 0.2920 (0.3070)  loss_ce_2_unscaled: 0.0553 (0.0517)  loss_segments_2_unscaled: 0.0401 (0.0454)  loss_iou_2_unscaled: 0.2920 (0.3031)  time: 0.0630  data: 0.0012  max mem: 488
[11/28 15:54:34][INFO]: Epoch: [5] Total time: 0:00:13 (0.0679 s / it)
[11/28 15:54:34][INFO]: Averaged stats:lr: 0.000200  loss: 2.5158 (2.5442)  loss_ce: 0.1108 (0.1052)  loss_iou: 0.2335 (0.2325)  loss_ce_0: 0.1305 (0.1263)  loss_iou_0: 0.6352 (0.6485)  loss_ce_1: 0.1108 (0.1081)  loss_iou_1: 0.5840 (0.6139)  loss_ce_2: 0.1106 (0.1035)  loss_iou_2: 0.5839 (0.6062)  loss_ce_unscaled: 0.0554 (0.0526)  class_error_unscaled: 0.0000 (0.2174)  loss_segments_unscaled: 0.0398 (0.0453)  loss_iou_unscaled: 0.1168 (0.1163)  loss_ce_0_unscaled: 0.0652 (0.0632)  loss_segments_0_unscaled: 0.0430 (0.0484)  loss_iou_0_unscaled: 0.3176 (0.3242)  loss_ce_1_unscaled: 0.0554 (0.0541)  loss_segments_1_unscaled: 0.0399 (0.0459)  loss_iou_1_unscaled: 0.2920 (0.3070)  loss_ce_2_unscaled: 0.0553 (0.0517)  loss_segments_2_unscaled: 0.0401 (0.0454)  loss_iou_2_unscaled: 0.2920 (0.3031)
[11/28 15:54:34][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 26.10it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:54:42][INFO]: mode=raw 123133 predictions from 210 videos
[11/28 15:54:46][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
70.18 64.29 55.18 41.07 25.08 51.16 raw epoch5
[11/28 15:54:46][INFO]: mAP_raw: 51.16
[11/28 15:54:46][INFO]: new best metric 0.5116@epoch5
[11/28 15:54:46][INFO]: lr=0.0002
[11/28 15:54:46][INFO]: lr=1e-05
[11/28 15:54:46][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:54:46][INFO]: Epoch: [6]  [  0/198]  eta: 0:00:52  lr: 0.000200  loss: 3.1405 (3.1405)  loss_ce: 0.0728 (0.0728)  loss_iou: 0.2260 (0.2260)  loss_ce_0: 0.0856 (0.0856)  loss_iou_0: 0.8484 (0.8484)  loss_ce_1: 0.0774 (0.0774)  loss_iou_1: 0.8521 (0.8521)  loss_ce_2: 0.0731 (0.0731)  loss_iou_2: 0.9051 (0.9051)  loss_ce_unscaled: 0.0364 (0.0364)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0499 (0.0499)  loss_iou_unscaled: 0.1130 (0.1130)  loss_ce_0_unscaled: 0.0428 (0.0428)  loss_segments_0_unscaled: 0.0391 (0.0391)  loss_iou_0_unscaled: 0.4242 (0.4242)  loss_ce_1_unscaled: 0.0387 (0.0387)  loss_segments_1_unscaled: 0.0431 (0.0431)  loss_iou_1_unscaled: 0.4260 (0.4260)  loss_ce_2_unscaled: 0.0366 (0.0366)  loss_segments_2_unscaled: 0.0451 (0.0451)  loss_iou_2_unscaled: 0.4525 (0.4525)  time: 0.2654  data: 0.1747  max mem: 488
[11/28 15:54:47][INFO]: Epoch: [6]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 2.2344 (2.3199)  loss_ce: 0.0828 (0.0846)  loss_iou: 0.2427 (0.2416)  loss_ce_0: 0.1029 (0.1057)  loss_iou_0: 0.5583 (0.5887)  loss_ce_1: 0.0869 (0.0900)  loss_iou_1: 0.5227 (0.5610)  loss_ce_2: 0.0906 (0.0887)  loss_iou_2: 0.5259 (0.5596)  loss_ce_unscaled: 0.0414 (0.0423)  class_error_unscaled: 0.0000 (0.0934)  loss_segments_unscaled: 0.0384 (0.0421)  loss_iou_unscaled: 0.1214 (0.1208)  loss_ce_0_unscaled: 0.0514 (0.0529)  loss_segments_0_unscaled: 0.0435 (0.0441)  loss_iou_0_unscaled: 0.2791 (0.2944)  loss_ce_1_unscaled: 0.0435 (0.0450)  loss_segments_1_unscaled: 0.0378 (0.0424)  loss_iou_1_unscaled: 0.2614 (0.2805)  loss_ce_2_unscaled: 0.0453 (0.0444)  loss_segments_2_unscaled: 0.0390 (0.0423)  loss_iou_2_unscaled: 0.2630 (0.2798)  time: 0.0709  data: 0.0012  max mem: 488
[11/28 15:54:49][INFO]: Epoch: [6]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 2.4307 (2.4146)  loss_ce: 0.0792 (0.0871)  loss_iou: 0.2271 (0.2353)  loss_ce_0: 0.1293 (0.1187)  loss_iou_0: 0.5954 (0.6164)  loss_ce_1: 0.1015 (0.0979)  loss_iou_1: 0.6122 (0.5886)  loss_ce_2: 0.0884 (0.0901)  loss_iou_2: 0.5935 (0.5805)  loss_ce_unscaled: 0.0396 (0.0436)  class_error_unscaled: 0.0000 (0.2148)  loss_segments_unscaled: 0.0477 (0.0457)  loss_iou_unscaled: 0.1135 (0.1176)  loss_ce_0_unscaled: 0.0647 (0.0593)  loss_segments_0_unscaled: 0.0475 (0.0472)  loss_iou_0_unscaled: 0.2977 (0.3082)  loss_ce_1_unscaled: 0.0507 (0.0490)  loss_segments_1_unscaled: 0.0467 (0.0461)  loss_iou_1_unscaled: 0.3061 (0.2943)  loss_ce_2_unscaled: 0.0442 (0.0450)  loss_segments_2_unscaled: 0.0477 (0.0455)  loss_iou_2_unscaled: 0.2967 (0.2903)  time: 0.0692  data: 0.0011  max mem: 488
[11/28 15:54:50][INFO]: Epoch: [6]  [ 60/198]  eta: 0:00:10  lr: 0.000200  loss: 2.4354 (2.4206)  loss_ce: 0.0812 (0.0867)  loss_iou: 0.2355 (0.2356)  loss_ce_0: 0.0941 (0.1148)  loss_iou_0: 0.6233 (0.6224)  loss_ce_1: 0.0831 (0.0950)  loss_iou_1: 0.5905 (0.5928)  loss_ce_2: 0.0721 (0.0890)  loss_iou_2: 0.5888 (0.5843)  loss_ce_unscaled: 0.0406 (0.0433)  class_error_unscaled: 0.0000 (0.2108)  loss_segments_unscaled: 0.0389 (0.0445)  loss_iou_unscaled: 0.1177 (0.1178)  loss_ce_0_unscaled: 0.0470 (0.0574)  loss_segments_0_unscaled: 0.0403 (0.0465)  loss_iou_0_unscaled: 0.3116 (0.3112)  loss_ce_1_unscaled: 0.0416 (0.0475)  loss_segments_1_unscaled: 0.0393 (0.0447)  loss_iou_1_unscaled: 0.2953 (0.2964)  loss_ce_2_unscaled: 0.0361 (0.0445)  loss_segments_2_unscaled: 0.0428 (0.0444)  loss_iou_2_unscaled: 0.2944 (0.2921)  time: 0.0692  data: 0.0012  max mem: 488
[11/28 15:54:51][INFO]: Epoch: [6]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 2.2502 (2.4124)  loss_ce: 0.0891 (0.0905)  loss_iou: 0.2226 (0.2329)  loss_ce_0: 0.0983 (0.1140)  loss_iou_0: 0.5847 (0.6176)  loss_ce_1: 0.0865 (0.0966)  loss_iou_1: 0.5559 (0.5880)  loss_ce_2: 0.0904 (0.0913)  loss_iou_2: 0.5479 (0.5815)  loss_ce_unscaled: 0.0445 (0.0452)  class_error_unscaled: 0.0000 (0.3549)  loss_segments_unscaled: 0.0413 (0.0441)  loss_iou_unscaled: 0.1113 (0.1164)  loss_ce_0_unscaled: 0.0492 (0.0570)  loss_segments_0_unscaled: 0.0453 (0.0462)  loss_iou_0_unscaled: 0.2924 (0.3088)  loss_ce_1_unscaled: 0.0432 (0.0483)  loss_segments_1_unscaled: 0.0411 (0.0443)  loss_iou_1_unscaled: 0.2779 (0.2940)  loss_ce_2_unscaled: 0.0452 (0.0457)  loss_segments_2_unscaled: 0.0413 (0.0440)  loss_iou_2_unscaled: 0.2740 (0.2907)  time: 0.0690  data: 0.0012  max mem: 488
[11/28 15:54:53][INFO]: Epoch: [6]  [100/198]  eta: 0:00:07  lr: 0.000200  loss: 2.3843 (2.4164)  loss_ce: 0.0904 (0.0908)  loss_iou: 0.2454 (0.2369)  loss_ce_0: 0.1225 (0.1153)  loss_iou_0: 0.5805 (0.6160)  loss_ce_1: 0.0982 (0.0974)  loss_iou_1: 0.5673 (0.5881)  loss_ce_2: 0.0899 (0.0911)  loss_iou_2: 0.5500 (0.5808)  loss_ce_unscaled: 0.0452 (0.0454)  class_error_unscaled: 0.0000 (0.3100)  loss_segments_unscaled: 0.0424 (0.0439)  loss_iou_unscaled: 0.1227 (0.1184)  loss_ce_0_unscaled: 0.0612 (0.0577)  loss_segments_0_unscaled: 0.0453 (0.0463)  loss_iou_0_unscaled: 0.2902 (0.3080)  loss_ce_1_unscaled: 0.0491 (0.0487)  loss_segments_1_unscaled: 0.0434 (0.0442)  loss_iou_1_unscaled: 0.2837 (0.2940)  loss_ce_2_unscaled: 0.0449 (0.0455)  loss_segments_2_unscaled: 0.0424 (0.0438)  loss_iou_2_unscaled: 0.2750 (0.2904)  time: 0.0716  data: 0.0012  max mem: 488
[11/28 15:54:54][INFO]: Epoch: [6]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 2.5173 (2.4267)  loss_ce: 0.1085 (0.0947)  loss_iou: 0.2379 (0.2375)  loss_ce_0: 0.1180 (0.1171)  loss_iou_0: 0.6082 (0.6164)  loss_ce_1: 0.1069 (0.1006)  loss_iou_1: 0.5732 (0.5868)  loss_ce_2: 0.1021 (0.0938)  loss_iou_2: 0.5774 (0.5798)  loss_ce_unscaled: 0.0542 (0.0474)  class_error_unscaled: 0.0000 (0.3150)  loss_segments_unscaled: 0.0380 (0.0429)  loss_iou_unscaled: 0.1189 (0.1187)  loss_ce_0_unscaled: 0.0590 (0.0585)  loss_segments_0_unscaled: 0.0399 (0.0454)  loss_iou_0_unscaled: 0.3041 (0.3082)  loss_ce_1_unscaled: 0.0534 (0.0503)  loss_segments_1_unscaled: 0.0386 (0.0433)  loss_iou_1_unscaled: 0.2866 (0.2934)  loss_ce_2_unscaled: 0.0510 (0.0469)  loss_segments_2_unscaled: 0.0395 (0.0430)  loss_iou_2_unscaled: 0.2887 (0.2899)  time: 0.0708  data: 0.0012  max mem: 488
[11/28 15:54:56][INFO]: Epoch: [6]  [140/198]  eta: 0:00:04  lr: 0.000200  loss: 2.3653 (2.4212)  loss_ce: 0.0866 (0.0944)  loss_iou: 0.2313 (0.2374)  loss_ce_0: 0.1064 (0.1163)  loss_iou_0: 0.6057 (0.6160)  loss_ce_1: 0.1050 (0.1004)  loss_iou_1: 0.5681 (0.5845)  loss_ce_2: 0.0959 (0.0941)  loss_iou_2: 0.5714 (0.5781)  loss_ce_unscaled: 0.0433 (0.0472)  class_error_unscaled: 0.0000 (0.2809)  loss_segments_unscaled: 0.0374 (0.0427)  loss_iou_unscaled: 0.1156 (0.1187)  loss_ce_0_unscaled: 0.0532 (0.0581)  loss_segments_0_unscaled: 0.0391 (0.0453)  loss_iou_0_unscaled: 0.3029 (0.3080)  loss_ce_1_unscaled: 0.0525 (0.0502)  loss_segments_1_unscaled: 0.0368 (0.0430)  loss_iou_1_unscaled: 0.2840 (0.2923)  loss_ce_2_unscaled: 0.0480 (0.0470)  loss_segments_2_unscaled: 0.0347 (0.0427)  loss_iou_2_unscaled: 0.2857 (0.2891)  time: 0.0698  data: 0.0012  max mem: 488
[11/28 15:54:57][INFO]: Epoch: [6]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 2.4431 (2.4415)  loss_ce: 0.0990 (0.0949)  loss_iou: 0.2381 (0.2384)  loss_ce_0: 0.1212 (0.1166)  loss_iou_0: 0.6375 (0.6229)  loss_ce_1: 0.0932 (0.0997)  loss_iou_1: 0.6131 (0.5907)  loss_ce_2: 0.0929 (0.0944)  loss_iou_2: 0.6110 (0.5839)  loss_ce_unscaled: 0.0495 (0.0474)  class_error_unscaled: 0.0000 (0.2911)  loss_segments_unscaled: 0.0448 (0.0434)  loss_iou_unscaled: 0.1191 (0.1192)  loss_ce_0_unscaled: 0.0606 (0.0583)  loss_segments_0_unscaled: 0.0518 (0.0461)  loss_iou_0_unscaled: 0.3187 (0.3114)  loss_ce_1_unscaled: 0.0466 (0.0499)  loss_segments_1_unscaled: 0.0480 (0.0438)  loss_iou_1_unscaled: 0.3065 (0.2954)  loss_ce_2_unscaled: 0.0465 (0.0472)  loss_segments_2_unscaled: 0.0462 (0.0434)  loss_iou_2_unscaled: 0.3055 (0.2919)  time: 0.0708  data: 0.0012  max mem: 488
[11/28 15:54:58][INFO]: Epoch: [6]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 2.2880 (2.4296)  loss_ce: 0.0744 (0.0930)  loss_iou: 0.2329 (0.2383)  loss_ce_0: 0.1036 (0.1154)  loss_iou_0: 0.5798 (0.6214)  loss_ce_1: 0.0865 (0.0984)  loss_iou_1: 0.5463 (0.5884)  loss_ce_2: 0.0773 (0.0928)  loss_iou_2: 0.5625 (0.5819)  loss_ce_unscaled: 0.0372 (0.0465)  class_error_unscaled: 0.0000 (0.2590)  loss_segments_unscaled: 0.0370 (0.0429)  loss_iou_unscaled: 0.1165 (0.1192)  loss_ce_0_unscaled: 0.0518 (0.0577)  loss_segments_0_unscaled: 0.0382 (0.0458)  loss_iou_0_unscaled: 0.2899 (0.3107)  loss_ce_1_unscaled: 0.0432 (0.0492)  loss_segments_1_unscaled: 0.0355 (0.0433)  loss_iou_1_unscaled: 0.2731 (0.2942)  loss_ce_2_unscaled: 0.0387 (0.0464)  loss_segments_2_unscaled: 0.0343 (0.0430)  loss_iou_2_unscaled: 0.2812 (0.2910)  time: 0.0683  data: 0.0011  max mem: 488
[11/28 15:55:00][INFO]: Epoch: [6]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 2.2245 (2.4136)  loss_ce: 0.0787 (0.0924)  loss_iou: 0.2190 (0.2369)  loss_ce_0: 0.1037 (0.1144)  loss_iou_0: 0.5566 (0.6177)  loss_ce_1: 0.0796 (0.0972)  loss_iou_1: 0.5241 (0.5845)  loss_ce_2: 0.0800 (0.0919)  loss_iou_2: 0.5277 (0.5785)  loss_ce_unscaled: 0.0393 (0.0462)  class_error_unscaled: 0.0000 (0.2367)  loss_segments_unscaled: 0.0401 (0.0425)  loss_iou_unscaled: 0.1095 (0.1185)  loss_ce_0_unscaled: 0.0519 (0.0572)  loss_segments_0_unscaled: 0.0414 (0.0455)  loss_iou_0_unscaled: 0.2783 (0.3088)  loss_ce_1_unscaled: 0.0398 (0.0486)  loss_segments_1_unscaled: 0.0395 (0.0429)  loss_iou_1_unscaled: 0.2620 (0.2923)  loss_ce_2_unscaled: 0.0400 (0.0460)  loss_segments_2_unscaled: 0.0400 (0.0427)  loss_iou_2_unscaled: 0.2639 (0.2893)  time: 0.0690  data: 0.0012  max mem: 488
[11/28 15:55:00][INFO]: Epoch: [6] Total time: 0:00:14 (0.0712 s / it)
[11/28 15:55:00][INFO]: Averaged stats:lr: 0.000200  loss: 2.2245 (2.4136)  loss_ce: 0.0787 (0.0924)  loss_iou: 0.2190 (0.2369)  loss_ce_0: 0.1037 (0.1144)  loss_iou_0: 0.5566 (0.6177)  loss_ce_1: 0.0796 (0.0972)  loss_iou_1: 0.5241 (0.5845)  loss_ce_2: 0.0800 (0.0919)  loss_iou_2: 0.5277 (0.5785)  loss_ce_unscaled: 0.0393 (0.0462)  class_error_unscaled: 0.0000 (0.2367)  loss_segments_unscaled: 0.0401 (0.0425)  loss_iou_unscaled: 0.1095 (0.1185)  loss_ce_0_unscaled: 0.0519 (0.0572)  loss_segments_0_unscaled: 0.0414 (0.0455)  loss_iou_0_unscaled: 0.2783 (0.3088)  loss_ce_1_unscaled: 0.0398 (0.0486)  loss_segments_1_unscaled: 0.0395 (0.0429)  loss_iou_1_unscaled: 0.2620 (0.2923)  loss_ce_2_unscaled: 0.0400 (0.0460)  loss_segments_2_unscaled: 0.0400 (0.0427)  loss_iou_2_unscaled: 0.2639 (0.2893)
[11/28 15:55:00][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 26.05it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:55:08][INFO]: mode=raw 120864 predictions from 210 videos
[11/28 15:55:11][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
71.62 66.04 55.93 42.91 28.34 52.97 raw epoch6
[11/28 15:55:11][INFO]: mAP_raw: 52.97
[11/28 15:55:11][INFO]: new best metric 0.5297@epoch6
[11/28 15:55:11][INFO]: lr=0.0002
[11/28 15:55:11][INFO]: lr=1e-05
[11/28 15:55:11][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:55:12][INFO]: Epoch: [7]  [  0/198]  eta: 0:00:59  lr: 0.000200  loss: 2.0932 (2.0932)  loss_ce: 0.1047 (0.1047)  loss_iou: 0.2261 (0.2261)  loss_ce_0: 0.1098 (0.1098)  loss_iou_0: 0.5253 (0.5253)  loss_ce_1: 0.1284 (0.1284)  loss_iou_1: 0.4505 (0.4505)  loss_ce_2: 0.1089 (0.1089)  loss_iou_2: 0.4393 (0.4393)  loss_ce_unscaled: 0.0524 (0.0524)  class_error_unscaled: 2.3810 (2.3810)  loss_segments_unscaled: 0.0590 (0.0590)  loss_iou_unscaled: 0.1130 (0.1130)  loss_ce_0_unscaled: 0.0549 (0.0549)  loss_segments_0_unscaled: 0.0841 (0.0841)  loss_iou_0_unscaled: 0.2627 (0.2627)  loss_ce_1_unscaled: 0.0642 (0.0642)  loss_segments_1_unscaled: 0.0656 (0.0656)  loss_iou_1_unscaled: 0.2253 (0.2253)  loss_ce_2_unscaled: 0.0545 (0.0545)  loss_segments_2_unscaled: 0.0648 (0.0648)  loss_iou_2_unscaled: 0.2197 (0.2197)  time: 0.2992  data: 0.2119  max mem: 488
[11/28 15:55:13][INFO]: Epoch: [7]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 2.2108 (2.2916)  loss_ce: 0.0758 (0.0822)  loss_iou: 0.2182 (0.2249)  loss_ce_0: 0.1020 (0.1003)  loss_iou_0: 0.6070 (0.6036)  loss_ce_1: 0.0783 (0.0868)  loss_iou_1: 0.5638 (0.5596)  loss_ce_2: 0.0802 (0.0846)  loss_iou_2: 0.5373 (0.5496)  loss_ce_unscaled: 0.0379 (0.0411)  class_error_unscaled: 0.0000 (0.4721)  loss_segments_unscaled: 0.0380 (0.0392)  loss_iou_unscaled: 0.1091 (0.1124)  loss_ce_0_unscaled: 0.0510 (0.0502)  loss_segments_0_unscaled: 0.0430 (0.0436)  loss_iou_0_unscaled: 0.3035 (0.3018)  loss_ce_1_unscaled: 0.0391 (0.0434)  loss_segments_1_unscaled: 0.0389 (0.0398)  loss_iou_1_unscaled: 0.2819 (0.2798)  loss_ce_2_unscaled: 0.0401 (0.0423)  loss_segments_2_unscaled: 0.0388 (0.0398)  loss_iou_2_unscaled: 0.2687 (0.2748)  time: 0.0700  data: 0.0012  max mem: 488
[11/28 15:55:14][INFO]: Epoch: [7]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 2.1718 (2.2171)  loss_ce: 0.0742 (0.0786)  loss_iou: 0.2227 (0.2287)  loss_ce_0: 0.0929 (0.0977)  loss_iou_0: 0.5547 (0.5789)  loss_ce_1: 0.0694 (0.0812)  loss_iou_1: 0.5304 (0.5410)  loss_ce_2: 0.0665 (0.0795)  loss_iou_2: 0.5128 (0.5315)  loss_ce_unscaled: 0.0371 (0.0393)  class_error_unscaled: 0.0000 (0.3467)  loss_segments_unscaled: 0.0345 (0.0378)  loss_iou_unscaled: 0.1113 (0.1143)  loss_ce_0_unscaled: 0.0464 (0.0488)  loss_segments_0_unscaled: 0.0389 (0.0420)  loss_iou_0_unscaled: 0.2774 (0.2894)  loss_ce_1_unscaled: 0.0347 (0.0406)  loss_segments_1_unscaled: 0.0356 (0.0387)  loss_iou_1_unscaled: 0.2652 (0.2705)  loss_ce_2_unscaled: 0.0332 (0.0398)  loss_segments_2_unscaled: 0.0344 (0.0382)  loss_iou_2_unscaled: 0.2564 (0.2657)  time: 0.0680  data: 0.0011  max mem: 488
[11/28 15:55:16][INFO]: Epoch: [7]  [ 60/198]  eta: 0:00:09  lr: 0.000200  loss: 2.1704 (2.2391)  loss_ce: 0.0820 (0.0796)  loss_iou: 0.2326 (0.2318)  loss_ce_0: 0.0956 (0.0966)  loss_iou_0: 0.5575 (0.5831)  loss_ce_1: 0.0729 (0.0799)  loss_iou_1: 0.5488 (0.5482)  loss_ce_2: 0.0778 (0.0797)  loss_iou_2: 0.5495 (0.5401)  loss_ce_unscaled: 0.0410 (0.0398)  class_error_unscaled: 0.0000 (0.2858)  loss_segments_unscaled: 0.0399 (0.0387)  loss_iou_unscaled: 0.1163 (0.1159)  loss_ce_0_unscaled: 0.0478 (0.0483)  loss_segments_0_unscaled: 0.0415 (0.0426)  loss_iou_0_unscaled: 0.2787 (0.2916)  loss_ce_1_unscaled: 0.0365 (0.0399)  loss_segments_1_unscaled: 0.0403 (0.0395)  loss_iou_1_unscaled: 0.2744 (0.2741)  loss_ce_2_unscaled: 0.0389 (0.0399)  loss_segments_2_unscaled: 0.0398 (0.0388)  loss_iou_2_unscaled: 0.2748 (0.2701)  time: 0.0678  data: 0.0013  max mem: 488
[11/28 15:55:17][INFO]: Epoch: [7]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 2.1810 (2.2429)  loss_ce: 0.0725 (0.0792)  loss_iou: 0.2280 (0.2324)  loss_ce_0: 0.1033 (0.0973)  loss_iou_0: 0.5565 (0.5835)  loss_ce_1: 0.0783 (0.0800)  loss_iou_1: 0.5206 (0.5489)  loss_ce_2: 0.0780 (0.0804)  loss_iou_2: 0.5305 (0.5413)  loss_ce_unscaled: 0.0362 (0.0396)  class_error_unscaled: 0.0000 (0.2153)  loss_segments_unscaled: 0.0372 (0.0388)  loss_iou_unscaled: 0.1140 (0.1162)  loss_ce_0_unscaled: 0.0516 (0.0487)  loss_segments_0_unscaled: 0.0421 (0.0425)  loss_iou_0_unscaled: 0.2783 (0.2917)  loss_ce_1_unscaled: 0.0392 (0.0400)  loss_segments_1_unscaled: 0.0375 (0.0396)  loss_iou_1_unscaled: 0.2603 (0.2744)  loss_ce_2_unscaled: 0.0390 (0.0402)  loss_segments_2_unscaled: 0.0373 (0.0390)  loss_iou_2_unscaled: 0.2652 (0.2707)  time: 0.0677  data: 0.0012  max mem: 488
[11/28 15:55:18][INFO]: Epoch: [7]  [100/198]  eta: 0:00:06  lr: 0.000200  loss: 2.0484 (2.2104)  loss_ce: 0.0687 (0.0774)  loss_iou: 0.2204 (0.2306)  loss_ce_0: 0.0913 (0.0964)  loss_iou_0: 0.5260 (0.5763)  loss_ce_1: 0.0716 (0.0791)  loss_iou_1: 0.4882 (0.5393)  loss_ce_2: 0.0681 (0.0784)  loss_iou_2: 0.5058 (0.5329)  loss_ce_unscaled: 0.0343 (0.0387)  class_error_unscaled: 0.0000 (0.1726)  loss_segments_unscaled: 0.0335 (0.0380)  loss_iou_unscaled: 0.1102 (0.1153)  loss_ce_0_unscaled: 0.0456 (0.0482)  loss_segments_0_unscaled: 0.0370 (0.0418)  loss_iou_0_unscaled: 0.2630 (0.2882)  loss_ce_1_unscaled: 0.0358 (0.0396)  loss_segments_1_unscaled: 0.0342 (0.0387)  loss_iou_1_unscaled: 0.2441 (0.2696)  loss_ce_2_unscaled: 0.0341 (0.0392)  loss_segments_2_unscaled: 0.0335 (0.0381)  loss_iou_2_unscaled: 0.2529 (0.2664)  time: 0.0684  data: 0.0012  max mem: 488
[11/28 15:55:20][INFO]: Epoch: [7]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 2.2808 (2.2309)  loss_ce: 0.0794 (0.0774)  loss_iou: 0.2352 (0.2317)  loss_ce_0: 0.1029 (0.0984)  loss_iou_0: 0.6048 (0.5823)  loss_ce_1: 0.0758 (0.0798)  loss_iou_1: 0.5541 (0.5451)  loss_ce_2: 0.0739 (0.0785)  loss_iou_2: 0.5544 (0.5379)  loss_ce_unscaled: 0.0397 (0.0387)  class_error_unscaled: 0.0000 (0.1664)  loss_segments_unscaled: 0.0392 (0.0384)  loss_iou_unscaled: 0.1176 (0.1158)  loss_ce_0_unscaled: 0.0515 (0.0492)  loss_segments_0_unscaled: 0.0420 (0.0422)  loss_iou_0_unscaled: 0.3024 (0.2912)  loss_ce_1_unscaled: 0.0379 (0.0399)  loss_segments_1_unscaled: 0.0392 (0.0391)  loss_iou_1_unscaled: 0.2770 (0.2725)  loss_ce_2_unscaled: 0.0369 (0.0392)  loss_segments_2_unscaled: 0.0396 (0.0385)  loss_iou_2_unscaled: 0.2772 (0.2689)  time: 0.0680  data: 0.0012  max mem: 488
[11/28 15:55:21][INFO]: Epoch: [7]  [140/198]  eta: 0:00:04  lr: 0.000200  loss: 2.2450 (2.2378)  loss_ce: 0.0631 (0.0779)  loss_iou: 0.2391 (0.2324)  loss_ce_0: 0.0959 (0.0976)  loss_iou_0: 0.5805 (0.5845)  loss_ce_1: 0.0793 (0.0800)  loss_iou_1: 0.5503 (0.5471)  loss_ce_2: 0.0668 (0.0785)  loss_iou_2: 0.5421 (0.5398)  loss_ce_unscaled: 0.0316 (0.0389)  class_error_unscaled: 0.0000 (0.1562)  loss_segments_unscaled: 0.0324 (0.0380)  loss_iou_unscaled: 0.1196 (0.1162)  loss_ce_0_unscaled: 0.0480 (0.0488)  loss_segments_0_unscaled: 0.0347 (0.0419)  loss_iou_0_unscaled: 0.2903 (0.2922)  loss_ce_1_unscaled: 0.0396 (0.0400)  loss_segments_1_unscaled: 0.0305 (0.0387)  loss_iou_1_unscaled: 0.2752 (0.2735)  loss_ce_2_unscaled: 0.0334 (0.0392)  loss_segments_2_unscaled: 0.0326 (0.0382)  loss_iou_2_unscaled: 0.2711 (0.2699)  time: 0.0674  data: 0.0012  max mem: 488
[11/28 15:55:22][INFO]: Epoch: [7]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 2.1141 (2.2284)  loss_ce: 0.0491 (0.0756)  loss_iou: 0.2273 (0.2318)  loss_ce_0: 0.0742 (0.0960)  loss_iou_0: 0.5831 (0.5840)  loss_ce_1: 0.0601 (0.0787)  loss_iou_1: 0.5279 (0.5460)  loss_ce_2: 0.0612 (0.0770)  loss_iou_2: 0.5092 (0.5393)  loss_ce_unscaled: 0.0245 (0.0378)  class_error_unscaled: 0.0000 (0.1368)  loss_segments_unscaled: 0.0312 (0.0375)  loss_iou_unscaled: 0.1137 (0.1159)  loss_ce_0_unscaled: 0.0371 (0.0480)  loss_segments_0_unscaled: 0.0359 (0.0413)  loss_iou_0_unscaled: 0.2916 (0.2920)  loss_ce_1_unscaled: 0.0300 (0.0394)  loss_segments_1_unscaled: 0.0312 (0.0381)  loss_iou_1_unscaled: 0.2639 (0.2730)  loss_ce_2_unscaled: 0.0306 (0.0385)  loss_segments_2_unscaled: 0.0322 (0.0376)  loss_iou_2_unscaled: 0.2546 (0.2696)  time: 0.0681  data: 0.0012  max mem: 488
[11/28 15:55:24][INFO]: Epoch: [7]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 2.1458 (2.2152)  loss_ce: 0.0664 (0.0746)  loss_iou: 0.2257 (0.2317)  loss_ce_0: 0.1012 (0.0963)  loss_iou_0: 0.5543 (0.5803)  loss_ce_1: 0.0653 (0.0777)  loss_iou_1: 0.5307 (0.5423)  loss_ce_2: 0.0640 (0.0760)  loss_iou_2: 0.5303 (0.5364)  loss_ce_unscaled: 0.0332 (0.0373)  class_error_unscaled: 0.0000 (0.1217)  loss_segments_unscaled: 0.0349 (0.0377)  loss_iou_unscaled: 0.1128 (0.1158)  loss_ce_0_unscaled: 0.0506 (0.0481)  loss_segments_0_unscaled: 0.0400 (0.0415)  loss_iou_0_unscaled: 0.2772 (0.2902)  loss_ce_1_unscaled: 0.0326 (0.0388)  loss_segments_1_unscaled: 0.0371 (0.0384)  loss_iou_1_unscaled: 0.2653 (0.2712)  loss_ce_2_unscaled: 0.0320 (0.0380)  loss_segments_2_unscaled: 0.0354 (0.0379)  loss_iou_2_unscaled: 0.2652 (0.2682)  time: 0.0692  data: 0.0012  max mem: 488
[11/28 15:55:25][INFO]: Epoch: [7]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 2.3261 (2.2225)  loss_ce: 0.0831 (0.0762)  loss_iou: 0.2241 (0.2312)  loss_ce_0: 0.1143 (0.0981)  loss_iou_0: 0.5688 (0.5798)  loss_ce_1: 0.0873 (0.0801)  loss_iou_1: 0.5426 (0.5428)  loss_ce_2: 0.0874 (0.0779)  loss_iou_2: 0.5427 (0.5365)  loss_ce_unscaled: 0.0416 (0.0381)  class_error_unscaled: 0.0000 (0.1311)  loss_segments_unscaled: 0.0410 (0.0379)  loss_iou_unscaled: 0.1120 (0.1156)  loss_ce_0_unscaled: 0.0572 (0.0491)  loss_segments_0_unscaled: 0.0410 (0.0416)  loss_iou_0_unscaled: 0.2844 (0.2899)  loss_ce_1_unscaled: 0.0436 (0.0400)  loss_segments_1_unscaled: 0.0406 (0.0385)  loss_iou_1_unscaled: 0.2713 (0.2714)  loss_ce_2_unscaled: 0.0437 (0.0390)  loss_segments_2_unscaled: 0.0411 (0.0381)  loss_iou_2_unscaled: 0.2713 (0.2682)  time: 0.0668  data: 0.0012  max mem: 488
[11/28 15:55:25][INFO]: Epoch: [7] Total time: 0:00:13 (0.0696 s / it)
[11/28 15:55:25][INFO]: Averaged stats:lr: 0.000200  loss: 2.3261 (2.2225)  loss_ce: 0.0831 (0.0762)  loss_iou: 0.2241 (0.2312)  loss_ce_0: 0.1143 (0.0981)  loss_iou_0: 0.5688 (0.5798)  loss_ce_1: 0.0873 (0.0801)  loss_iou_1: 0.5426 (0.5428)  loss_ce_2: 0.0874 (0.0779)  loss_iou_2: 0.5427 (0.5365)  loss_ce_unscaled: 0.0416 (0.0381)  class_error_unscaled: 0.0000 (0.1311)  loss_segments_unscaled: 0.0410 (0.0379)  loss_iou_unscaled: 0.1120 (0.1156)  loss_ce_0_unscaled: 0.0572 (0.0491)  loss_segments_0_unscaled: 0.0410 (0.0416)  loss_iou_0_unscaled: 0.2844 (0.2899)  loss_ce_1_unscaled: 0.0436 (0.0400)  loss_segments_1_unscaled: 0.0406 (0.0385)  loss_iou_1_unscaled: 0.2713 (0.2714)  loss_ce_2_unscaled: 0.0437 (0.0390)  loss_segments_2_unscaled: 0.0411 (0.0381)  loss_iou_2_unscaled: 0.2713 (0.2682)
[11/28 15:55:25][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 26.04it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:55:33][INFO]: mode=raw 127284 predictions from 210 videos
[11/28 15:55:37][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
65.93 60.14 51.34 37.46 22.35 47.44 raw epoch7
[11/28 15:55:37][INFO]: mAP_raw: 47.44
[11/28 15:55:37][INFO]: lr=0.0002
[11/28 15:55:37][INFO]: lr=1e-05
[11/28 15:55:37][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:55:37][INFO]: Epoch: [8]  [  0/198]  eta: 0:00:56  lr: 0.000200  loss: 2.3625 (2.3625)  loss_ce: 0.0461 (0.0461)  loss_iou: 0.2499 (0.2499)  loss_ce_0: 0.0851 (0.0851)  loss_iou_0: 0.6586 (0.6586)  loss_ce_1: 0.0658 (0.0658)  loss_iou_1: 0.6044 (0.6044)  loss_ce_2: 0.0569 (0.0569)  loss_iou_2: 0.5957 (0.5957)  loss_ce_unscaled: 0.0231 (0.0231)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0457 (0.0457)  loss_iou_unscaled: 0.1250 (0.1250)  loss_ce_0_unscaled: 0.0425 (0.0425)  loss_segments_0_unscaled: 0.0510 (0.0510)  loss_iou_0_unscaled: 0.3293 (0.3293)  loss_ce_1_unscaled: 0.0329 (0.0329)  loss_segments_1_unscaled: 0.0466 (0.0466)  loss_iou_1_unscaled: 0.3022 (0.3022)  loss_ce_2_unscaled: 0.0284 (0.0284)  loss_segments_2_unscaled: 0.0457 (0.0457)  loss_iou_2_unscaled: 0.2978 (0.2978)  time: 0.2859  data: 0.1886  max mem: 488
[11/28 15:55:38][INFO]: Epoch: [8]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 2.2271 (2.2155)  loss_ce: 0.0777 (0.0834)  loss_iou: 0.2231 (0.2273)  loss_ce_0: 0.1045 (0.1048)  loss_iou_0: 0.5749 (0.5696)  loss_ce_1: 0.0845 (0.0909)  loss_iou_1: 0.5366 (0.5321)  loss_ce_2: 0.0850 (0.0847)  loss_iou_2: 0.5203 (0.5226)  loss_ce_unscaled: 0.0388 (0.0417)  class_error_unscaled: 0.0000 (0.2458)  loss_segments_unscaled: 0.0377 (0.0395)  loss_iou_unscaled: 0.1116 (0.1136)  loss_ce_0_unscaled: 0.0523 (0.0524)  loss_segments_0_unscaled: 0.0402 (0.0430)  loss_iou_0_unscaled: 0.2875 (0.2848)  loss_ce_1_unscaled: 0.0423 (0.0454)  loss_segments_1_unscaled: 0.0370 (0.0394)  loss_iou_1_unscaled: 0.2683 (0.2661)  loss_ce_2_unscaled: 0.0425 (0.0424)  loss_segments_2_unscaled: 0.0368 (0.0389)  loss_iou_2_unscaled: 0.2602 (0.2613)  time: 0.0699  data: 0.0012  max mem: 488
[11/28 15:55:40][INFO]: Epoch: [8]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 2.3300 (2.2592)  loss_ce: 0.0816 (0.0849)  loss_iou: 0.2200 (0.2266)  loss_ce_0: 0.0870 (0.1014)  loss_iou_0: 0.6186 (0.5849)  loss_ce_1: 0.0750 (0.0890)  loss_iou_1: 0.5756 (0.5471)  loss_ce_2: 0.0738 (0.0832)  loss_iou_2: 0.5765 (0.5421)  loss_ce_unscaled: 0.0408 (0.0424)  class_error_unscaled: 0.0000 (0.2046)  loss_segments_unscaled: 0.0410 (0.0404)  loss_iou_unscaled: 0.1100 (0.1133)  loss_ce_0_unscaled: 0.0435 (0.0507)  loss_segments_0_unscaled: 0.0441 (0.0436)  loss_iou_0_unscaled: 0.3093 (0.2925)  loss_ce_1_unscaled: 0.0375 (0.0445)  loss_segments_1_unscaled: 0.0426 (0.0406)  loss_iou_1_unscaled: 0.2878 (0.2735)  loss_ce_2_unscaled: 0.0369 (0.0416)  loss_segments_2_unscaled: 0.0415 (0.0404)  loss_iou_2_unscaled: 0.2883 (0.2711)  time: 0.0693  data: 0.0012  max mem: 488
[11/28 15:55:41][INFO]: Epoch: [8]  [ 60/198]  eta: 0:00:10  lr: 0.000200  loss: 2.2425 (2.2486)  loss_ce: 0.0787 (0.0849)  loss_iou: 0.2215 (0.2269)  loss_ce_0: 0.1057 (0.1050)  loss_iou_0: 0.5692 (0.5822)  loss_ce_1: 0.0884 (0.0886)  loss_iou_1: 0.5273 (0.5412)  loss_ce_2: 0.0823 (0.0829)  loss_iou_2: 0.5197 (0.5370)  loss_ce_unscaled: 0.0394 (0.0424)  class_error_unscaled: 0.0000 (0.2688)  loss_segments_unscaled: 0.0379 (0.0397)  loss_iou_unscaled: 0.1107 (0.1134)  loss_ce_0_unscaled: 0.0528 (0.0525)  loss_segments_0_unscaled: 0.0414 (0.0434)  loss_iou_0_unscaled: 0.2846 (0.2911)  loss_ce_1_unscaled: 0.0442 (0.0443)  loss_segments_1_unscaled: 0.0366 (0.0402)  loss_iou_1_unscaled: 0.2637 (0.2706)  loss_ce_2_unscaled: 0.0412 (0.0415)  loss_segments_2_unscaled: 0.0379 (0.0402)  loss_iou_2_unscaled: 0.2599 (0.2685)  time: 0.0704  data: 0.0012  max mem: 488
[11/28 15:55:43][INFO]: Epoch: [8]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 1.9330 (2.1925)  loss_ce: 0.0589 (0.0789)  loss_iou: 0.2348 (0.2298)  loss_ce_0: 0.0797 (0.1000)  loss_iou_0: 0.5065 (0.5693)  loss_ce_1: 0.0649 (0.0840)  loss_iou_1: 0.4835 (0.5284)  loss_ce_2: 0.0635 (0.0784)  loss_iou_2: 0.4689 (0.5238)  loss_ce_unscaled: 0.0295 (0.0394)  class_error_unscaled: 0.0000 (0.2651)  loss_segments_unscaled: 0.0306 (0.0379)  loss_iou_unscaled: 0.1174 (0.1149)  loss_ce_0_unscaled: 0.0399 (0.0500)  loss_segments_0_unscaled: 0.0352 (0.0416)  loss_iou_0_unscaled: 0.2533 (0.2847)  loss_ce_1_unscaled: 0.0324 (0.0420)  loss_segments_1_unscaled: 0.0315 (0.0383)  loss_iou_1_unscaled: 0.2417 (0.2642)  loss_ce_2_unscaled: 0.0317 (0.0392)  loss_segments_2_unscaled: 0.0306 (0.0383)  loss_iou_2_unscaled: 0.2345 (0.2619)  time: 0.0708  data: 0.0012  max mem: 488
[11/28 15:55:44][INFO]: Epoch: [8]  [100/198]  eta: 0:00:07  lr: 0.000200  loss: 2.0817 (2.1775)  loss_ce: 0.0661 (0.0768)  loss_iou: 0.2206 (0.2285)  loss_ce_0: 0.0783 (0.0963)  loss_iou_0: 0.5425 (0.5678)  loss_ce_1: 0.0741 (0.0819)  loss_iou_1: 0.4980 (0.5269)  loss_ce_2: 0.0677 (0.0767)  loss_iou_2: 0.4911 (0.5226)  loss_ce_unscaled: 0.0330 (0.0384)  class_error_unscaled: 0.0000 (0.2254)  loss_segments_unscaled: 0.0383 (0.0379)  loss_iou_unscaled: 0.1103 (0.1142)  loss_ce_0_unscaled: 0.0392 (0.0481)  loss_segments_0_unscaled: 0.0404 (0.0413)  loss_iou_0_unscaled: 0.2713 (0.2839)  loss_ce_1_unscaled: 0.0370 (0.0410)  loss_segments_1_unscaled: 0.0380 (0.0380)  loss_iou_1_unscaled: 0.2490 (0.2634)  loss_ce_2_unscaled: 0.0339 (0.0383)  loss_segments_2_unscaled: 0.0378 (0.0381)  loss_iou_2_unscaled: 0.2456 (0.2613)  time: 0.0662  data: 0.0011  max mem: 488
[11/28 15:55:45][INFO]: Epoch: [8]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 2.0153 (2.1652)  loss_ce: 0.0650 (0.0752)  loss_iou: 0.2232 (0.2291)  loss_ce_0: 0.0931 (0.0954)  loss_iou_0: 0.5180 (0.5644)  loss_ce_1: 0.0724 (0.0808)  loss_iou_1: 0.4858 (0.5245)  loss_ce_2: 0.0694 (0.0757)  loss_iou_2: 0.4877 (0.5200)  loss_ce_unscaled: 0.0325 (0.0376)  class_error_unscaled: 0.0000 (0.1998)  loss_segments_unscaled: 0.0357 (0.0378)  loss_iou_unscaled: 0.1116 (0.1145)  loss_ce_0_unscaled: 0.0465 (0.0477)  loss_segments_0_unscaled: 0.0368 (0.0410)  loss_iou_0_unscaled: 0.2590 (0.2822)  loss_ce_1_unscaled: 0.0362 (0.0404)  loss_segments_1_unscaled: 0.0347 (0.0379)  loss_iou_1_unscaled: 0.2429 (0.2623)  loss_ce_2_unscaled: 0.0347 (0.0379)  loss_segments_2_unscaled: 0.0358 (0.0379)  loss_iou_2_unscaled: 0.2438 (0.2600)  time: 0.0664  data: 0.0011  max mem: 488
[11/28 15:55:47][INFO]: Epoch: [8]  [140/198]  eta: 0:00:04  lr: 0.000200  loss: 2.1521 (2.1726)  loss_ce: 0.0650 (0.0744)  loss_iou: 0.2277 (0.2293)  loss_ce_0: 0.0873 (0.0951)  loss_iou_0: 0.5837 (0.5676)  loss_ce_1: 0.0686 (0.0797)  loss_iou_1: 0.5402 (0.5280)  loss_ce_2: 0.0658 (0.0752)  loss_iou_2: 0.5340 (0.5235)  loss_ce_unscaled: 0.0325 (0.0372)  class_error_unscaled: 0.0000 (0.1819)  loss_segments_unscaled: 0.0328 (0.0376)  loss_iou_unscaled: 0.1139 (0.1146)  loss_ce_0_unscaled: 0.0437 (0.0475)  loss_segments_0_unscaled: 0.0352 (0.0408)  loss_iou_0_unscaled: 0.2919 (0.2838)  loss_ce_1_unscaled: 0.0343 (0.0398)  loss_segments_1_unscaled: 0.0334 (0.0378)  loss_iou_1_unscaled: 0.2701 (0.2640)  loss_ce_2_unscaled: 0.0329 (0.0376)  loss_segments_2_unscaled: 0.0328 (0.0378)  loss_iou_2_unscaled: 0.2670 (0.2617)  time: 0.0678  data: 0.0011  max mem: 488
[11/28 15:55:48][INFO]: Epoch: [8]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 2.2035 (2.1734)  loss_ce: 0.0735 (0.0756)  loss_iou: 0.2175 (0.2289)  loss_ce_0: 0.1046 (0.0968)  loss_iou_0: 0.5690 (0.5662)  loss_ce_1: 0.0889 (0.0806)  loss_iou_1: 0.5179 (0.5268)  loss_ce_2: 0.0848 (0.0767)  loss_iou_2: 0.5016 (0.5217)  loss_ce_unscaled: 0.0368 (0.0378)  class_error_unscaled: 0.0000 (0.1593)  loss_segments_unscaled: 0.0338 (0.0372)  loss_iou_unscaled: 0.1088 (0.1144)  loss_ce_0_unscaled: 0.0523 (0.0484)  loss_segments_0_unscaled: 0.0347 (0.0405)  loss_iou_0_unscaled: 0.2845 (0.2831)  loss_ce_1_unscaled: 0.0445 (0.0403)  loss_segments_1_unscaled: 0.0339 (0.0376)  loss_iou_1_unscaled: 0.2589 (0.2634)  loss_ce_2_unscaled: 0.0424 (0.0384)  loss_segments_2_unscaled: 0.0334 (0.0374)  loss_iou_2_unscaled: 0.2508 (0.2609)  time: 0.0672  data: 0.0011  max mem: 488
[11/28 15:55:49][INFO]: Epoch: [8]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 1.9019 (2.1623)  loss_ce: 0.0656 (0.0753)  loss_iou: 0.2297 (0.2294)  loss_ce_0: 0.1021 (0.0974)  loss_iou_0: 0.4789 (0.5631)  loss_ce_1: 0.0790 (0.0806)  loss_iou_1: 0.4476 (0.5231)  loss_ce_2: 0.0659 (0.0757)  loss_iou_2: 0.4444 (0.5177)  loss_ce_unscaled: 0.0328 (0.0376)  class_error_unscaled: 0.0000 (0.1417)  loss_segments_unscaled: 0.0343 (0.0372)  loss_iou_unscaled: 0.1149 (0.1147)  loss_ce_0_unscaled: 0.0510 (0.0487)  loss_segments_0_unscaled: 0.0378 (0.0406)  loss_iou_0_unscaled: 0.2395 (0.2815)  loss_ce_1_unscaled: 0.0395 (0.0403)  loss_segments_1_unscaled: 0.0357 (0.0376)  loss_iou_1_unscaled: 0.2238 (0.2615)  loss_ce_2_unscaled: 0.0330 (0.0379)  loss_segments_2_unscaled: 0.0350 (0.0375)  loss_iou_2_unscaled: 0.2222 (0.2588)  time: 0.0667  data: 0.0013  max mem: 488
[11/28 15:55:51][INFO]: Epoch: [8]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 1.9074 (2.1508)  loss_ce: 0.0611 (0.0740)  loss_iou: 0.2315 (0.2299)  loss_ce_0: 0.0797 (0.0966)  loss_iou_0: 0.4788 (0.5599)  loss_ce_1: 0.0727 (0.0800)  loss_iou_1: 0.4361 (0.5204)  loss_ce_2: 0.0611 (0.0748)  loss_iou_2: 0.4437 (0.5152)  loss_ce_unscaled: 0.0306 (0.0370)  class_error_unscaled: 0.0000 (0.1295)  loss_segments_unscaled: 0.0343 (0.0371)  loss_iou_unscaled: 0.1158 (0.1149)  loss_ce_0_unscaled: 0.0398 (0.0483)  loss_segments_0_unscaled: 0.0362 (0.0404)  loss_iou_0_unscaled: 0.2394 (0.2799)  loss_ce_1_unscaled: 0.0364 (0.0400)  loss_segments_1_unscaled: 0.0327 (0.0375)  loss_iou_1_unscaled: 0.2180 (0.2602)  loss_ce_2_unscaled: 0.0305 (0.0374)  loss_segments_2_unscaled: 0.0343 (0.0373)  loss_iou_2_unscaled: 0.2218 (0.2576)  time: 0.0676  data: 0.0013  max mem: 488
[11/28 15:55:51][INFO]: Epoch: [8] Total time: 0:00:13 (0.0696 s / it)
[11/28 15:55:51][INFO]: Averaged stats:lr: 0.000200  loss: 1.9074 (2.1508)  loss_ce: 0.0611 (0.0740)  loss_iou: 0.2315 (0.2299)  loss_ce_0: 0.0797 (0.0966)  loss_iou_0: 0.4788 (0.5599)  loss_ce_1: 0.0727 (0.0800)  loss_iou_1: 0.4361 (0.5204)  loss_ce_2: 0.0611 (0.0748)  loss_iou_2: 0.4437 (0.5152)  loss_ce_unscaled: 0.0306 (0.0370)  class_error_unscaled: 0.0000 (0.1295)  loss_segments_unscaled: 0.0343 (0.0371)  loss_iou_unscaled: 0.1158 (0.1149)  loss_ce_0_unscaled: 0.0398 (0.0483)  loss_segments_0_unscaled: 0.0362 (0.0404)  loss_iou_0_unscaled: 0.2394 (0.2799)  loss_ce_1_unscaled: 0.0364 (0.0400)  loss_segments_1_unscaled: 0.0327 (0.0375)  loss_iou_1_unscaled: 0.2180 (0.2602)  loss_ce_2_unscaled: 0.0305 (0.0374)  loss_segments_2_unscaled: 0.0343 (0.0373)  loss_iou_2_unscaled: 0.2218 (0.2576)
[11/28 15:55:51][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 25.88it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:55:59][INFO]: mode=raw 123928 predictions from 210 videos
[11/28 15:56:02][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
70.84 65.57 56.11 45.64 29.25 53.48 raw epoch8
[11/28 15:56:02][INFO]: mAP_raw: 53.48
[11/28 15:56:02][INFO]: new best metric 0.5348@epoch8
[11/28 15:56:02][INFO]: lr=0.0002
[11/28 15:56:02][INFO]: lr=1e-05
[11/28 15:56:02][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:56:03][INFO]: Epoch: [9]  [  0/198]  eta: 0:01:01  lr: 0.000200  loss: 2.7362 (2.7362)  loss_ce: 0.0968 (0.0968)  loss_iou: 0.2207 (0.2207)  loss_ce_0: 0.1041 (0.1041)  loss_iou_0: 0.7377 (0.7377)  loss_ce_1: 0.0870 (0.0870)  loss_iou_1: 0.7096 (0.7096)  loss_ce_2: 0.0960 (0.0960)  loss_iou_2: 0.6842 (0.6842)  loss_ce_unscaled: 0.0484 (0.0484)  class_error_unscaled: 1.5873 (1.5873)  loss_segments_unscaled: 0.0347 (0.0347)  loss_iou_unscaled: 0.1103 (0.1103)  loss_ce_0_unscaled: 0.0521 (0.0521)  loss_segments_0_unscaled: 0.0354 (0.0354)  loss_iou_0_unscaled: 0.3689 (0.3689)  loss_ce_1_unscaled: 0.0435 (0.0435)  loss_segments_1_unscaled: 0.0321 (0.0321)  loss_iou_1_unscaled: 0.3548 (0.3548)  loss_ce_2_unscaled: 0.0480 (0.0480)  loss_segments_2_unscaled: 0.0346 (0.0346)  loss_iou_2_unscaled: 0.3421 (0.3421)  time: 0.3120  data: 0.2282  max mem: 488
[11/28 15:56:04][INFO]: Epoch: [9]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 1.9854 (2.0689)  loss_ce: 0.0602 (0.0657)  loss_iou: 0.2149 (0.2181)  loss_ce_0: 0.0816 (0.0850)  loss_iou_0: 0.5068 (0.5490)  loss_ce_1: 0.0707 (0.0727)  loss_iou_1: 0.4886 (0.5097)  loss_ce_2: 0.0591 (0.0661)  loss_iou_2: 0.4743 (0.5026)  loss_ce_unscaled: 0.0301 (0.0328)  class_error_unscaled: 0.0000 (0.0756)  loss_segments_unscaled: 0.0311 (0.0318)  loss_iou_unscaled: 0.1074 (0.1090)  loss_ce_0_unscaled: 0.0408 (0.0425)  loss_segments_0_unscaled: 0.0340 (0.0354)  loss_iou_0_unscaled: 0.2534 (0.2745)  loss_ce_1_unscaled: 0.0353 (0.0364)  loss_segments_1_unscaled: 0.0304 (0.0320)  loss_iou_1_unscaled: 0.2443 (0.2549)  loss_ce_2_unscaled: 0.0295 (0.0330)  loss_segments_2_unscaled: 0.0319 (0.0320)  loss_iou_2_unscaled: 0.2371 (0.2513)  time: 0.0687  data: 0.0012  max mem: 488
[11/28 15:56:05][INFO]: Epoch: [9]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 2.0346 (2.0854)  loss_ce: 0.0598 (0.0653)  loss_iou: 0.2192 (0.2221)  loss_ce_0: 0.0829 (0.0881)  loss_iou_0: 0.5195 (0.5478)  loss_ce_1: 0.0765 (0.0772)  loss_iou_1: 0.4741 (0.5111)  loss_ce_2: 0.0650 (0.0691)  loss_iou_2: 0.4746 (0.5047)  loss_ce_unscaled: 0.0299 (0.0326)  class_error_unscaled: 0.0000 (0.0387)  loss_segments_unscaled: 0.0379 (0.0359)  loss_iou_unscaled: 0.1096 (0.1111)  loss_ce_0_unscaled: 0.0414 (0.0440)  loss_segments_0_unscaled: 0.0383 (0.0382)  loss_iou_0_unscaled: 0.2598 (0.2739)  loss_ce_1_unscaled: 0.0382 (0.0386)  loss_segments_1_unscaled: 0.0375 (0.0356)  loss_iou_1_unscaled: 0.2371 (0.2555)  loss_ce_2_unscaled: 0.0325 (0.0346)  loss_segments_2_unscaled: 0.0372 (0.0354)  loss_iou_2_unscaled: 0.2373 (0.2524)  time: 0.0674  data: 0.0011  max mem: 488
[11/28 15:56:07][INFO]: Epoch: [9]  [ 60/198]  eta: 0:00:10  lr: 0.000200  loss: 2.0579 (2.0724)  loss_ce: 0.0599 (0.0642)  loss_iou: 0.2183 (0.2219)  loss_ce_0: 0.0817 (0.0868)  loss_iou_0: 0.5432 (0.5466)  loss_ce_1: 0.0749 (0.0750)  loss_iou_1: 0.4832 (0.5081)  loss_ce_2: 0.0689 (0.0674)  loss_iou_2: 0.4778 (0.5024)  loss_ce_unscaled: 0.0299 (0.0321)  class_error_unscaled: 0.0000 (0.0260)  loss_segments_unscaled: 0.0345 (0.0356)  loss_iou_unscaled: 0.1091 (0.1110)  loss_ce_0_unscaled: 0.0408 (0.0434)  loss_segments_0_unscaled: 0.0388 (0.0384)  loss_iou_0_unscaled: 0.2716 (0.2733)  loss_ce_1_unscaled: 0.0375 (0.0375)  loss_segments_1_unscaled: 0.0340 (0.0354)  loss_iou_1_unscaled: 0.2416 (0.2540)  loss_ce_2_unscaled: 0.0344 (0.0337)  loss_segments_2_unscaled: 0.0345 (0.0354)  loss_iou_2_unscaled: 0.2389 (0.2512)  time: 0.0695  data: 0.0012  max mem: 488
[11/28 15:56:08][INFO]: Epoch: [9]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 2.0596 (2.0860)  loss_ce: 0.0574 (0.0640)  loss_iou: 0.2277 (0.2251)  loss_ce_0: 0.0785 (0.0855)  loss_iou_0: 0.5480 (0.5502)  loss_ce_1: 0.0598 (0.0736)  loss_iou_1: 0.5231 (0.5134)  loss_ce_2: 0.0566 (0.0662)  loss_iou_2: 0.5104 (0.5079)  loss_ce_unscaled: 0.0287 (0.0320)  class_error_unscaled: 0.0000 (0.0196)  loss_segments_unscaled: 0.0339 (0.0359)  loss_iou_unscaled: 0.1138 (0.1126)  loss_ce_0_unscaled: 0.0393 (0.0428)  loss_segments_0_unscaled: 0.0350 (0.0387)  loss_iou_0_unscaled: 0.2740 (0.2751)  loss_ce_1_unscaled: 0.0299 (0.0368)  loss_segments_1_unscaled: 0.0332 (0.0358)  loss_iou_1_unscaled: 0.2615 (0.2567)  loss_ce_2_unscaled: 0.0283 (0.0331)  loss_segments_2_unscaled: 0.0336 (0.0357)  loss_iou_2_unscaled: 0.2552 (0.2540)  time: 0.0675  data: 0.0011  max mem: 488
[11/28 15:56:10][INFO]: Epoch: [9]  [100/198]  eta: 0:00:06  lr: 0.000200  loss: 2.0173 (2.0929)  loss_ce: 0.0781 (0.0673)  loss_iou: 0.2403 (0.2278)  loss_ce_0: 0.0954 (0.0873)  loss_iou_0: 0.5104 (0.5492)  loss_ce_1: 0.0745 (0.0744)  loss_iou_1: 0.4802 (0.5120)  loss_ce_2: 0.0718 (0.0684)  loss_iou_2: 0.4700 (0.5065)  loss_ce_unscaled: 0.0391 (0.0337)  class_error_unscaled: 0.0000 (0.0525)  loss_segments_unscaled: 0.0322 (0.0354)  loss_iou_unscaled: 0.1201 (0.1139)  loss_ce_0_unscaled: 0.0477 (0.0436)  loss_segments_0_unscaled: 0.0369 (0.0385)  loss_iou_0_unscaled: 0.2552 (0.2746)  loss_ce_1_unscaled: 0.0372 (0.0372)  loss_segments_1_unscaled: 0.0348 (0.0354)  loss_iou_1_unscaled: 0.2401 (0.2560)  loss_ce_2_unscaled: 0.0359 (0.0342)  loss_segments_2_unscaled: 0.0321 (0.0354)  loss_iou_2_unscaled: 0.2350 (0.2533)  time: 0.0698  data: 0.0012  max mem: 488
[11/28 15:56:11][INFO]: Epoch: [9]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 1.9823 (2.0795)  loss_ce: 0.0661 (0.0688)  loss_iou: 0.2292 (0.2291)  loss_ce_0: 0.0865 (0.0871)  loss_iou_0: 0.5134 (0.5440)  loss_ce_1: 0.0694 (0.0736)  loss_iou_1: 0.4447 (0.5069)  loss_ce_2: 0.0691 (0.0693)  loss_iou_2: 0.4411 (0.5008)  loss_ce_unscaled: 0.0331 (0.0344)  class_error_unscaled: 0.0000 (0.0438)  loss_segments_unscaled: 0.0284 (0.0353)  loss_iou_unscaled: 0.1146 (0.1146)  loss_ce_0_unscaled: 0.0433 (0.0436)  loss_segments_0_unscaled: 0.0328 (0.0385)  loss_iou_0_unscaled: 0.2567 (0.2720)  loss_ce_1_unscaled: 0.0347 (0.0368)  loss_segments_1_unscaled: 0.0294 (0.0354)  loss_iou_1_unscaled: 0.2223 (0.2534)  loss_ce_2_unscaled: 0.0346 (0.0346)  loss_segments_2_unscaled: 0.0289 (0.0352)  loss_iou_2_unscaled: 0.2205 (0.2504)  time: 0.0693  data: 0.0011  max mem: 488
[11/28 15:56:12][INFO]: Epoch: [9]  [140/198]  eta: 0:00:04  lr: 0.000200  loss: 2.0725 (2.0875)  loss_ce: 0.0871 (0.0713)  loss_iou: 0.2448 (0.2314)  loss_ce_0: 0.1044 (0.0900)  loss_iou_0: 0.5426 (0.5435)  loss_ce_1: 0.0817 (0.0752)  loss_iou_1: 0.4953 (0.5059)  loss_ce_2: 0.0819 (0.0715)  loss_iou_2: 0.4846 (0.4987)  loss_ce_unscaled: 0.0435 (0.0356)  class_error_unscaled: 0.0000 (0.1781)  loss_segments_unscaled: 0.0325 (0.0350)  loss_iou_unscaled: 0.1224 (0.1157)  loss_ce_0_unscaled: 0.0522 (0.0450)  loss_segments_0_unscaled: 0.0370 (0.0386)  loss_iou_0_unscaled: 0.2713 (0.2718)  loss_ce_1_unscaled: 0.0408 (0.0376)  loss_segments_1_unscaled: 0.0333 (0.0354)  loss_iou_1_unscaled: 0.2476 (0.2530)  loss_ce_2_unscaled: 0.0409 (0.0357)  loss_segments_2_unscaled: 0.0325 (0.0350)  loss_iou_2_unscaled: 0.2423 (0.2493)  time: 0.0677  data: 0.0013  max mem: 488
[11/28 15:56:14][INFO]: Epoch: [9]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 1.9986 (2.0873)  loss_ce: 0.0733 (0.0728)  loss_iou: 0.2347 (0.2320)  loss_ce_0: 0.1047 (0.0919)  loss_iou_0: 0.5274 (0.5407)  loss_ce_1: 0.0752 (0.0772)  loss_iou_1: 0.4817 (0.5027)  loss_ce_2: 0.0760 (0.0738)  loss_iou_2: 0.4673 (0.4962)  loss_ce_unscaled: 0.0366 (0.0364)  class_error_unscaled: 0.0000 (0.2575)  loss_segments_unscaled: 0.0365 (0.0351)  loss_iou_unscaled: 0.1174 (0.1160)  loss_ce_0_unscaled: 0.0523 (0.0460)  loss_segments_0_unscaled: 0.0360 (0.0385)  loss_iou_0_unscaled: 0.2637 (0.2704)  loss_ce_1_unscaled: 0.0376 (0.0386)  loss_segments_1_unscaled: 0.0351 (0.0354)  loss_iou_1_unscaled: 0.2408 (0.2513)  loss_ce_2_unscaled: 0.0380 (0.0369)  loss_segments_2_unscaled: 0.0361 (0.0350)  loss_iou_2_unscaled: 0.2337 (0.2481)  time: 0.0657  data: 0.0012  max mem: 488
[11/28 15:56:15][INFO]: Epoch: [9]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 2.1122 (2.0904)  loss_ce: 0.0620 (0.0718)  loss_iou: 0.2249 (0.2315)  loss_ce_0: 0.0822 (0.0910)  loss_iou_0: 0.5666 (0.5438)  loss_ce_1: 0.0569 (0.0758)  loss_iou_1: 0.5270 (0.5050)  loss_ce_2: 0.0610 (0.0729)  loss_iou_2: 0.5172 (0.4985)  loss_ce_unscaled: 0.0310 (0.0359)  class_error_unscaled: 0.0000 (0.2455)  loss_segments_unscaled: 0.0330 (0.0350)  loss_iou_unscaled: 0.1125 (0.1158)  loss_ce_0_unscaled: 0.0411 (0.0455)  loss_segments_0_unscaled: 0.0363 (0.0386)  loss_iou_0_unscaled: 0.2833 (0.2719)  loss_ce_1_unscaled: 0.0284 (0.0379)  loss_segments_1_unscaled: 0.0337 (0.0354)  loss_iou_1_unscaled: 0.2635 (0.2525)  loss_ce_2_unscaled: 0.0305 (0.0365)  loss_segments_2_unscaled: 0.0315 (0.0349)  loss_iou_2_unscaled: 0.2586 (0.2493)  time: 0.0674  data: 0.0012  max mem: 488
[11/28 15:56:16][INFO]: Epoch: [9]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 1.9377 (2.0796)  loss_ce: 0.0613 (0.0710)  loss_iou: 0.2218 (0.2316)  loss_ce_0: 0.0934 (0.0915)  loss_iou_0: 0.5139 (0.5412)  loss_ce_1: 0.0670 (0.0754)  loss_iou_1: 0.4742 (0.5014)  loss_ce_2: 0.0591 (0.0720)  loss_iou_2: 0.4763 (0.4954)  loss_ce_unscaled: 0.0306 (0.0355)  class_error_unscaled: 0.0000 (0.2354)  loss_segments_unscaled: 0.0338 (0.0351)  loss_iou_unscaled: 0.1109 (0.1158)  loss_ce_0_unscaled: 0.0467 (0.0458)  loss_segments_0_unscaled: 0.0362 (0.0387)  loss_iou_0_unscaled: 0.2569 (0.2706)  loss_ce_1_unscaled: 0.0335 (0.0377)  loss_segments_1_unscaled: 0.0348 (0.0355)  loss_iou_1_unscaled: 0.2371 (0.2507)  loss_ce_2_unscaled: 0.0296 (0.0360)  loss_segments_2_unscaled: 0.0338 (0.0350)  loss_iou_2_unscaled: 0.2381 (0.2477)  time: 0.0629  data: 0.0013  max mem: 488
[11/28 15:56:16][INFO]: Epoch: [9] Total time: 0:00:13 (0.0691 s / it)
[11/28 15:56:16][INFO]: Averaged stats:lr: 0.000200  loss: 1.9377 (2.0796)  loss_ce: 0.0613 (0.0710)  loss_iou: 0.2218 (0.2316)  loss_ce_0: 0.0934 (0.0915)  loss_iou_0: 0.5139 (0.5412)  loss_ce_1: 0.0670 (0.0754)  loss_iou_1: 0.4742 (0.5014)  loss_ce_2: 0.0591 (0.0720)  loss_iou_2: 0.4763 (0.4954)  loss_ce_unscaled: 0.0306 (0.0355)  class_error_unscaled: 0.0000 (0.2354)  loss_segments_unscaled: 0.0338 (0.0351)  loss_iou_unscaled: 0.1109 (0.1158)  loss_ce_0_unscaled: 0.0467 (0.0458)  loss_segments_0_unscaled: 0.0362 (0.0387)  loss_iou_0_unscaled: 0.2569 (0.2706)  loss_ce_1_unscaled: 0.0335 (0.0377)  loss_segments_1_unscaled: 0.0348 (0.0355)  loss_iou_1_unscaled: 0.2371 (0.2507)  loss_ce_2_unscaled: 0.0296 (0.0360)  loss_segments_2_unscaled: 0.0338 (0.0350)  loss_iou_2_unscaled: 0.2381 (0.2477)
[11/28 15:56:16][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 25.94it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:56:24][INFO]: mode=raw 118693 predictions from 210 videos
[11/28 15:56:27][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
69.78 64.64 56.82 43.06 29.04 52.67 raw epoch9
[11/28 15:56:27][INFO]: mAP_raw: 52.67
[11/28 15:56:27][INFO]: lr=0.0002
[11/28 15:56:27][INFO]: lr=1e-05
[11/28 15:56:27][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:56:28][INFO]: Epoch: [10]  [  0/198]  eta: 0:00:52  lr: 0.000200  loss: 2.0692 (2.0692)  loss_ce: 0.0706 (0.0706)  loss_iou: 0.2361 (0.2361)  loss_ce_0: 0.0812 (0.0812)  loss_iou_0: 0.5401 (0.5401)  loss_ce_1: 0.0650 (0.0650)  loss_iou_1: 0.5107 (0.5107)  loss_ce_2: 0.0612 (0.0612)  loss_iou_2: 0.5043 (0.5043)  loss_ce_unscaled: 0.0353 (0.0353)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0356 (0.0356)  loss_iou_unscaled: 0.1180 (0.1180)  loss_ce_0_unscaled: 0.0406 (0.0406)  loss_segments_0_unscaled: 0.0341 (0.0341)  loss_iou_0_unscaled: 0.2700 (0.2700)  loss_ce_1_unscaled: 0.0325 (0.0325)  loss_segments_1_unscaled: 0.0361 (0.0361)  loss_iou_1_unscaled: 0.2553 (0.2553)  loss_ce_2_unscaled: 0.0306 (0.0306)  loss_segments_2_unscaled: 0.0356 (0.0356)  loss_iou_2_unscaled: 0.2522 (0.2522)  time: 0.2654  data: 0.1687  max mem: 488
[11/28 15:56:29][INFO]: Epoch: [10]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 1.9104 (1.9937)  loss_ce: 0.0479 (0.0538)  loss_iou: 0.2274 (0.2338)  loss_ce_0: 0.0741 (0.0803)  loss_iou_0: 0.5023 (0.5361)  loss_ce_1: 0.0605 (0.0639)  loss_iou_1: 0.4762 (0.4882)  loss_ce_2: 0.0501 (0.0571)  loss_iou_2: 0.4781 (0.4806)  loss_ce_unscaled: 0.0239 (0.0269)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0316 (0.0312)  loss_iou_unscaled: 0.1137 (0.1169)  loss_ce_0_unscaled: 0.0371 (0.0401)  loss_segments_0_unscaled: 0.0352 (0.0350)  loss_iou_0_unscaled: 0.2512 (0.2680)  loss_ce_1_unscaled: 0.0302 (0.0319)  loss_segments_1_unscaled: 0.0326 (0.0321)  loss_iou_1_unscaled: 0.2381 (0.2441)  loss_ce_2_unscaled: 0.0250 (0.0286)  loss_segments_2_unscaled: 0.0316 (0.0312)  loss_iou_2_unscaled: 0.2391 (0.2403)  time: 0.0709  data: 0.0011  max mem: 488
[11/28 15:56:30][INFO]: Epoch: [10]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 1.9552 (2.0021)  loss_ce: 0.0571 (0.0557)  loss_iou: 0.2181 (0.2303)  loss_ce_0: 0.0792 (0.0801)  loss_iou_0: 0.5089 (0.5304)  loss_ce_1: 0.0571 (0.0614)  loss_iou_1: 0.5031 (0.4971)  loss_ce_2: 0.0517 (0.0566)  loss_iou_2: 0.5040 (0.4905)  loss_ce_unscaled: 0.0286 (0.0278)  class_error_unscaled: 0.0000 (0.1875)  loss_segments_unscaled: 0.0307 (0.0308)  loss_iou_unscaled: 0.1091 (0.1152)  loss_ce_0_unscaled: 0.0396 (0.0401)  loss_segments_0_unscaled: 0.0318 (0.0340)  loss_iou_0_unscaled: 0.2544 (0.2652)  loss_ce_1_unscaled: 0.0286 (0.0307)  loss_segments_1_unscaled: 0.0305 (0.0316)  loss_iou_1_unscaled: 0.2515 (0.2485)  loss_ce_2_unscaled: 0.0259 (0.0283)  loss_segments_2_unscaled: 0.0327 (0.0309)  loss_iou_2_unscaled: 0.2520 (0.2453)  time: 0.0684  data: 0.0011  max mem: 488
[11/28 15:56:32][INFO]: Epoch: [10]  [ 60/198]  eta: 0:00:09  lr: 0.000200  loss: 1.9305 (1.9813)  loss_ce: 0.0454 (0.0543)  loss_iou: 0.2070 (0.2252)  loss_ce_0: 0.0724 (0.0786)  loss_iou_0: 0.5202 (0.5284)  loss_ce_1: 0.0578 (0.0606)  loss_iou_1: 0.4619 (0.4924)  loss_ce_2: 0.0471 (0.0555)  loss_iou_2: 0.4598 (0.4863)  loss_ce_unscaled: 0.0227 (0.0272)  class_error_unscaled: 0.0000 (0.1553)  loss_segments_unscaled: 0.0362 (0.0326)  loss_iou_unscaled: 0.1035 (0.1126)  loss_ce_0_unscaled: 0.0362 (0.0393)  loss_segments_0_unscaled: 0.0413 (0.0364)  loss_iou_0_unscaled: 0.2601 (0.2642)  loss_ce_1_unscaled: 0.0289 (0.0303)  loss_segments_1_unscaled: 0.0355 (0.0334)  loss_iou_1_unscaled: 0.2310 (0.2462)  loss_ce_2_unscaled: 0.0235 (0.0277)  loss_segments_2_unscaled: 0.0362 (0.0327)  loss_iou_2_unscaled: 0.2299 (0.2432)  time: 0.0677  data: 0.0012  max mem: 488
[11/28 15:56:33][INFO]: Epoch: [10]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 2.0036 (1.9897)  loss_ce: 0.0592 (0.0572)  loss_iou: 0.2275 (0.2261)  loss_ce_0: 0.0790 (0.0813)  loss_iou_0: 0.5079 (0.5265)  loss_ce_1: 0.0638 (0.0633)  loss_iou_1: 0.4631 (0.4911)  loss_ce_2: 0.0619 (0.0584)  loss_iou_2: 0.4618 (0.4857)  loss_ce_unscaled: 0.0296 (0.0286)  class_error_unscaled: 0.0000 (0.2259)  loss_segments_unscaled: 0.0318 (0.0329)  loss_iou_unscaled: 0.1138 (0.1131)  loss_ce_0_unscaled: 0.0395 (0.0407)  loss_segments_0_unscaled: 0.0334 (0.0366)  loss_iou_0_unscaled: 0.2539 (0.2633)  loss_ce_1_unscaled: 0.0319 (0.0316)  loss_segments_1_unscaled: 0.0287 (0.0334)  loss_iou_1_unscaled: 0.2316 (0.2456)  loss_ce_2_unscaled: 0.0309 (0.0292)  loss_segments_2_unscaled: 0.0318 (0.0329)  loss_iou_2_unscaled: 0.2309 (0.2429)  time: 0.0703  data: 0.0012  max mem: 488
[11/28 15:56:35][INFO]: Epoch: [10]  [100/198]  eta: 0:00:06  lr: 0.000200  loss: 2.1061 (1.9990)  loss_ce: 0.0622 (0.0582)  loss_iou: 0.2260 (0.2270)  loss_ce_0: 0.0762 (0.0819)  loss_iou_0: 0.5533 (0.5281)  loss_ce_1: 0.0644 (0.0641)  loss_iou_1: 0.4835 (0.4927)  loss_ce_2: 0.0621 (0.0598)  loss_iou_2: 0.4780 (0.4873)  loss_ce_unscaled: 0.0311 (0.0291)  class_error_unscaled: 0.0000 (0.1812)  loss_segments_unscaled: 0.0342 (0.0335)  loss_iou_unscaled: 0.1130 (0.1135)  loss_ce_0_unscaled: 0.0381 (0.0409)  loss_segments_0_unscaled: 0.0378 (0.0371)  loss_iou_0_unscaled: 0.2767 (0.2640)  loss_ce_1_unscaled: 0.0322 (0.0320)  loss_segments_1_unscaled: 0.0338 (0.0340)  loss_iou_1_unscaled: 0.2418 (0.2463)  loss_ce_2_unscaled: 0.0311 (0.0299)  loss_segments_2_unscaled: 0.0343 (0.0335)  loss_iou_2_unscaled: 0.2390 (0.2437)  time: 0.0698  data: 0.0013  max mem: 488
[11/28 15:56:36][INFO]: Epoch: [10]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 2.0758 (2.0180)  loss_ce: 0.0833 (0.0630)  loss_iou: 0.2375 (0.2293)  loss_ce_0: 0.1051 (0.0863)  loss_iou_0: 0.5130 (0.5288)  loss_ce_1: 0.0828 (0.0686)  loss_iou_1: 0.4806 (0.4918)  loss_ce_2: 0.0800 (0.0641)  loss_iou_2: 0.4693 (0.4861)  loss_ce_unscaled: 0.0416 (0.0315)  class_error_unscaled: 0.0000 (0.2590)  loss_segments_unscaled: 0.0316 (0.0339)  loss_iou_unscaled: 0.1188 (0.1146)  loss_ce_0_unscaled: 0.0525 (0.0431)  loss_segments_0_unscaled: 0.0385 (0.0377)  loss_iou_0_unscaled: 0.2565 (0.2644)  loss_ce_1_unscaled: 0.0414 (0.0343)  loss_segments_1_unscaled: 0.0335 (0.0344)  loss_iou_1_unscaled: 0.2403 (0.2459)  loss_ce_2_unscaled: 0.0400 (0.0321)  loss_segments_2_unscaled: 0.0316 (0.0340)  loss_iou_2_unscaled: 0.2347 (0.2430)  time: 0.0678  data: 0.0012  max mem: 488
[11/28 15:56:37][INFO]: Epoch: [10]  [140/198]  eta: 0:00:04  lr: 0.000200  loss: 1.9520 (2.0239)  loss_ce: 0.0688 (0.0638)  loss_iou: 0.2349 (0.2303)  loss_ce_0: 0.0749 (0.0849)  loss_iou_0: 0.5206 (0.5316)  loss_ce_1: 0.0596 (0.0678)  loss_iou_1: 0.5011 (0.4940)  loss_ce_2: 0.0630 (0.0645)  loss_iou_2: 0.4669 (0.4871)  loss_ce_unscaled: 0.0344 (0.0319)  class_error_unscaled: 0.0000 (0.2339)  loss_segments_unscaled: 0.0286 (0.0340)  loss_iou_unscaled: 0.1174 (0.1151)  loss_ce_0_unscaled: 0.0375 (0.0424)  loss_segments_0_unscaled: 0.0330 (0.0380)  loss_iou_0_unscaled: 0.2603 (0.2658)  loss_ce_1_unscaled: 0.0298 (0.0339)  loss_segments_1_unscaled: 0.0295 (0.0347)  loss_iou_1_unscaled: 0.2505 (0.2470)  loss_ce_2_unscaled: 0.0315 (0.0322)  loss_segments_2_unscaled: 0.0321 (0.0341)  loss_iou_2_unscaled: 0.2334 (0.2435)  time: 0.0678  data: 0.0012  max mem: 488
[11/28 15:56:39][INFO]: Epoch: [10]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 2.0318 (2.0288)  loss_ce: 0.0606 (0.0635)  loss_iou: 0.2484 (0.2326)  loss_ce_0: 0.0760 (0.0843)  loss_iou_0: 0.5082 (0.5330)  loss_ce_1: 0.0684 (0.0678)  loss_iou_1: 0.4717 (0.4952)  loss_ce_2: 0.0616 (0.0643)  loss_iou_2: 0.4682 (0.4879)  loss_ce_unscaled: 0.0303 (0.0318)  class_error_unscaled: 0.0000 (0.2273)  loss_segments_unscaled: 0.0303 (0.0338)  loss_iou_unscaled: 0.1242 (0.1163)  loss_ce_0_unscaled: 0.0380 (0.0421)  loss_segments_0_unscaled: 0.0356 (0.0376)  loss_iou_0_unscaled: 0.2541 (0.2665)  loss_ce_1_unscaled: 0.0342 (0.0339)  loss_segments_1_unscaled: 0.0312 (0.0345)  loss_iou_1_unscaled: 0.2358 (0.2476)  loss_ce_2_unscaled: 0.0308 (0.0322)  loss_segments_2_unscaled: 0.0302 (0.0339)  loss_iou_2_unscaled: 0.2341 (0.2440)  time: 0.0669  data: 0.0013  max mem: 488
[11/28 15:56:40][INFO]: Epoch: [10]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 1.9472 (2.0351)  loss_ce: 0.0705 (0.0645)  loss_iou: 0.2298 (0.2328)  loss_ce_0: 0.0922 (0.0852)  loss_iou_0: 0.5223 (0.5333)  loss_ce_1: 0.0729 (0.0688)  loss_iou_1: 0.4672 (0.4962)  loss_ce_2: 0.0666 (0.0653)  loss_iou_2: 0.4449 (0.4889)  loss_ce_unscaled: 0.0352 (0.0323)  class_error_unscaled: 0.0000 (0.2150)  loss_segments_unscaled: 0.0390 (0.0347)  loss_iou_unscaled: 0.1149 (0.1164)  loss_ce_0_unscaled: 0.0461 (0.0426)  loss_segments_0_unscaled: 0.0402 (0.0384)  loss_iou_0_unscaled: 0.2611 (0.2667)  loss_ce_1_unscaled: 0.0365 (0.0344)  loss_segments_1_unscaled: 0.0423 (0.0354)  loss_iou_1_unscaled: 0.2336 (0.2481)  loss_ce_2_unscaled: 0.0333 (0.0327)  loss_segments_2_unscaled: 0.0390 (0.0348)  loss_iou_2_unscaled: 0.2224 (0.2444)  time: 0.0683  data: 0.0013  max mem: 488
[11/28 15:56:41][INFO]: Epoch: [10]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 2.1970 (2.0509)  loss_ce: 0.0717 (0.0655)  loss_iou: 0.2305 (0.2339)  loss_ce_0: 0.1015 (0.0872)  loss_iou_0: 0.5492 (0.5362)  loss_ce_1: 0.0818 (0.0702)  loss_iou_1: 0.5328 (0.4994)  loss_ce_2: 0.0814 (0.0671)  loss_iou_2: 0.5394 (0.4914)  loss_ce_unscaled: 0.0359 (0.0328)  class_error_unscaled: 0.0000 (0.2026)  loss_segments_unscaled: 0.0372 (0.0351)  loss_iou_unscaled: 0.1153 (0.1169)  loss_ce_0_unscaled: 0.0507 (0.0436)  loss_segments_0_unscaled: 0.0407 (0.0386)  loss_iou_0_unscaled: 0.2746 (0.2681)  loss_ce_1_unscaled: 0.0409 (0.0351)  loss_segments_1_unscaled: 0.0398 (0.0358)  loss_iou_1_unscaled: 0.2664 (0.2497)  loss_ce_2_unscaled: 0.0407 (0.0335)  loss_segments_2_unscaled: 0.0373 (0.0350)  loss_iou_2_unscaled: 0.2697 (0.2457)  time: 0.0668  data: 0.0012  max mem: 488
[11/28 15:56:41][INFO]: Epoch: [10] Total time: 0:00:13 (0.0698 s / it)
[11/28 15:56:41][INFO]: Averaged stats:lr: 0.000200  loss: 2.1970 (2.0509)  loss_ce: 0.0717 (0.0655)  loss_iou: 0.2305 (0.2339)  loss_ce_0: 0.1015 (0.0872)  loss_iou_0: 0.5492 (0.5362)  loss_ce_1: 0.0818 (0.0702)  loss_iou_1: 0.5328 (0.4994)  loss_ce_2: 0.0814 (0.0671)  loss_iou_2: 0.5394 (0.4914)  loss_ce_unscaled: 0.0359 (0.0328)  class_error_unscaled: 0.0000 (0.2026)  loss_segments_unscaled: 0.0372 (0.0351)  loss_iou_unscaled: 0.1153 (0.1169)  loss_ce_0_unscaled: 0.0507 (0.0436)  loss_segments_0_unscaled: 0.0407 (0.0386)  loss_iou_0_unscaled: 0.2746 (0.2681)  loss_ce_1_unscaled: 0.0409 (0.0351)  loss_segments_1_unscaled: 0.0398 (0.0358)  loss_iou_1_unscaled: 0.2664 (0.2497)  loss_ce_2_unscaled: 0.0407 (0.0335)  loss_segments_2_unscaled: 0.0373 (0.0350)  loss_iou_2_unscaled: 0.2697 (0.2457)
[11/28 15:56:41][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 25.94it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:56:49][INFO]: mode=raw 120126 predictions from 210 videos
[11/28 15:56:53][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
71.46 64.53 55.26 42.88 28.17 52.46 raw epoch10
[11/28 15:56:53][INFO]: mAP_raw: 52.46
[11/28 15:56:53][INFO]: lr=0.0002
[11/28 15:56:53][INFO]: lr=1e-05
[11/28 15:56:53][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:56:53][INFO]: Epoch: [11]  [  0/198]  eta: 0:01:01  lr: 0.000200  loss: 1.6864 (1.6864)  loss_ce: 0.0421 (0.0421)  loss_iou: 0.2275 (0.2275)  loss_ce_0: 0.0529 (0.0529)  loss_iou_0: 0.4470 (0.4470)  loss_ce_1: 0.0423 (0.0423)  loss_iou_1: 0.4143 (0.4143)  loss_ce_2: 0.0373 (0.0373)  loss_iou_2: 0.4230 (0.4230)  loss_ce_unscaled: 0.0211 (0.0211)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0326 (0.0326)  loss_iou_unscaled: 0.1138 (0.1138)  loss_ce_0_unscaled: 0.0264 (0.0264)  loss_segments_0_unscaled: 0.0335 (0.0335)  loss_iou_0_unscaled: 0.2235 (0.2235)  loss_ce_1_unscaled: 0.0211 (0.0211)  loss_segments_1_unscaled: 0.0327 (0.0327)  loss_iou_1_unscaled: 0.2071 (0.2071)  loss_ce_2_unscaled: 0.0186 (0.0186)  loss_segments_2_unscaled: 0.0326 (0.0326)  loss_iou_2_unscaled: 0.2115 (0.2115)  time: 0.3115  data: 0.2296  max mem: 488
[11/28 15:56:55][INFO]: Epoch: [11]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 1.9587 (1.9857)  loss_ce: 0.0563 (0.0559)  loss_iou: 0.2287 (0.2330)  loss_ce_0: 0.0787 (0.0826)  loss_iou_0: 0.5261 (0.5271)  loss_ce_1: 0.0621 (0.0667)  loss_iou_1: 0.4743 (0.4824)  loss_ce_2: 0.0504 (0.0574)  loss_iou_2: 0.4862 (0.4807)  loss_ce_unscaled: 0.0282 (0.0280)  class_error_unscaled: 0.0000 (0.1361)  loss_segments_unscaled: 0.0331 (0.0351)  loss_iou_unscaled: 0.1143 (0.1165)  loss_ce_0_unscaled: 0.0394 (0.0413)  loss_segments_0_unscaled: 0.0355 (0.0394)  loss_iou_0_unscaled: 0.2630 (0.2636)  loss_ce_1_unscaled: 0.0310 (0.0333)  loss_segments_1_unscaled: 0.0333 (0.0361)  loss_iou_1_unscaled: 0.2371 (0.2412)  loss_ce_2_unscaled: 0.0252 (0.0287)  loss_segments_2_unscaled: 0.0324 (0.0360)  loss_iou_2_unscaled: 0.2431 (0.2403)  time: 0.0704  data: 0.0013  max mem: 488
[11/28 15:56:56][INFO]: Epoch: [11]  [ 40/198]  eta: 0:00:12  lr: 0.000200  loss: 2.0163 (2.0351)  loss_ce: 0.0531 (0.0574)  loss_iou: 0.2271 (0.2318)  loss_ce_0: 0.0874 (0.0860)  loss_iou_0: 0.5315 (0.5420)  loss_ce_1: 0.0678 (0.0680)  loss_iou_1: 0.4817 (0.4963)  loss_ce_2: 0.0565 (0.0586)  loss_iou_2: 0.4906 (0.4950)  loss_ce_unscaled: 0.0265 (0.0287)  class_error_unscaled: 0.0000 (0.2017)  loss_segments_unscaled: 0.0341 (0.0353)  loss_iou_unscaled: 0.1135 (0.1159)  loss_ce_0_unscaled: 0.0437 (0.0430)  loss_segments_0_unscaled: 0.0397 (0.0396)  loss_iou_0_unscaled: 0.2658 (0.2710)  loss_ce_1_unscaled: 0.0339 (0.0340)  loss_segments_1_unscaled: 0.0346 (0.0363)  loss_iou_1_unscaled: 0.2409 (0.2482)  loss_ce_2_unscaled: 0.0282 (0.0293)  loss_segments_2_unscaled: 0.0343 (0.0358)  loss_iou_2_unscaled: 0.2453 (0.2475)  time: 0.0703  data: 0.0012  max mem: 488
[11/28 15:56:58][INFO]: Epoch: [11]  [ 60/198]  eta: 0:00:10  lr: 0.000200  loss: 2.0310 (2.0244)  loss_ce: 0.0578 (0.0589)  loss_iou: 0.2333 (0.2326)  loss_ce_0: 0.0770 (0.0831)  loss_iou_0: 0.5422 (0.5377)  loss_ce_1: 0.0633 (0.0664)  loss_iou_1: 0.4918 (0.4948)  loss_ce_2: 0.0609 (0.0595)  loss_iou_2: 0.4717 (0.4913)  loss_ce_unscaled: 0.0289 (0.0294)  class_error_unscaled: 0.0000 (0.2813)  loss_segments_unscaled: 0.0291 (0.0340)  loss_iou_unscaled: 0.1167 (0.1163)  loss_ce_0_unscaled: 0.0385 (0.0416)  loss_segments_0_unscaled: 0.0344 (0.0383)  loss_iou_0_unscaled: 0.2711 (0.2689)  loss_ce_1_unscaled: 0.0316 (0.0332)  loss_segments_1_unscaled: 0.0310 (0.0348)  loss_iou_1_unscaled: 0.2459 (0.2474)  loss_ce_2_unscaled: 0.0304 (0.0298)  loss_segments_2_unscaled: 0.0291 (0.0345)  loss_iou_2_unscaled: 0.2358 (0.2457)  time: 0.0693  data: 0.0012  max mem: 488
[11/28 15:56:59][INFO]: Epoch: [11]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 1.9357 (1.9964)  loss_ce: 0.0502 (0.0566)  loss_iou: 0.2206 (0.2303)  loss_ce_0: 0.0908 (0.0854)  loss_iou_0: 0.5066 (0.5279)  loss_ce_1: 0.0610 (0.0663)  loss_iou_1: 0.4612 (0.4863)  loss_ce_2: 0.0564 (0.0584)  loss_iou_2: 0.4551 (0.4850)  loss_ce_unscaled: 0.0251 (0.0283)  class_error_unscaled: 0.0000 (0.2667)  loss_segments_unscaled: 0.0305 (0.0337)  loss_iou_unscaled: 0.1103 (0.1152)  loss_ce_0_unscaled: 0.0454 (0.0427)  loss_segments_0_unscaled: 0.0327 (0.0379)  loss_iou_0_unscaled: 0.2533 (0.2640)  loss_ce_1_unscaled: 0.0305 (0.0332)  loss_segments_1_unscaled: 0.0305 (0.0342)  loss_iou_1_unscaled: 0.2306 (0.2432)  loss_ce_2_unscaled: 0.0282 (0.0292)  loss_segments_2_unscaled: 0.0307 (0.0341)  loss_iou_2_unscaled: 0.2275 (0.2425)  time: 0.0683  data: 0.0012  max mem: 488
[11/28 15:57:00][INFO]: Epoch: [11]  [100/198]  eta: 0:00:07  lr: 0.000200  loss: 1.6820 (1.9638)  loss_ce: 0.0531 (0.0564)  loss_iou: 0.2170 (0.2318)  loss_ce_0: 0.0768 (0.0837)  loss_iou_0: 0.4238 (0.5171)  loss_ce_1: 0.0644 (0.0660)  loss_iou_1: 0.3885 (0.4760)  loss_ce_2: 0.0602 (0.0588)  loss_iou_2: 0.3906 (0.4739)  loss_ce_unscaled: 0.0265 (0.0282)  class_error_unscaled: 0.0000 (0.2840)  loss_segments_unscaled: 0.0278 (0.0331)  loss_iou_unscaled: 0.1085 (0.1159)  loss_ce_0_unscaled: 0.0384 (0.0419)  loss_segments_0_unscaled: 0.0325 (0.0374)  loss_iou_0_unscaled: 0.2119 (0.2586)  loss_ce_1_unscaled: 0.0322 (0.0330)  loss_segments_1_unscaled: 0.0272 (0.0335)  loss_iou_1_unscaled: 0.1942 (0.2380)  loss_ce_2_unscaled: 0.0301 (0.0294)  loss_segments_2_unscaled: 0.0265 (0.0333)  loss_iou_2_unscaled: 0.1953 (0.2369)  time: 0.0682  data: 0.0012  max mem: 488
[11/28 15:57:02][INFO]: Epoch: [11]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 1.9496 (1.9711)  loss_ce: 0.0578 (0.0573)  loss_iou: 0.2245 (0.2327)  loss_ce_0: 0.0747 (0.0834)  loss_iou_0: 0.5338 (0.5195)  loss_ce_1: 0.0533 (0.0657)  loss_iou_1: 0.4799 (0.4778)  loss_ce_2: 0.0529 (0.0589)  loss_iou_2: 0.4724 (0.4758)  loss_ce_unscaled: 0.0289 (0.0287)  class_error_unscaled: 0.0000 (0.2687)  loss_segments_unscaled: 0.0312 (0.0332)  loss_iou_unscaled: 0.1123 (0.1164)  loss_ce_0_unscaled: 0.0373 (0.0417)  loss_segments_0_unscaled: 0.0344 (0.0373)  loss_iou_0_unscaled: 0.2669 (0.2597)  loss_ce_1_unscaled: 0.0266 (0.0328)  loss_segments_1_unscaled: 0.0319 (0.0337)  loss_iou_1_unscaled: 0.2399 (0.2389)  loss_ce_2_unscaled: 0.0264 (0.0294)  loss_segments_2_unscaled: 0.0312 (0.0333)  loss_iou_2_unscaled: 0.2362 (0.2379)  time: 0.0657  data: 0.0012  max mem: 488
[11/28 15:57:03][INFO]: Epoch: [11]  [140/198]  eta: 0:00:04  lr: 0.000200  loss: 2.1003 (1.9834)  loss_ce: 0.0553 (0.0582)  loss_iou: 0.2346 (0.2347)  loss_ce_0: 0.0784 (0.0844)  loss_iou_0: 0.5177 (0.5215)  loss_ce_1: 0.0640 (0.0670)  loss_iou_1: 0.5032 (0.4798)  loss_ce_2: 0.0617 (0.0597)  loss_iou_2: 0.4959 (0.4781)  loss_ce_unscaled: 0.0276 (0.0291)  class_error_unscaled: 0.0000 (0.2777)  loss_segments_unscaled: 0.0332 (0.0334)  loss_iou_unscaled: 0.1173 (0.1174)  loss_ce_0_unscaled: 0.0392 (0.0422)  loss_segments_0_unscaled: 0.0381 (0.0377)  loss_iou_0_unscaled: 0.2588 (0.2608)  loss_ce_1_unscaled: 0.0320 (0.0335)  loss_segments_1_unscaled: 0.0348 (0.0339)  loss_iou_1_unscaled: 0.2516 (0.2399)  loss_ce_2_unscaled: 0.0308 (0.0299)  loss_segments_2_unscaled: 0.0332 (0.0335)  loss_iou_2_unscaled: 0.2479 (0.2391)  time: 0.0674  data: 0.0013  max mem: 488
[11/28 15:57:04][INFO]: Epoch: [11]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 1.9809 (1.9964)  loss_ce: 0.0553 (0.0587)  loss_iou: 0.2520 (0.2370)  loss_ce_0: 0.0699 (0.0838)  loss_iou_0: 0.5112 (0.5256)  loss_ce_1: 0.0614 (0.0666)  loss_iou_1: 0.4710 (0.4835)  loss_ce_2: 0.0579 (0.0598)  loss_iou_2: 0.4515 (0.4815)  loss_ce_unscaled: 0.0276 (0.0293)  class_error_unscaled: 0.0000 (0.2665)  loss_segments_unscaled: 0.0342 (0.0336)  loss_iou_unscaled: 0.1260 (0.1185)  loss_ce_0_unscaled: 0.0349 (0.0419)  loss_segments_0_unscaled: 0.0367 (0.0379)  loss_iou_0_unscaled: 0.2556 (0.2628)  loss_ce_1_unscaled: 0.0307 (0.0333)  loss_segments_1_unscaled: 0.0353 (0.0342)  loss_iou_1_unscaled: 0.2355 (0.2417)  loss_ce_2_unscaled: 0.0290 (0.0299)  loss_segments_2_unscaled: 0.0356 (0.0337)  loss_iou_2_unscaled: 0.2258 (0.2407)  time: 0.0683  data: 0.0013  max mem: 488
[11/28 15:57:06][INFO]: Epoch: [11]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 2.1509 (2.0221)  loss_ce: 0.0887 (0.0628)  loss_iou: 0.2564 (0.2389)  loss_ce_0: 0.1118 (0.0873)  loss_iou_0: 0.5165 (0.5277)  loss_ce_1: 0.0941 (0.0702)  loss_iou_1: 0.4834 (0.4872)  loss_ce_2: 0.0873 (0.0631)  loss_iou_2: 0.4720 (0.4849)  loss_ce_unscaled: 0.0443 (0.0314)  class_error_unscaled: 1.1364 (0.4675)  loss_segments_unscaled: 0.0365 (0.0343)  loss_iou_unscaled: 0.1282 (0.1195)  loss_ce_0_unscaled: 0.0559 (0.0436)  loss_segments_0_unscaled: 0.0371 (0.0385)  loss_iou_0_unscaled: 0.2582 (0.2639)  loss_ce_1_unscaled: 0.0471 (0.0351)  loss_segments_1_unscaled: 0.0387 (0.0348)  loss_iou_1_unscaled: 0.2417 (0.2436)  loss_ce_2_unscaled: 0.0437 (0.0315)  loss_segments_2_unscaled: 0.0386 (0.0344)  loss_iou_2_unscaled: 0.2360 (0.2425)  time: 0.0688  data: 0.0012  max mem: 488
[11/28 15:57:07][INFO]: Epoch: [11]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 2.1103 (2.0312)  loss_ce: 0.0701 (0.0635)  loss_iou: 0.2316 (0.2391)  loss_ce_0: 0.1034 (0.0893)  loss_iou_0: 0.5702 (0.5295)  loss_ce_1: 0.0701 (0.0717)  loss_iou_1: 0.5126 (0.4880)  loss_ce_2: 0.0720 (0.0644)  loss_iou_2: 0.5201 (0.4857)  loss_ce_unscaled: 0.0351 (0.0317)  class_error_unscaled: 0.0000 (0.4675)  loss_segments_unscaled: 0.0337 (0.0342)  loss_iou_unscaled: 0.1158 (0.1196)  loss_ce_0_unscaled: 0.0517 (0.0446)  loss_segments_0_unscaled: 0.0342 (0.0382)  loss_iou_0_unscaled: 0.2851 (0.2648)  loss_ce_1_unscaled: 0.0351 (0.0359)  loss_segments_1_unscaled: 0.0314 (0.0346)  loss_iou_1_unscaled: 0.2563 (0.2440)  loss_ce_2_unscaled: 0.0360 (0.0322)  loss_segments_2_unscaled: 0.0318 (0.0342)  loss_iou_2_unscaled: 0.2601 (0.2428)  time: 0.0656  data: 0.0012  max mem: 488
[11/28 15:57:07][INFO]: Epoch: [11] Total time: 0:00:13 (0.0697 s / it)
[11/28 15:57:07][INFO]: Averaged stats:lr: 0.000200  loss: 2.1103 (2.0312)  loss_ce: 0.0701 (0.0635)  loss_iou: 0.2316 (0.2391)  loss_ce_0: 0.1034 (0.0893)  loss_iou_0: 0.5702 (0.5295)  loss_ce_1: 0.0701 (0.0717)  loss_iou_1: 0.5126 (0.4880)  loss_ce_2: 0.0720 (0.0644)  loss_iou_2: 0.5201 (0.4857)  loss_ce_unscaled: 0.0351 (0.0317)  class_error_unscaled: 0.0000 (0.4675)  loss_segments_unscaled: 0.0337 (0.0342)  loss_iou_unscaled: 0.1158 (0.1196)  loss_ce_0_unscaled: 0.0517 (0.0446)  loss_segments_0_unscaled: 0.0342 (0.0382)  loss_iou_0_unscaled: 0.2851 (0.2648)  loss_ce_1_unscaled: 0.0351 (0.0359)  loss_segments_1_unscaled: 0.0314 (0.0346)  loss_iou_1_unscaled: 0.2563 (0.2440)  loss_ce_2_unscaled: 0.0360 (0.0322)  loss_segments_2_unscaled: 0.0318 (0.0342)  loss_iou_2_unscaled: 0.2601 (0.2428)
[11/28 15:57:07][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 26.07it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:57:15][INFO]: mode=raw 122589 predictions from 210 videos
[11/28 15:57:20][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
70.66 64.09 55.11 42.50 26.77 51.82 raw epoch11
[11/28 15:57:20][INFO]: mAP_raw: 51.82
[11/28 15:57:20][INFO]: lr=0.0002
[11/28 15:57:20][INFO]: lr=1e-05
[11/28 15:57:20][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:57:20][INFO]: Epoch: [12]  [  0/198]  eta: 0:01:01  lr: 0.000200  loss: 1.6618 (1.6618)  loss_ce: 0.0404 (0.0404)  loss_iou: 0.3674 (0.3674)  loss_ce_0: 0.0581 (0.0581)  loss_iou_0: 0.3688 (0.3688)  loss_ce_1: 0.0472 (0.0472)  loss_iou_1: 0.3714 (0.3714)  loss_ce_2: 0.0494 (0.0494)  loss_iou_2: 0.3592 (0.3592)  loss_ce_unscaled: 0.0202 (0.0202)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0251 (0.0251)  loss_iou_unscaled: 0.1837 (0.1837)  loss_ce_0_unscaled: 0.0291 (0.0291)  loss_segments_0_unscaled: 0.0251 (0.0251)  loss_iou_0_unscaled: 0.1844 (0.1844)  loss_ce_1_unscaled: 0.0236 (0.0236)  loss_segments_1_unscaled: 0.0251 (0.0251)  loss_iou_1_unscaled: 0.1857 (0.1857)  loss_ce_2_unscaled: 0.0247 (0.0247)  loss_segments_2_unscaled: 0.0251 (0.0251)  loss_iou_2_unscaled: 0.1796 (0.1796)  time: 0.3093  data: 0.2130  max mem: 488
[11/28 15:57:22][INFO]: Epoch: [12]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 1.9504 (1.9634)  loss_ce: 0.0524 (0.0545)  loss_iou: 0.2374 (0.2480)  loss_ce_0: 0.0772 (0.0724)  loss_iou_0: 0.5157 (0.5151)  loss_ce_1: 0.0571 (0.0586)  loss_iou_1: 0.4899 (0.4863)  loss_ce_2: 0.0527 (0.0547)  loss_iou_2: 0.4755 (0.4738)  loss_ce_unscaled: 0.0262 (0.0273)  class_error_unscaled: 0.0000 (0.4189)  loss_segments_unscaled: 0.0342 (0.0325)  loss_iou_unscaled: 0.1187 (0.1240)  loss_ce_0_unscaled: 0.0386 (0.0362)  loss_segments_0_unscaled: 0.0374 (0.0362)  loss_iou_0_unscaled: 0.2578 (0.2576)  loss_ce_1_unscaled: 0.0285 (0.0293)  loss_segments_1_unscaled: 0.0343 (0.0340)  loss_iou_1_unscaled: 0.2449 (0.2432)  loss_ce_2_unscaled: 0.0263 (0.0273)  loss_segments_2_unscaled: 0.0342 (0.0331)  loss_iou_2_unscaled: 0.2377 (0.2369)  time: 0.0692  data: 0.0011  max mem: 488
[11/28 15:57:23][INFO]: Epoch: [12]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 1.8324 (1.9210)  loss_ce: 0.0579 (0.0627)  loss_iou: 0.2226 (0.2370)  loss_ce_0: 0.0803 (0.0794)  loss_iou_0: 0.4731 (0.5002)  loss_ce_1: 0.0725 (0.0660)  loss_iou_1: 0.4170 (0.4617)  loss_ce_2: 0.0635 (0.0610)  loss_iou_2: 0.4157 (0.4528)  loss_ce_unscaled: 0.0290 (0.0314)  class_error_unscaled: 0.0000 (0.5567)  loss_segments_unscaled: 0.0271 (0.0306)  loss_iou_unscaled: 0.1113 (0.1185)  loss_ce_0_unscaled: 0.0401 (0.0397)  loss_segments_0_unscaled: 0.0315 (0.0348)  loss_iou_0_unscaled: 0.2366 (0.2501)  loss_ce_1_unscaled: 0.0363 (0.0330)  loss_segments_1_unscaled: 0.0274 (0.0315)  loss_iou_1_unscaled: 0.2085 (0.2309)  loss_ce_2_unscaled: 0.0317 (0.0305)  loss_segments_2_unscaled: 0.0276 (0.0311)  loss_iou_2_unscaled: 0.2078 (0.2264)  time: 0.0691  data: 0.0012  max mem: 488
[11/28 15:57:25][INFO]: Epoch: [12]  [ 60/198]  eta: 0:00:10  lr: 0.000200  loss: 2.0815 (1.9716)  loss_ce: 0.0820 (0.0693)  loss_iou: 0.2220 (0.2336)  loss_ce_0: 0.0942 (0.0884)  loss_iou_0: 0.5371 (0.5099)  loss_ce_1: 0.0795 (0.0737)  loss_iou_1: 0.4775 (0.4674)  loss_ce_2: 0.0799 (0.0691)  loss_iou_2: 0.4716 (0.4603)  loss_ce_unscaled: 0.0410 (0.0346)  class_error_unscaled: 0.0000 (0.4479)  loss_segments_unscaled: 0.0352 (0.0327)  loss_iou_unscaled: 0.1110 (0.1168)  loss_ce_0_unscaled: 0.0471 (0.0442)  loss_segments_0_unscaled: 0.0395 (0.0369)  loss_iou_0_unscaled: 0.2685 (0.2549)  loss_ce_1_unscaled: 0.0397 (0.0368)  loss_segments_1_unscaled: 0.0361 (0.0334)  loss_iou_1_unscaled: 0.2388 (0.2337)  loss_ce_2_unscaled: 0.0400 (0.0345)  loss_segments_2_unscaled: 0.0356 (0.0330)  loss_iou_2_unscaled: 0.2358 (0.2302)  time: 0.0683  data: 0.0013  max mem: 488
[11/28 15:57:26][INFO]: Epoch: [12]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 1.9761 (2.0127)  loss_ce: 0.0695 (0.0759)  loss_iou: 0.2424 (0.2354)  loss_ce_0: 0.0926 (0.0930)  loss_iou_0: 0.5100 (0.5152)  loss_ce_1: 0.0774 (0.0805)  loss_iou_1: 0.4450 (0.4715)  loss_ce_2: 0.0745 (0.0758)  loss_iou_2: 0.4414 (0.4653)  loss_ce_unscaled: 0.0348 (0.0380)  class_error_unscaled: 0.0000 (0.5429)  loss_segments_unscaled: 0.0309 (0.0332)  loss_iou_unscaled: 0.1212 (0.1177)  loss_ce_0_unscaled: 0.0463 (0.0465)  loss_segments_0_unscaled: 0.0335 (0.0374)  loss_iou_0_unscaled: 0.2550 (0.2576)  loss_ce_1_unscaled: 0.0387 (0.0403)  loss_segments_1_unscaled: 0.0297 (0.0337)  loss_iou_1_unscaled: 0.2225 (0.2358)  loss_ce_2_unscaled: 0.0373 (0.0379)  loss_segments_2_unscaled: 0.0309 (0.0333)  loss_iou_2_unscaled: 0.2207 (0.2327)  time: 0.0710  data: 0.0012  max mem: 488
[11/28 15:57:27][INFO]: Epoch: [12]  [100/198]  eta: 0:00:07  lr: 0.000200  loss: 1.7988 (1.9785)  loss_ce: 0.0502 (0.0719)  loss_iou: 0.2157 (0.2321)  loss_ce_0: 0.0742 (0.0895)  loss_iou_0: 0.4591 (0.5099)  loss_ce_1: 0.0520 (0.0768)  loss_iou_1: 0.4063 (0.4660)  loss_ce_2: 0.0516 (0.0718)  loss_iou_2: 0.4084 (0.4604)  loss_ce_unscaled: 0.0251 (0.0360)  class_error_unscaled: 0.0000 (0.4565)  loss_segments_unscaled: 0.0296 (0.0325)  loss_iou_unscaled: 0.1079 (0.1161)  loss_ce_0_unscaled: 0.0371 (0.0448)  loss_segments_0_unscaled: 0.0343 (0.0369)  loss_iou_0_unscaled: 0.2295 (0.2550)  loss_ce_1_unscaled: 0.0260 (0.0384)  loss_segments_1_unscaled: 0.0307 (0.0331)  loss_iou_1_unscaled: 0.2032 (0.2330)  loss_ce_2_unscaled: 0.0258 (0.0359)  loss_segments_2_unscaled: 0.0297 (0.0327)  loss_iou_2_unscaled: 0.2042 (0.2302)  time: 0.0698  data: 0.0012  max mem: 488
[11/28 15:57:29][INFO]: Epoch: [12]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 1.7417 (1.9500)  loss_ce: 0.0400 (0.0687)  loss_iou: 0.2154 (0.2313)  loss_ce_0: 0.0654 (0.0867)  loss_iou_0: 0.4731 (0.5046)  loss_ce_1: 0.0506 (0.0731)  loss_iou_1: 0.4283 (0.4615)  loss_ce_2: 0.0391 (0.0685)  loss_iou_2: 0.4077 (0.4556)  loss_ce_unscaled: 0.0200 (0.0344)  class_error_unscaled: 0.0000 (0.4328)  loss_segments_unscaled: 0.0270 (0.0318)  loss_iou_unscaled: 0.1077 (0.1157)  loss_ce_0_unscaled: 0.0327 (0.0434)  loss_segments_0_unscaled: 0.0312 (0.0361)  loss_iou_0_unscaled: 0.2366 (0.2523)  loss_ce_1_unscaled: 0.0253 (0.0365)  loss_segments_1_unscaled: 0.0282 (0.0324)  loss_iou_1_unscaled: 0.2141 (0.2307)  loss_ce_2_unscaled: 0.0196 (0.0342)  loss_segments_2_unscaled: 0.0280 (0.0320)  loss_iou_2_unscaled: 0.2039 (0.2278)  time: 0.0685  data: 0.0012  max mem: 488
[11/28 15:57:30][INFO]: Epoch: [12]  [140/198]  eta: 0:00:04  lr: 0.000200  loss: 1.9736 (1.9652)  loss_ce: 0.0636 (0.0676)  loss_iou: 0.2422 (0.2331)  loss_ce_0: 0.0909 (0.0876)  loss_iou_0: 0.4952 (0.5086)  loss_ce_1: 0.0665 (0.0719)  loss_iou_1: 0.4764 (0.4670)  loss_ce_2: 0.0564 (0.0669)  loss_iou_2: 0.4840 (0.4624)  loss_ce_unscaled: 0.0318 (0.0338)  class_error_unscaled: 0.0000 (0.3995)  loss_segments_unscaled: 0.0309 (0.0321)  loss_iou_unscaled: 0.1211 (0.1166)  loss_ce_0_unscaled: 0.0454 (0.0438)  loss_segments_0_unscaled: 0.0344 (0.0363)  loss_iou_0_unscaled: 0.2476 (0.2543)  loss_ce_1_unscaled: 0.0333 (0.0360)  loss_segments_1_unscaled: 0.0316 (0.0328)  loss_iou_1_unscaled: 0.2382 (0.2335)  loss_ce_2_unscaled: 0.0282 (0.0335)  loss_segments_2_unscaled: 0.0309 (0.0323)  loss_iou_2_unscaled: 0.2420 (0.2312)  time: 0.0670  data: 0.0012  max mem: 488
[11/28 15:57:31][INFO]: Epoch: [12]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 1.8971 (1.9632)  loss_ce: 0.0510 (0.0664)  loss_iou: 0.2375 (0.2337)  loss_ce_0: 0.0880 (0.0876)  loss_iou_0: 0.4997 (0.5091)  loss_ce_1: 0.0776 (0.0723)  loss_iou_1: 0.4507 (0.4667)  loss_ce_2: 0.0530 (0.0657)  loss_iou_2: 0.4301 (0.4617)  loss_ce_unscaled: 0.0255 (0.0332)  class_error_unscaled: 0.0000 (0.3628)  loss_segments_unscaled: 0.0272 (0.0318)  loss_iou_unscaled: 0.1187 (0.1168)  loss_ce_0_unscaled: 0.0440 (0.0438)  loss_segments_0_unscaled: 0.0323 (0.0362)  loss_iou_0_unscaled: 0.2498 (0.2545)  loss_ce_1_unscaled: 0.0388 (0.0362)  loss_segments_1_unscaled: 0.0278 (0.0325)  loss_iou_1_unscaled: 0.2253 (0.2333)  loss_ce_2_unscaled: 0.0265 (0.0329)  loss_segments_2_unscaled: 0.0272 (0.0320)  loss_iou_2_unscaled: 0.2150 (0.2308)  time: 0.0677  data: 0.0013  max mem: 488
[11/28 15:57:33][INFO]: Epoch: [12]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 1.8998 (1.9655)  loss_ce: 0.0510 (0.0665)  loss_iou: 0.2333 (0.2352)  loss_ce_0: 0.0773 (0.0890)  loss_iou_0: 0.4845 (0.5084)  loss_ce_1: 0.0547 (0.0720)  loss_iou_1: 0.4605 (0.4668)  loss_ce_2: 0.0525 (0.0663)  loss_iou_2: 0.4451 (0.4614)  loss_ce_unscaled: 0.0255 (0.0333)  class_error_unscaled: 0.0000 (0.4083)  loss_segments_unscaled: 0.0296 (0.0318)  loss_iou_unscaled: 0.1166 (0.1176)  loss_ce_0_unscaled: 0.0386 (0.0445)  loss_segments_0_unscaled: 0.0337 (0.0360)  loss_iou_0_unscaled: 0.2423 (0.2542)  loss_ce_1_unscaled: 0.0274 (0.0360)  loss_segments_1_unscaled: 0.0300 (0.0324)  loss_iou_1_unscaled: 0.2303 (0.2334)  loss_ce_2_unscaled: 0.0262 (0.0331)  loss_segments_2_unscaled: 0.0296 (0.0319)  loss_iou_2_unscaled: 0.2226 (0.2307)  time: 0.0673  data: 0.0012  max mem: 488
[11/28 15:57:34][INFO]: Epoch: [12]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 1.8539 (1.9560)  loss_ce: 0.0647 (0.0665)  loss_iou: 0.2267 (0.2345)  loss_ce_0: 0.0837 (0.0891)  loss_iou_0: 0.4850 (0.5059)  loss_ce_1: 0.0612 (0.0719)  loss_iou_1: 0.4469 (0.4639)  loss_ce_2: 0.0687 (0.0663)  loss_iou_2: 0.4312 (0.4580)  loss_ce_unscaled: 0.0324 (0.0332)  class_error_unscaled: 0.0000 (0.4224)  loss_segments_unscaled: 0.0258 (0.0317)  loss_iou_unscaled: 0.1133 (0.1172)  loss_ce_0_unscaled: 0.0419 (0.0445)  loss_segments_0_unscaled: 0.0315 (0.0360)  loss_iou_0_unscaled: 0.2425 (0.2529)  loss_ce_1_unscaled: 0.0306 (0.0360)  loss_segments_1_unscaled: 0.0278 (0.0324)  loss_iou_1_unscaled: 0.2234 (0.2319)  loss_ce_2_unscaled: 0.0344 (0.0332)  loss_segments_2_unscaled: 0.0258 (0.0318)  loss_iou_2_unscaled: 0.2156 (0.2290)  time: 0.0667  data: 0.0012  max mem: 488
[11/28 15:57:34][INFO]: Epoch: [12] Total time: 0:00:13 (0.0700 s / it)
[11/28 15:57:34][INFO]: Averaged stats:lr: 0.000200  loss: 1.8539 (1.9560)  loss_ce: 0.0647 (0.0665)  loss_iou: 0.2267 (0.2345)  loss_ce_0: 0.0837 (0.0891)  loss_iou_0: 0.4850 (0.5059)  loss_ce_1: 0.0612 (0.0719)  loss_iou_1: 0.4469 (0.4639)  loss_ce_2: 0.0687 (0.0663)  loss_iou_2: 0.4312 (0.4580)  loss_ce_unscaled: 0.0324 (0.0332)  class_error_unscaled: 0.0000 (0.4224)  loss_segments_unscaled: 0.0258 (0.0317)  loss_iou_unscaled: 0.1133 (0.1172)  loss_ce_0_unscaled: 0.0419 (0.0445)  loss_segments_0_unscaled: 0.0315 (0.0360)  loss_iou_0_unscaled: 0.2425 (0.2529)  loss_ce_1_unscaled: 0.0306 (0.0360)  loss_segments_1_unscaled: 0.0278 (0.0324)  loss_iou_1_unscaled: 0.2234 (0.2319)  loss_ce_2_unscaled: 0.0344 (0.0332)  loss_segments_2_unscaled: 0.0258 (0.0318)  loss_iou_2_unscaled: 0.2156 (0.2290)
[11/28 15:57:34][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 25.95it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:57:42][INFO]: mode=raw 122632 predictions from 210 videos
[11/28 15:57:46][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
73.78 67.60 58.37 45.30 30.39 55.09 raw epoch12
[11/28 15:57:46][INFO]: mAP_raw: 55.09
[11/28 15:57:46][INFO]: new best metric 0.5509@epoch12
[11/28 15:57:46][INFO]: lr=0.0002
[11/28 15:57:46][INFO]: lr=1e-05
[11/28 15:57:46][INFO]: lr=2e-05
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:57:46][INFO]: Epoch: [13]  [  0/198]  eta: 0:00:58  lr: 0.000200  loss: 1.7267 (1.7267)  loss_ce: 0.0173 (0.0173)  loss_iou: 0.2139 (0.2139)  loss_ce_0: 0.0552 (0.0552)  loss_iou_0: 0.5186 (0.5186)  loss_ce_1: 0.0346 (0.0346)  loss_iou_1: 0.4433 (0.4433)  loss_ce_2: 0.0130 (0.0130)  loss_iou_2: 0.4309 (0.4309)  loss_ce_unscaled: 0.0086 (0.0086)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0254 (0.0254)  loss_iou_unscaled: 0.1069 (0.1069)  loss_ce_0_unscaled: 0.0276 (0.0276)  loss_segments_0_unscaled: 0.0318 (0.0318)  loss_iou_0_unscaled: 0.2593 (0.2593)  loss_ce_1_unscaled: 0.0173 (0.0173)  loss_segments_1_unscaled: 0.0260 (0.0260)  loss_iou_1_unscaled: 0.2216 (0.2216)  loss_ce_2_unscaled: 0.0065 (0.0065)  loss_segments_2_unscaled: 0.0254 (0.0254)  loss_iou_2_unscaled: 0.2154 (0.2154)  time: 0.2970  data: 0.2112  max mem: 488
[11/28 15:57:48][INFO]: Epoch: [13]  [ 20/198]  eta: 0:00:14  lr: 0.000200  loss: 1.6945 (1.7620)  loss_ce: 0.0578 (0.0517)  loss_iou: 0.2273 (0.2319)  loss_ce_0: 0.0703 (0.0726)  loss_iou_0: 0.4412 (0.4637)  loss_ce_1: 0.0630 (0.0594)  loss_iou_1: 0.4094 (0.4176)  loss_ce_2: 0.0450 (0.0492)  loss_iou_2: 0.4105 (0.4158)  loss_ce_unscaled: 0.0289 (0.0258)  class_error_unscaled: 0.0000 (0.1082)  loss_segments_unscaled: 0.0303 (0.0307)  loss_iou_unscaled: 0.1136 (0.1160)  loss_ce_0_unscaled: 0.0352 (0.0363)  loss_segments_0_unscaled: 0.0326 (0.0351)  loss_iou_0_unscaled: 0.2206 (0.2319)  loss_ce_1_unscaled: 0.0315 (0.0297)  loss_segments_1_unscaled: 0.0287 (0.0309)  loss_iou_1_unscaled: 0.2047 (0.2088)  loss_ce_2_unscaled: 0.0225 (0.0246)  loss_segments_2_unscaled: 0.0303 (0.0312)  loss_iou_2_unscaled: 0.2053 (0.2079)  time: 0.0699  data: 0.0011  max mem: 488
[11/28 15:57:49][INFO]: Epoch: [13]  [ 40/198]  eta: 0:00:11  lr: 0.000200  loss: 1.7596 (1.7833)  loss_ce: 0.0427 (0.0524)  loss_iou: 0.2313 (0.2310)  loss_ce_0: 0.0789 (0.0787)  loss_iou_0: 0.4515 (0.4668)  loss_ce_1: 0.0619 (0.0624)  loss_iou_1: 0.4155 (0.4214)  loss_ce_2: 0.0501 (0.0512)  loss_iou_2: 0.4189 (0.4193)  loss_ce_unscaled: 0.0214 (0.0262)  class_error_unscaled: 0.0000 (0.0554)  loss_segments_unscaled: 0.0287 (0.0297)  loss_iou_unscaled: 0.1156 (0.1155)  loss_ce_0_unscaled: 0.0395 (0.0393)  loss_segments_0_unscaled: 0.0317 (0.0343)  loss_iou_0_unscaled: 0.2257 (0.2334)  loss_ce_1_unscaled: 0.0309 (0.0312)  loss_segments_1_unscaled: 0.0295 (0.0300)  loss_iou_1_unscaled: 0.2078 (0.2107)  loss_ce_2_unscaled: 0.0250 (0.0256)  loss_segments_2_unscaled: 0.0287 (0.0299)  loss_iou_2_unscaled: 0.2094 (0.2097)  time: 0.0683  data: 0.0011  max mem: 488
[11/28 15:57:51][INFO]: Epoch: [13]  [ 60/198]  eta: 0:00:10  lr: 0.000200  loss: 2.1569 (1.9030)  loss_ce: 0.0827 (0.0631)  loss_iou: 0.2163 (0.2289)  loss_ce_0: 0.0817 (0.0844)  loss_iou_0: 0.5943 (0.5010)  loss_ce_1: 0.0832 (0.0700)  loss_iou_1: 0.5330 (0.4483)  loss_ce_2: 0.0766 (0.0625)  loss_iou_2: 0.5211 (0.4448)  loss_ce_unscaled: 0.0413 (0.0316)  class_error_unscaled: 0.0000 (0.5178)  loss_segments_unscaled: 0.0337 (0.0310)  loss_iou_unscaled: 0.1082 (0.1144)  loss_ce_0_unscaled: 0.0409 (0.0422)  loss_segments_0_unscaled: 0.0402 (0.0362)  loss_iou_0_unscaled: 0.2972 (0.2505)  loss_ce_1_unscaled: 0.0416 (0.0350)  loss_segments_1_unscaled: 0.0323 (0.0313)  loss_iou_1_unscaled: 0.2665 (0.2241)  loss_ce_2_unscaled: 0.0383 (0.0312)  loss_segments_2_unscaled: 0.0322 (0.0309)  loss_iou_2_unscaled: 0.2606 (0.2224)  time: 0.0698  data: 0.0011  max mem: 488
[11/28 15:57:52][INFO]: Epoch: [13]  [ 80/198]  eta: 0:00:08  lr: 0.000200  loss: 1.8652 (1.9258)  loss_ce: 0.0606 (0.0659)  loss_iou: 0.2232 (0.2284)  loss_ce_0: 0.1017 (0.0890)  loss_iou_0: 0.5065 (0.5056)  loss_ce_1: 0.0725 (0.0738)  loss_iou_1: 0.4226 (0.4510)  loss_ce_2: 0.0567 (0.0651)  loss_iou_2: 0.4410 (0.4470)  loss_ce_unscaled: 0.0303 (0.0330)  class_error_unscaled: 0.0000 (0.4616)  loss_segments_unscaled: 0.0299 (0.0314)  loss_iou_unscaled: 0.1116 (0.1142)  loss_ce_0_unscaled: 0.0508 (0.0445)  loss_segments_0_unscaled: 0.0353 (0.0367)  loss_iou_0_unscaled: 0.2533 (0.2528)  loss_ce_1_unscaled: 0.0363 (0.0369)  loss_segments_1_unscaled: 0.0300 (0.0319)  loss_iou_1_unscaled: 0.2113 (0.2255)  loss_ce_2_unscaled: 0.0283 (0.0326)  loss_segments_2_unscaled: 0.0299 (0.0315)  loss_iou_2_unscaled: 0.2205 (0.2235)  time: 0.0702  data: 0.0012  max mem: 488
[11/28 15:57:53][INFO]: Epoch: [13]  [100/198]  eta: 0:00:07  lr: 0.000200  loss: 1.7152 (1.9047)  loss_ce: 0.0456 (0.0636)  loss_iou: 0.2220 (0.2285)  loss_ce_0: 0.0781 (0.0872)  loss_iou_0: 0.4557 (0.4995)  loss_ce_1: 0.0590 (0.0722)  loss_iou_1: 0.4110 (0.4476)  loss_ce_2: 0.0482 (0.0627)  loss_iou_2: 0.4134 (0.4435)  loss_ce_unscaled: 0.0228 (0.0318)  class_error_unscaled: 0.0000 (0.3702)  loss_segments_unscaled: 0.0344 (0.0321)  loss_iou_unscaled: 0.1110 (0.1143)  loss_ce_0_unscaled: 0.0390 (0.0436)  loss_segments_0_unscaled: 0.0383 (0.0371)  loss_iou_0_unscaled: 0.2278 (0.2497)  loss_ce_1_unscaled: 0.0295 (0.0361)  loss_segments_1_unscaled: 0.0326 (0.0325)  loss_iou_1_unscaled: 0.2055 (0.2238)  loss_ce_2_unscaled: 0.0241 (0.0313)  loss_segments_2_unscaled: 0.0340 (0.0321)  loss_iou_2_unscaled: 0.2067 (0.2218)  time: 0.0692  data: 0.0012  max mem: 488
[11/28 15:57:55][INFO]: Epoch: [13]  [120/198]  eta: 0:00:05  lr: 0.000200  loss: 1.8121 (1.9106)  loss_ce: 0.0615 (0.0641)  loss_iou: 0.2262 (0.2284)  loss_ce_0: 0.0760 (0.0864)  loss_iou_0: 0.4891 (0.5018)  loss_ce_1: 0.0668 (0.0718)  loss_iou_1: 0.4113 (0.4497)  loss_ce_2: 0.0635 (0.0631)  loss_iou_2: 0.4155 (0.4453)  loss_ce_unscaled: 0.0307 (0.0321)  class_error_unscaled: 0.0000 (0.3370)  loss_segments_unscaled: 0.0263 (0.0315)  loss_iou_unscaled: 0.1131 (0.1142)  loss_ce_0_unscaled: 0.0380 (0.0432)  loss_segments_0_unscaled: 0.0349 (0.0368)  loss_iou_0_unscaled: 0.2446 (0.2509)  loss_ce_1_unscaled: 0.0334 (0.0359)  loss_segments_1_unscaled: 0.0283 (0.0322)  loss_iou_1_unscaled: 0.2057 (0.2249)  loss_ce_2_unscaled: 0.0317 (0.0315)  loss_segments_2_unscaled: 0.0263 (0.0317)  loss_iou_2_unscaled: 0.2077 (0.2226)  time: 0.0667  data: 0.0011  max mem: 488
[11/28 15:57:56][INFO]: Epoch: [13]  [140/198]  eta: 0:00:04  lr: 0.000200  loss: 2.0165 (1.9274)  loss_ce: 0.0559 (0.0669)  loss_iou: 0.2251 (0.2295)  loss_ce_0: 0.0893 (0.0879)  loss_iou_0: 0.4844 (0.5032)  loss_ce_1: 0.0675 (0.0730)  loss_iou_1: 0.4647 (0.4530)  loss_ce_2: 0.0514 (0.0658)  loss_iou_2: 0.4645 (0.4480)  loss_ce_unscaled: 0.0280 (0.0334)  class_error_unscaled: 0.0000 (0.3949)  loss_segments_unscaled: 0.0266 (0.0313)  loss_iou_unscaled: 0.1125 (0.1148)  loss_ce_0_unscaled: 0.0446 (0.0440)  loss_segments_0_unscaled: 0.0301 (0.0364)  loss_iou_0_unscaled: 0.2422 (0.2516)  loss_ce_1_unscaled: 0.0338 (0.0365)  loss_segments_1_unscaled: 0.0280 (0.0319)  loss_iou_1_unscaled: 0.2324 (0.2265)  loss_ce_2_unscaled: 0.0257 (0.0329)  loss_segments_2_unscaled: 0.0278 (0.0315)  loss_iou_2_unscaled: 0.2322 (0.2240)  time: 0.0653  data: 0.0012  max mem: 488
[11/28 15:57:57][INFO]: Epoch: [13]  [160/198]  eta: 0:00:02  lr: 0.000200  loss: 1.6478 (1.9086)  loss_ce: 0.0466 (0.0653)  loss_iou: 0.2168 (0.2287)  loss_ce_0: 0.0757 (0.0862)  loss_iou_0: 0.4565 (0.4986)  loss_ce_1: 0.0527 (0.0708)  loss_iou_1: 0.4154 (0.4503)  loss_ce_2: 0.0427 (0.0638)  loss_iou_2: 0.3955 (0.4449)  loss_ce_unscaled: 0.0233 (0.0327)  class_error_unscaled: 0.0000 (0.3666)  loss_segments_unscaled: 0.0270 (0.0310)  loss_iou_unscaled: 0.1084 (0.1143)  loss_ce_0_unscaled: 0.0379 (0.0431)  loss_segments_0_unscaled: 0.0322 (0.0360)  loss_iou_0_unscaled: 0.2282 (0.2493)  loss_ce_1_unscaled: 0.0264 (0.0354)  loss_segments_1_unscaled: 0.0289 (0.0316)  loss_iou_1_unscaled: 0.2077 (0.2251)  loss_ce_2_unscaled: 0.0214 (0.0319)  loss_segments_2_unscaled: 0.0267 (0.0311)  loss_iou_2_unscaled: 0.1978 (0.2224)  time: 0.0698  data: 0.0013  max mem: 488
[11/28 15:57:59][INFO]: Epoch: [13]  [180/198]  eta: 0:00:01  lr: 0.000200  loss: 1.7405 (1.9042)  loss_ce: 0.0499 (0.0643)  loss_iou: 0.2410 (0.2298)  loss_ce_0: 0.0741 (0.0852)  loss_iou_0: 0.4394 (0.4972)  loss_ce_1: 0.0476 (0.0693)  loss_iou_1: 0.4239 (0.4507)  loss_ce_2: 0.0477 (0.0627)  loss_iou_2: 0.4185 (0.4450)  loss_ce_unscaled: 0.0250 (0.0321)  class_error_unscaled: 0.0000 (0.3261)  loss_segments_unscaled: 0.0273 (0.0308)  loss_iou_unscaled: 0.1205 (0.1149)  loss_ce_0_unscaled: 0.0371 (0.0426)  loss_segments_0_unscaled: 0.0294 (0.0355)  loss_iou_0_unscaled: 0.2197 (0.2486)  loss_ce_1_unscaled: 0.0238 (0.0347)  loss_segments_1_unscaled: 0.0284 (0.0314)  loss_iou_1_unscaled: 0.2120 (0.2254)  loss_ce_2_unscaled: 0.0239 (0.0313)  loss_segments_2_unscaled: 0.0273 (0.0309)  loss_iou_2_unscaled: 0.2092 (0.2225)  time: 0.0717  data: 0.0012  max mem: 488
[11/28 15:58:00][INFO]: Epoch: [13]  [197/198]  eta: 0:00:00  lr: 0.000200  loss: 1.8035 (1.9002)  loss_ce: 0.0502 (0.0639)  loss_iou: 0.2193 (0.2295)  loss_ce_0: 0.0706 (0.0841)  loss_iou_0: 0.4791 (0.4963)  loss_ce_1: 0.0509 (0.0685)  loss_iou_1: 0.4324 (0.4503)  loss_ce_2: 0.0590 (0.0626)  loss_iou_2: 0.4417 (0.4449)  loss_ce_unscaled: 0.0251 (0.0320)  class_error_unscaled: 0.0000 (0.3034)  loss_segments_unscaled: 0.0301 (0.0309)  loss_iou_unscaled: 0.1097 (0.1147)  loss_ce_0_unscaled: 0.0353 (0.0421)  loss_segments_0_unscaled: 0.0343 (0.0355)  loss_iou_0_unscaled: 0.2396 (0.2481)  loss_ce_1_unscaled: 0.0255 (0.0343)  loss_segments_1_unscaled: 0.0309 (0.0314)  loss_iou_1_unscaled: 0.2162 (0.2252)  loss_ce_2_unscaled: 0.0295 (0.0313)  loss_segments_2_unscaled: 0.0301 (0.0309)  loss_iou_2_unscaled: 0.2209 (0.2224)  time: 0.0681  data: 0.0013  max mem: 488
[11/28 15:58:00][INFO]: Epoch: [13] Total time: 0:00:13 (0.0703 s / it)
[11/28 15:58:00][INFO]: Averaged stats:lr: 0.000200  loss: 1.8035 (1.9002)  loss_ce: 0.0502 (0.0639)  loss_iou: 0.2193 (0.2295)  loss_ce_0: 0.0706 (0.0841)  loss_iou_0: 0.4791 (0.4963)  loss_ce_1: 0.0509 (0.0685)  loss_iou_1: 0.4324 (0.4503)  loss_ce_2: 0.0590 (0.0626)  loss_iou_2: 0.4417 (0.4449)  loss_ce_unscaled: 0.0251 (0.0320)  class_error_unscaled: 0.0000 (0.3034)  loss_segments_unscaled: 0.0301 (0.0309)  loss_iou_unscaled: 0.1097 (0.1147)  loss_ce_0_unscaled: 0.0353 (0.0421)  loss_segments_0_unscaled: 0.0343 (0.0355)  loss_iou_0_unscaled: 0.2396 (0.2481)  loss_ce_1_unscaled: 0.0255 (0.0343)  loss_segments_1_unscaled: 0.0309 (0.0314)  loss_iou_1_unscaled: 0.2162 (0.2252)  loss_ce_2_unscaled: 0.0295 (0.0313)  loss_segments_2_unscaled: 0.0301 (0.0309)  loss_iou_2_unscaled: 0.2209 (0.2224)
[11/28 15:58:00][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 25.88it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:58:08][INFO]: mode=raw 112734 predictions from 210 videos
[11/28 15:58:12][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
71.64 65.95 56.88 44.52 29.65 53.73 raw epoch13
[11/28 15:58:12][INFO]: mAP_raw: 53.73
[11/28 15:58:12][INFO]: lr=2e-05
[11/28 15:58:12][INFO]: lr=1.0000000000000002e-06
[11/28 15:58:12][INFO]: lr=2.0000000000000003e-06
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:58:12][INFO]: Epoch: [14]  [  0/198]  eta: 0:00:54  lr: 0.000020  loss: 1.9468 (1.9468)  loss_ce: 0.0494 (0.0494)  loss_iou: 0.2216 (0.2216)  loss_ce_0: 0.0554 (0.0554)  loss_iou_0: 0.5275 (0.5275)  loss_ce_1: 0.0439 (0.0439)  loss_iou_1: 0.5099 (0.5099)  loss_ce_2: 0.0349 (0.0349)  loss_iou_2: 0.5041 (0.5041)  loss_ce_unscaled: 0.0247 (0.0247)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0209 (0.0209)  loss_iou_unscaled: 0.1108 (0.1108)  loss_ce_0_unscaled: 0.0277 (0.0277)  loss_segments_0_unscaled: 0.0240 (0.0240)  loss_iou_0_unscaled: 0.2637 (0.2637)  loss_ce_1_unscaled: 0.0219 (0.0219)  loss_segments_1_unscaled: 0.0210 (0.0210)  loss_iou_1_unscaled: 0.2550 (0.2550)  loss_ce_2_unscaled: 0.0175 (0.0175)  loss_segments_2_unscaled: 0.0209 (0.0209)  loss_iou_2_unscaled: 0.2521 (0.2521)  time: 0.2762  data: 0.1794  max mem: 488
[11/28 15:58:14][INFO]: Epoch: [14]  [ 20/198]  eta: 0:00:14  lr: 0.000020  loss: 1.5890 (1.6459)  loss_ce: 0.0297 (0.0428)  loss_iou: 0.2177 (0.2190)  loss_ce_0: 0.0564 (0.0629)  loss_iou_0: 0.4412 (0.4432)  loss_ce_1: 0.0418 (0.0508)  loss_iou_1: 0.3758 (0.3940)  loss_ce_2: 0.0380 (0.0442)  loss_iou_2: 0.3582 (0.3890)  loss_ce_unscaled: 0.0149 (0.0214)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0255 (0.0263)  loss_iou_unscaled: 0.1089 (0.1095)  loss_ce_0_unscaled: 0.0282 (0.0315)  loss_segments_0_unscaled: 0.0299 (0.0310)  loss_iou_0_unscaled: 0.2206 (0.2216)  loss_ce_1_unscaled: 0.0209 (0.0254)  loss_segments_1_unscaled: 0.0249 (0.0267)  loss_iou_1_unscaled: 0.1879 (0.1970)  loss_ce_2_unscaled: 0.0190 (0.0221)  loss_segments_2_unscaled: 0.0255 (0.0263)  loss_iou_2_unscaled: 0.1791 (0.1945)  time: 0.0697  data: 0.0012  max mem: 488
[11/28 15:58:15][INFO]: Epoch: [14]  [ 40/198]  eta: 0:00:11  lr: 0.000020  loss: 1.5295 (1.6287)  loss_ce: 0.0329 (0.0381)  loss_iou: 0.2079 (0.2161)  loss_ce_0: 0.0408 (0.0532)  loss_iou_0: 0.4141 (0.4422)  loss_ce_1: 0.0302 (0.0432)  loss_iou_1: 0.3867 (0.3996)  loss_ce_2: 0.0331 (0.0396)  loss_iou_2: 0.3772 (0.3967)  loss_ce_unscaled: 0.0165 (0.0190)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0269 (0.0268)  loss_iou_unscaled: 0.1039 (0.1080)  loss_ce_0_unscaled: 0.0204 (0.0266)  loss_segments_0_unscaled: 0.0287 (0.0308)  loss_iou_0_unscaled: 0.2071 (0.2211)  loss_ce_1_unscaled: 0.0151 (0.0216)  loss_segments_1_unscaled: 0.0261 (0.0273)  loss_iou_1_unscaled: 0.1934 (0.1998)  loss_ce_2_unscaled: 0.0166 (0.0198)  loss_segments_2_unscaled: 0.0277 (0.0271)  loss_iou_2_unscaled: 0.1886 (0.1984)  time: 0.0701  data: 0.0012  max mem: 488
[11/28 15:58:17][INFO]: Epoch: [14]  [ 60/198]  eta: 0:00:10  lr: 0.000020  loss: 1.6363 (1.6647)  loss_ce: 0.0291 (0.0366)  loss_iou: 0.2235 (0.2203)  loss_ce_0: 0.0516 (0.0547)  loss_iou_0: 0.4451 (0.4512)  loss_ce_1: 0.0304 (0.0422)  loss_iou_1: 0.4162 (0.4125)  loss_ce_2: 0.0333 (0.0383)  loss_iou_2: 0.4112 (0.4088)  loss_ce_unscaled: 0.0145 (0.0183)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0267 (0.0273)  loss_iou_unscaled: 0.1117 (0.1102)  loss_ce_0_unscaled: 0.0258 (0.0274)  loss_segments_0_unscaled: 0.0317 (0.0311)  loss_iou_0_unscaled: 0.2226 (0.2256)  loss_ce_1_unscaled: 0.0152 (0.0211)  loss_segments_1_unscaled: 0.0277 (0.0279)  loss_iou_1_unscaled: 0.2081 (0.2062)  loss_ce_2_unscaled: 0.0167 (0.0192)  loss_segments_2_unscaled: 0.0267 (0.0275)  loss_iou_2_unscaled: 0.2056 (0.2044)  time: 0.0694  data: 0.0011  max mem: 488
[11/28 15:58:18][INFO]: Epoch: [14]  [ 80/198]  eta: 0:00:08  lr: 0.000020  loss: 1.5002 (1.6439)  loss_ce: 0.0251 (0.0354)  loss_iou: 0.2098 (0.2203)  loss_ce_0: 0.0513 (0.0547)  loss_iou_0: 0.4167 (0.4450)  loss_ce_1: 0.0325 (0.0413)  loss_iou_1: 0.3744 (0.4068)  loss_ce_2: 0.0318 (0.0374)  loss_iou_2: 0.3622 (0.4032)  loss_ce_unscaled: 0.0126 (0.0177)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0237 (0.0271)  loss_iou_unscaled: 0.1049 (0.1101)  loss_ce_0_unscaled: 0.0256 (0.0273)  loss_segments_0_unscaled: 0.0268 (0.0307)  loss_iou_0_unscaled: 0.2083 (0.2225)  loss_ce_1_unscaled: 0.0162 (0.0207)  loss_segments_1_unscaled: 0.0244 (0.0277)  loss_iou_1_unscaled: 0.1872 (0.2034)  loss_ce_2_unscaled: 0.0159 (0.0187)  loss_segments_2_unscaled: 0.0237 (0.0274)  loss_iou_2_unscaled: 0.1811 (0.2016)  time: 0.0666  data: 0.0011  max mem: 488
[11/28 15:58:19][INFO]: Epoch: [14]  [100/198]  eta: 0:00:06  lr: 0.000020  loss: 1.5262 (1.6310)  loss_ce: 0.0257 (0.0343)  loss_iou: 0.2207 (0.2208)  loss_ce_0: 0.0453 (0.0535)  loss_iou_0: 0.4423 (0.4424)  loss_ce_1: 0.0277 (0.0394)  loss_iou_1: 0.3956 (0.4040)  loss_ce_2: 0.0261 (0.0355)  loss_iou_2: 0.3876 (0.4010)  loss_ce_unscaled: 0.0128 (0.0171)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0218 (0.0265)  loss_iou_unscaled: 0.1103 (0.1104)  loss_ce_0_unscaled: 0.0226 (0.0267)  loss_segments_0_unscaled: 0.0252 (0.0302)  loss_iou_0_unscaled: 0.2212 (0.2212)  loss_ce_1_unscaled: 0.0139 (0.0197)  loss_segments_1_unscaled: 0.0226 (0.0270)  loss_iou_1_unscaled: 0.1978 (0.2020)  loss_ce_2_unscaled: 0.0131 (0.0178)  loss_segments_2_unscaled: 0.0218 (0.0268)  loss_iou_2_unscaled: 0.1938 (0.2005)  time: 0.0681  data: 0.0012  max mem: 488
[11/28 15:58:21][INFO]: Epoch: [14]  [120/198]  eta: 0:00:05  lr: 0.000020  loss: 1.5505 (1.6170)  loss_ce: 0.0306 (0.0342)  loss_iou: 0.2260 (0.2222)  loss_ce_0: 0.0468 (0.0532)  loss_iou_0: 0.4009 (0.4374)  loss_ce_1: 0.0330 (0.0392)  loss_iou_1: 0.3836 (0.3994)  loss_ce_2: 0.0317 (0.0353)  loss_iou_2: 0.3744 (0.3961)  loss_ce_unscaled: 0.0153 (0.0171)  class_error_unscaled: 0.0000 (0.0153)  loss_segments_unscaled: 0.0244 (0.0265)  loss_iou_unscaled: 0.1130 (0.1111)  loss_ce_0_unscaled: 0.0234 (0.0266)  loss_segments_0_unscaled: 0.0269 (0.0301)  loss_iou_0_unscaled: 0.2004 (0.2187)  loss_ce_1_unscaled: 0.0165 (0.0196)  loss_segments_1_unscaled: 0.0251 (0.0270)  loss_iou_1_unscaled: 0.1918 (0.1997)  loss_ce_2_unscaled: 0.0158 (0.0177)  loss_segments_2_unscaled: 0.0244 (0.0267)  loss_iou_2_unscaled: 0.1872 (0.1981)  time: 0.0665  data: 0.0013  max mem: 488
[11/28 15:58:22][INFO]: Epoch: [14]  [140/198]  eta: 0:00:04  lr: 0.000020  loss: 1.4669 (1.6051)  loss_ce: 0.0320 (0.0337)  loss_iou: 0.2122 (0.2212)  loss_ce_0: 0.0512 (0.0529)  loss_iou_0: 0.3621 (0.4344)  loss_ce_1: 0.0310 (0.0381)  loss_iou_1: 0.3720 (0.3968)  loss_ce_2: 0.0271 (0.0347)  loss_iou_2: 0.3378 (0.3933)  loss_ce_unscaled: 0.0160 (0.0169)  class_error_unscaled: 0.0000 (0.0131)  loss_segments_unscaled: 0.0232 (0.0263)  loss_iou_unscaled: 0.1061 (0.1106)  loss_ce_0_unscaled: 0.0256 (0.0265)  loss_segments_0_unscaled: 0.0244 (0.0298)  loss_iou_0_unscaled: 0.1810 (0.2172)  loss_ce_1_unscaled: 0.0155 (0.0191)  loss_segments_1_unscaled: 0.0248 (0.0270)  loss_iou_1_unscaled: 0.1860 (0.1984)  loss_ce_2_unscaled: 0.0135 (0.0174)  loss_segments_2_unscaled: 0.0239 (0.0266)  loss_iou_2_unscaled: 0.1689 (0.1966)  time: 0.0658  data: 0.0012  max mem: 488
[11/28 15:58:23][INFO]: Epoch: [14]  [160/198]  eta: 0:00:02  lr: 0.000020  loss: 1.5866 (1.6057)  loss_ce: 0.0181 (0.0336)  loss_iou: 0.2288 (0.2227)  loss_ce_0: 0.0484 (0.0531)  loss_iou_0: 0.4148 (0.4337)  loss_ce_1: 0.0312 (0.0383)  loss_iou_1: 0.3740 (0.3964)  loss_ce_2: 0.0287 (0.0349)  loss_iou_2: 0.3888 (0.3931)  loss_ce_unscaled: 0.0091 (0.0168)  class_error_unscaled: 0.0000 (0.0115)  loss_segments_unscaled: 0.0268 (0.0266)  loss_iou_unscaled: 0.1144 (0.1114)  loss_ce_0_unscaled: 0.0242 (0.0265)  loss_segments_0_unscaled: 0.0291 (0.0300)  loss_iou_0_unscaled: 0.2074 (0.2168)  loss_ce_1_unscaled: 0.0156 (0.0191)  loss_segments_1_unscaled: 0.0259 (0.0272)  loss_iou_1_unscaled: 0.1870 (0.1982)  loss_ce_2_unscaled: 0.0144 (0.0174)  loss_segments_2_unscaled: 0.0268 (0.0268)  loss_iou_2_unscaled: 0.1944 (0.1965)  time: 0.0686  data: 0.0012  max mem: 488
[11/28 15:58:25][INFO]: Epoch: [14]  [180/198]  eta: 0:00:01  lr: 0.000020  loss: 1.4648 (1.6029)  loss_ce: 0.0239 (0.0331)  loss_iou: 0.2171 (0.2223)  loss_ce_0: 0.0432 (0.0526)  loss_iou_0: 0.3912 (0.4327)  loss_ce_1: 0.0333 (0.0378)  loss_iou_1: 0.3612 (0.3968)  loss_ce_2: 0.0263 (0.0343)  loss_iou_2: 0.3588 (0.3933)  loss_ce_unscaled: 0.0120 (0.0165)  class_error_unscaled: 0.0000 (0.0102)  loss_segments_unscaled: 0.0239 (0.0267)  loss_iou_unscaled: 0.1085 (0.1111)  loss_ce_0_unscaled: 0.0216 (0.0263)  loss_segments_0_unscaled: 0.0257 (0.0301)  loss_iou_0_unscaled: 0.1956 (0.2163)  loss_ce_1_unscaled: 0.0167 (0.0189)  loss_segments_1_unscaled: 0.0237 (0.0273)  loss_iou_1_unscaled: 0.1806 (0.1984)  loss_ce_2_unscaled: 0.0132 (0.0171)  loss_segments_2_unscaled: 0.0242 (0.0269)  loss_iou_2_unscaled: 0.1794 (0.1966)  time: 0.0649  data: 0.0011  max mem: 488
[11/28 15:58:26][INFO]: Epoch: [14]  [197/198]  eta: 0:00:00  lr: 0.000020  loss: 1.4514 (1.5979)  loss_ce: 0.0263 (0.0332)  loss_iou: 0.2226 (0.2220)  loss_ce_0: 0.0450 (0.0529)  loss_iou_0: 0.3915 (0.4307)  loss_ce_1: 0.0279 (0.0377)  loss_iou_1: 0.3547 (0.3952)  loss_ce_2: 0.0221 (0.0344)  loss_iou_2: 0.3541 (0.3919)  loss_ce_unscaled: 0.0131 (0.0166)  class_error_unscaled: 0.0000 (0.0094)  loss_segments_unscaled: 0.0222 (0.0267)  loss_iou_unscaled: 0.1113 (0.1110)  loss_ce_0_unscaled: 0.0225 (0.0264)  loss_segments_0_unscaled: 0.0263 (0.0301)  loss_iou_0_unscaled: 0.1957 (0.2153)  loss_ce_1_unscaled: 0.0140 (0.0189)  loss_segments_1_unscaled: 0.0238 (0.0273)  loss_iou_1_unscaled: 0.1774 (0.1976)  loss_ce_2_unscaled: 0.0111 (0.0172)  loss_segments_2_unscaled: 0.0222 (0.0268)  loss_iou_2_unscaled: 0.1771 (0.1959)  time: 0.0656  data: 0.0012  max mem: 488
[11/28 15:58:26][INFO]: Epoch: [14] Total time: 0:00:13 (0.0689 s / it)
[11/28 15:58:26][INFO]: Averaged stats:lr: 0.000020  loss: 1.4514 (1.5979)  loss_ce: 0.0263 (0.0332)  loss_iou: 0.2226 (0.2220)  loss_ce_0: 0.0450 (0.0529)  loss_iou_0: 0.3915 (0.4307)  loss_ce_1: 0.0279 (0.0377)  loss_iou_1: 0.3547 (0.3952)  loss_ce_2: 0.0221 (0.0344)  loss_iou_2: 0.3541 (0.3919)  loss_ce_unscaled: 0.0131 (0.0166)  class_error_unscaled: 0.0000 (0.0094)  loss_segments_unscaled: 0.0222 (0.0267)  loss_iou_unscaled: 0.1113 (0.1110)  loss_ce_0_unscaled: 0.0225 (0.0264)  loss_segments_0_unscaled: 0.0263 (0.0301)  loss_iou_0_unscaled: 0.1957 (0.2153)  loss_ce_1_unscaled: 0.0140 (0.0189)  loss_segments_1_unscaled: 0.0238 (0.0273)  loss_iou_1_unscaled: 0.1774 (0.1976)  loss_ce_2_unscaled: 0.0111 (0.0172)  loss_segments_2_unscaled: 0.0222 (0.0268)  loss_iou_2_unscaled: 0.1771 (0.1959)
[11/28 15:58:26][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 25.96it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:58:34][INFO]: mode=raw 118207 predictions from 210 videos
[11/28 15:58:37][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
73.02 67.58 59.07 46.90 31.43 55.60 raw epoch14
[11/28 15:58:37][INFO]: mAP_raw: 55.60
[11/28 15:58:37][INFO]: new best metric 0.5560@epoch14
[11/28 15:58:37][INFO]: lr=2e-05
[11/28 15:58:37][INFO]: lr=1.0000000000000002e-06
[11/28 15:58:37][INFO]: lr=2.0000000000000003e-06
/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
[11/28 15:58:38][INFO]: Epoch: [15]  [  0/198]  eta: 0:00:57  lr: 0.000020  loss: 1.6910 (1.6910)  loss_ce: 0.0517 (0.0517)  loss_iou: 0.2009 (0.2009)  loss_ce_0: 0.0448 (0.0448)  loss_iou_0: 0.4518 (0.4518)  loss_ce_1: 0.0469 (0.0469)  loss_iou_1: 0.4158 (0.4158)  loss_ce_2: 0.0488 (0.0488)  loss_iou_2: 0.4302 (0.4302)  loss_ce_unscaled: 0.0258 (0.0258)  class_error_unscaled: 0.0000 (0.0000)  loss_segments_unscaled: 0.0230 (0.0230)  loss_iou_unscaled: 0.1005 (0.1005)  loss_ce_0_unscaled: 0.0224 (0.0224)  loss_segments_0_unscaled: 0.0268 (0.0268)  loss_iou_0_unscaled: 0.2259 (0.2259)  loss_ce_1_unscaled: 0.0235 (0.0235)  loss_segments_1_unscaled: 0.0223 (0.0223)  loss_iou_1_unscaled: 0.2079 (0.2079)  loss_ce_2_unscaled: 0.0244 (0.0244)  loss_segments_2_unscaled: 0.0241 (0.0241)  loss_iou_2_unscaled: 0.2151 (0.2151)  time: 0.2909  data: 0.2073  max mem: 488
[11/28 15:58:39][INFO]: Epoch: [15]  [ 20/198]  eta: 0:00:14  lr: 0.000020  loss: 1.4842 (1.5171)  loss_ce: 0.0191 (0.0247)  loss_iou: 0.2167 (0.2157)  loss_ce_0: 0.0460 (0.0465)  loss_iou_0: 0.4078 (0.4118)  loss_ce_1: 0.0314 (0.0339)  loss_iou_1: 0.3686 (0.3791)  loss_ce_2: 0.0228 (0.0268)  loss_iou_2: 0.3609 (0.3785)  loss_ce_unscaled: 0.0095 (0.0124)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0236 (0.0251)  loss_iou_unscaled: 0.1083 (0.1079)  loss_ce_0_unscaled: 0.0230 (0.0233)  loss_segments_0_unscaled: 0.0250 (0.0266)  loss_iou_0_unscaled: 0.2039 (0.2059)  loss_ce_1_unscaled: 0.0157 (0.0170)  loss_segments_1_unscaled: 0.0225 (0.0246)  loss_iou_1_unscaled: 0.1843 (0.1895)  loss_ce_2_unscaled: 0.0114 (0.0134)  loss_segments_2_unscaled: 0.0238 (0.0248)  loss_iou_2_unscaled: 0.1804 (0.1892)  time: 0.0694  data: 0.0011  max mem: 488
[11/28 15:58:40][INFO]: Epoch: [15]  [ 40/198]  eta: 0:00:11  lr: 0.000020  loss: 1.5225 (1.5266)  loss_ce: 0.0214 (0.0240)  loss_iou: 0.2210 (0.2213)  loss_ce_0: 0.0451 (0.0468)  loss_iou_0: 0.4146 (0.4170)  loss_ce_1: 0.0266 (0.0319)  loss_iou_1: 0.3915 (0.3803)  loss_ce_2: 0.0173 (0.0250)  loss_iou_2: 0.3890 (0.3802)  loss_ce_unscaled: 0.0107 (0.0120)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0236 (0.0252)  loss_iou_unscaled: 0.1105 (0.1107)  loss_ce_0_unscaled: 0.0225 (0.0234)  loss_segments_0_unscaled: 0.0272 (0.0273)  loss_iou_0_unscaled: 0.2073 (0.2085)  loss_ce_1_unscaled: 0.0133 (0.0159)  loss_segments_1_unscaled: 0.0238 (0.0249)  loss_iou_1_unscaled: 0.1958 (0.1901)  loss_ce_2_unscaled: 0.0087 (0.0125)  loss_segments_2_unscaled: 0.0236 (0.0252)  loss_iou_2_unscaled: 0.1945 (0.1901)  time: 0.0683  data: 0.0011  max mem: 488
[11/28 15:58:42][INFO]: Epoch: [15]  [ 60/198]  eta: 0:00:09  lr: 0.000020  loss: 1.3817 (1.5146)  loss_ce: 0.0202 (0.0240)  loss_iou: 0.2265 (0.2229)  loss_ce_0: 0.0453 (0.0457)  loss_iou_0: 0.3936 (0.4125)  loss_ce_1: 0.0225 (0.0305)  loss_iou_1: 0.3435 (0.3776)  loss_ce_2: 0.0249 (0.0250)  loss_iou_2: 0.3408 (0.3764)  loss_ce_unscaled: 0.0101 (0.0120)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0227 (0.0255)  loss_iou_unscaled: 0.1132 (0.1115)  loss_ce_0_unscaled: 0.0227 (0.0229)  loss_segments_0_unscaled: 0.0238 (0.0278)  loss_iou_0_unscaled: 0.1968 (0.2062)  loss_ce_1_unscaled: 0.0112 (0.0152)  loss_segments_1_unscaled: 0.0220 (0.0253)  loss_iou_1_unscaled: 0.1718 (0.1888)  loss_ce_2_unscaled: 0.0125 (0.0125)  loss_segments_2_unscaled: 0.0227 (0.0255)  loss_iou_2_unscaled: 0.1704 (0.1882)  time: 0.0673  data: 0.0012  max mem: 488
[11/28 15:58:43][INFO]: Epoch: [15]  [ 80/198]  eta: 0:00:08  lr: 0.000020  loss: 1.3320 (1.4949)  loss_ce: 0.0168 (0.0235)  loss_iou: 0.2195 (0.2227)  loss_ce_0: 0.0389 (0.0447)  loss_iou_0: 0.3678 (0.4073)  loss_ce_1: 0.0241 (0.0297)  loss_iou_1: 0.3255 (0.3715)  loss_ce_2: 0.0189 (0.0250)  loss_iou_2: 0.3249 (0.3705)  loss_ce_unscaled: 0.0084 (0.0118)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0228 (0.0251)  loss_iou_unscaled: 0.1098 (0.1113)  loss_ce_0_unscaled: 0.0194 (0.0224)  loss_segments_0_unscaled: 0.0239 (0.0274)  loss_iou_0_unscaled: 0.1839 (0.2037)  loss_ce_1_unscaled: 0.0121 (0.0149)  loss_segments_1_unscaled: 0.0221 (0.0250)  loss_iou_1_unscaled: 0.1628 (0.1858)  loss_ce_2_unscaled: 0.0095 (0.0125)  loss_segments_2_unscaled: 0.0229 (0.0252)  loss_iou_2_unscaled: 0.1625 (0.1852)  time: 0.0672  data: 0.0012  max mem: 488
[11/28 15:58:44][INFO]: Epoch: [15]  [100/198]  eta: 0:00:06  lr: 0.000020  loss: 1.3340 (1.4817)  loss_ce: 0.0164 (0.0224)  loss_iou: 0.2188 (0.2224)  loss_ce_0: 0.0382 (0.0437)  loss_iou_0: 0.3777 (0.4045)  loss_ce_1: 0.0193 (0.0281)  loss_iou_1: 0.3336 (0.3692)  loss_ce_2: 0.0149 (0.0235)  loss_iou_2: 0.3287 (0.3679)  loss_ce_unscaled: 0.0082 (0.0112)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0208 (0.0248)  loss_iou_unscaled: 0.1094 (0.1112)  loss_ce_0_unscaled: 0.0191 (0.0218)  loss_segments_0_unscaled: 0.0246 (0.0272)  loss_iou_0_unscaled: 0.1889 (0.2023)  loss_ce_1_unscaled: 0.0097 (0.0141)  loss_segments_1_unscaled: 0.0219 (0.0249)  loss_iou_1_unscaled: 0.1668 (0.1846)  loss_ce_2_unscaled: 0.0075 (0.0117)  loss_segments_2_unscaled: 0.0208 (0.0249)  loss_iou_2_unscaled: 0.1643 (0.1839)  time: 0.0677  data: 0.0012  max mem: 488
[11/28 15:58:46][INFO]: Epoch: [15]  [120/198]  eta: 0:00:05  lr: 0.000020  loss: 1.4035 (1.4885)  loss_ce: 0.0213 (0.0230)  loss_iou: 0.2173 (0.2215)  loss_ce_0: 0.0417 (0.0442)  loss_iou_0: 0.3867 (0.4061)  loss_ce_1: 0.0292 (0.0288)  loss_iou_1: 0.3619 (0.3711)  loss_ce_2: 0.0198 (0.0241)  loss_iou_2: 0.3514 (0.3699)  loss_ce_unscaled: 0.0106 (0.0115)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0223 (0.0250)  loss_iou_unscaled: 0.1087 (0.1107)  loss_ce_0_unscaled: 0.0208 (0.0221)  loss_segments_0_unscaled: 0.0275 (0.0273)  loss_iou_0_unscaled: 0.1934 (0.2030)  loss_ce_1_unscaled: 0.0146 (0.0144)  loss_segments_1_unscaled: 0.0231 (0.0250)  loss_iou_1_unscaled: 0.1809 (0.1856)  loss_ce_2_unscaled: 0.0099 (0.0120)  loss_segments_2_unscaled: 0.0223 (0.0249)  loss_iou_2_unscaled: 0.1757 (0.1849)  time: 0.0678  data: 0.0012  max mem: 488
[11/28 15:58:47][INFO]: Epoch: [15]  [140/198]  eta: 0:00:04  lr: 0.000020  loss: 1.4610 (1.4890)  loss_ce: 0.0254 (0.0237)  loss_iou: 0.2161 (0.2223)  loss_ce_0: 0.0486 (0.0451)  loss_iou_0: 0.3729 (0.4045)  loss_ce_1: 0.0286 (0.0290)  loss_iou_1: 0.3608 (0.3708)  loss_ce_2: 0.0252 (0.0244)  loss_iou_2: 0.3454 (0.3693)  loss_ce_unscaled: 0.0127 (0.0118)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0240 (0.0250)  loss_iou_unscaled: 0.1080 (0.1111)  loss_ce_0_unscaled: 0.0243 (0.0225)  loss_segments_0_unscaled: 0.0275 (0.0274)  loss_iou_0_unscaled: 0.1864 (0.2023)  loss_ce_1_unscaled: 0.0143 (0.0145)  loss_segments_1_unscaled: 0.0242 (0.0251)  loss_iou_1_unscaled: 0.1804 (0.1854)  loss_ce_2_unscaled: 0.0126 (0.0122)  loss_segments_2_unscaled: 0.0240 (0.0249)  loss_iou_2_unscaled: 0.1727 (0.1846)  time: 0.0678  data: 0.0013  max mem: 488
[11/28 15:58:48][INFO]: Epoch: [15]  [160/198]  eta: 0:00:02  lr: 0.000020  loss: 1.4814 (1.4908)  loss_ce: 0.0155 (0.0234)  loss_iou: 0.2152 (0.2220)  loss_ce_0: 0.0470 (0.0456)  loss_iou_0: 0.3927 (0.4056)  loss_ce_1: 0.0254 (0.0291)  loss_iou_1: 0.3525 (0.3715)  loss_ce_2: 0.0194 (0.0243)  loss_iou_2: 0.3539 (0.3693)  loss_ce_unscaled: 0.0077 (0.0117)  class_error_unscaled: 0.0000 (-0.0000)  loss_segments_unscaled: 0.0245 (0.0249)  loss_iou_unscaled: 0.1076 (0.1110)  loss_ce_0_unscaled: 0.0235 (0.0228)  loss_segments_0_unscaled: 0.0266 (0.0274)  loss_iou_0_unscaled: 0.1963 (0.2028)  loss_ce_1_unscaled: 0.0127 (0.0146)  loss_segments_1_unscaled: 0.0238 (0.0251)  loss_iou_1_unscaled: 0.1762 (0.1857)  loss_ce_2_unscaled: 0.0097 (0.0122)  loss_segments_2_unscaled: 0.0245 (0.0249)  loss_iou_2_unscaled: 0.1769 (0.1847)  time: 0.0680  data: 0.0012  max mem: 488
[11/28 15:58:50][INFO]: Epoch: [15]  [180/198]  eta: 0:00:01  lr: 0.000020  loss: 1.5272 (1.4988)  loss_ce: 0.0248 (0.0241)  loss_iou: 0.2228 (0.2225)  loss_ce_0: 0.0483 (0.0461)  loss_iou_0: 0.4048 (0.4075)  loss_ce_1: 0.0302 (0.0296)  loss_iou_1: 0.3693 (0.3733)  loss_ce_2: 0.0276 (0.0250)  loss_iou_2: 0.3545 (0.3708)  loss_ce_unscaled: 0.0124 (0.0120)  class_error_unscaled: 0.0000 (0.0085)  loss_segments_unscaled: 0.0248 (0.0249)  loss_iou_unscaled: 0.1114 (0.1112)  loss_ce_0_unscaled: 0.0241 (0.0230)  loss_segments_0_unscaled: 0.0270 (0.0275)  loss_iou_0_unscaled: 0.2024 (0.2038)  loss_ce_1_unscaled: 0.0151 (0.0148)  loss_segments_1_unscaled: 0.0257 (0.0251)  loss_iou_1_unscaled: 0.1847 (0.1866)  loss_ce_2_unscaled: 0.0138 (0.0125)  loss_segments_2_unscaled: 0.0248 (0.0249)  loss_iou_2_unscaled: 0.1772 (0.1854)  time: 0.0690  data: 0.0012  max mem: 488
[11/28 15:58:51][INFO]: Epoch: [15]  [197/198]  eta: 0:00:00  lr: 0.000020  loss: 1.4695 (1.4984)  loss_ce: 0.0261 (0.0245)  loss_iou: 0.2108 (0.2220)  loss_ce_0: 0.0446 (0.0457)  loss_iou_0: 0.3914 (0.4075)  loss_ce_1: 0.0291 (0.0297)  loss_iou_1: 0.3597 (0.3730)  loss_ce_2: 0.0296 (0.0254)  loss_iou_2: 0.3575 (0.3707)  loss_ce_unscaled: 0.0131 (0.0123)  class_error_unscaled: 0.0000 (0.0195)  loss_segments_unscaled: 0.0251 (0.0250)  loss_iou_unscaled: 0.1054 (0.1110)  loss_ce_0_unscaled: 0.0223 (0.0228)  loss_segments_0_unscaled: 0.0298 (0.0277)  loss_iou_0_unscaled: 0.1957 (0.2037)  loss_ce_1_unscaled: 0.0145 (0.0149)  loss_segments_1_unscaled: 0.0274 (0.0254)  loss_iou_1_unscaled: 0.1799 (0.1865)  loss_ce_2_unscaled: 0.0148 (0.0127)  loss_segments_2_unscaled: 0.0263 (0.0251)  loss_iou_2_unscaled: 0.1787 (0.1853)  time: 0.0665  data: 0.0012  max mem: 488
[11/28 15:58:51][INFO]: Epoch: [15] Total time: 0:00:13 (0.0692 s / it)
[11/28 15:58:51][INFO]: Averaged stats:lr: 0.000020  loss: 1.4695 (1.4984)  loss_ce: 0.0261 (0.0245)  loss_iou: 0.2108 (0.2220)  loss_ce_0: 0.0446 (0.0457)  loss_iou_0: 0.3914 (0.4075)  loss_ce_1: 0.0291 (0.0297)  loss_iou_1: 0.3597 (0.3730)  loss_ce_2: 0.0296 (0.0254)  loss_iou_2: 0.3575 (0.3707)  loss_ce_unscaled: 0.0131 (0.0123)  class_error_unscaled: 0.0000 (0.0195)  loss_segments_unscaled: 0.0251 (0.0250)  loss_iou_unscaled: 0.1054 (0.1110)  loss_ce_0_unscaled: 0.0223 (0.0228)  loss_segments_0_unscaled: 0.0298 (0.0277)  loss_iou_0_unscaled: 0.1957 (0.2037)  loss_ce_1_unscaled: 0.0145 (0.0149)  loss_segments_1_unscaled: 0.0274 (0.0254)  loss_iou_1_unscaled: 0.1799 (0.1865)  loss_ce_2_unscaled: 0.0148 (0.0127)  loss_segments_2_unscaled: 0.0263 (0.0251)  loss_iou_2_unscaled: 0.1787 (0.1853)
[11/28 15:58:51][INFO]: 3311 ground truth instances from 210 videos
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:95: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  gt_by_cls.append(all_gt[all_gt.cls == cls].reset_index(drop=True).drop('cls', 1))
  0%|                                                                                                                                           | 0/112 [00:00<?, ?it/s]/home/next/PycharmProjects/TadTR/TadTR/models/position_encoding.py:47: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
/home/next/PycharmProjects/TadTR/TadTR/models/tadtr.py:424: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  topk_segments = topk_indexes // out_logits.shape[2]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:04<00:00, 25.90it/s]
175700 210
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
/home/next/PycharmProjects/TadTR/TadTR/datasets/tad_eval.py:245: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.
  self.pred_by_cls[nms_mode] = [self.all_pred[nms_mode][self.all_pred[nms_mode].cls == cls].reset_index(drop=True).drop('cls', 1) for cls in range(self.num_classes)]
[11/28 15:58:59][INFO]: mode=raw 119728 predictions from 210 videos
[11/28 15:59:03][INFO]: 
0.30 0.40 0.50 0.60 0.70 avg
73.75 68.03 60.20 48.09 32.25 56.46 raw epoch15
[11/28 15:59:03][INFO]: mAP_raw: 56.46
[11/28 15:59:03][INFO]: new best metric 0.5646@epoch15
[11/28 15:59:03][INFO]: Training time 0:06:48
[11/28 15:59:03][INFO]: ['mAP_raw:0.5646468798121947', 'AP50_raw:0.6019867842918306']
[11/28 15:59:03][INFO]: best det result
0.30 0.40 0.50 0.60 0.70 avg
73.75 68.03 60.20 48.09 32.25 56.46 raw epoch15
[11/28 15:59:03][INFO]: outputs/thumos14_i3d2s_tadtr/train.log
[11/28 15:59:03][INFO]: main takes 411.399 seconds
(TadTR) next@pc-b-mou-d-2001-ubuntu:~/PycharmProjects/TadTR/TadTR$ 

